{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: facenet_pytorch in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (2.5.3)\n",
      "Requirement already satisfied: numpy in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from facenet_pytorch) (1.26.0)\n",
      "Requirement already satisfied: requests in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from facenet_pytorch) (2.31.0)\n",
      "Requirement already satisfied: torchvision in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from facenet_pytorch) (0.16.0)\n",
      "Requirement already satisfied: pillow in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from facenet_pytorch) (10.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from requests->facenet_pytorch) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from requests->facenet_pytorch) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from requests->facenet_pytorch) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from requests->facenet_pytorch) (2022.12.7)\n",
      "Requirement already satisfied: torch in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torchvision->facenet_pytorch) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (1.11.1)\n",
      "Requirement already satisfied: networkx in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (3.0)\n",
      "Requirement already satisfied: jinja2 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from torch->torchvision->facenet_pytorch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from jinja2->torch->torchvision->facenet_pytorch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from sympy->torch->torchvision->facenet_pytorch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install facenet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (4.44.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/csgrad/kaushik3/miniconda3/envs/llm/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.gender_mapping = {'male': 0, 'female': 1}\n",
    "        self.ethnicity_mapping = {'white': 0, 'black': 1, 'asian': 2, 'hispanic': 3}\n",
    "        self.data['nameNum'] = self.data['name'].astype('category').cat.codes\n",
    "        self.data['nameNum'] = self.data['nameNum'].astype(int)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "    \n",
    "    def getAgeLabel(self,value1):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        if(class_ranges[0][0]<=value1 and value1<class_ranges[0][1]):\n",
    "            return 0\n",
    "        elif(class_ranges[1][0]<=value1 and value1<class_ranges[1][1]):\n",
    "            return 1\n",
    "        elif(class_ranges[2][0]<=value1 and value1<class_ranges[2][1]):\n",
    "            return 2\n",
    "        elif(class_ranges[3][0]<=value1 and value1<class_ranges[3][1]):\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "   \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        image_path = '/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/Data/CELEBTEST/'+row['name']+'/' + row['filename']  # Assuming images are in a folder named 'images'\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(image_path)\n",
    "        except Exception as e:\n",
    "            # Handle the error, for example, you can return a placeholder image\n",
    "            print(\"here\")\n",
    "            #self.__getitem__(idx + 1)\n",
    "            #image = Image.new('RGB', (224, 224))  # Create a blank image\n",
    "        \n",
    "        image = Image.open(image_path)\n",
    "        age = row['age']\n",
    "        \n",
    "        if(row['age']<=0):\n",
    "            age=35\n",
    "        label = {\n",
    "            'age': self.getAgeLabel(age),\n",
    "            'gender': self.gender_mapping.get(row['gender'], 0),  # -1 for unknown\n",
    "            'ethnicity': self.ethnicity_mapping.get(row['ethnicity'], 0),\n",
    "            'age1':age,\n",
    "            'name': row['nameNum']\n",
    "        \n",
    "        }\n",
    "        #print(row['name'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/home/csgrad/byalavar/FHE/celebSet/celebSET_final_v1.csv'  # Replace with the actual path to your CSV file\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Create a list to store the indices of rows with missing files\n",
    "# rows_to_remove = []\n",
    "# count=0\n",
    "# # Iterate through the DataFrame and check if the files exist\n",
    "# for index, row in df.iterrows():\n",
    "#     image_path = '/home/csgrad/byalavar/FHE/celebSet/CELEBTEST/CELEBTEST/'+row['name']+'/' + row['filename'] \n",
    "#     if not os.path.exists(image_path):\n",
    "#         rows_to_remove.append(index)\n",
    "#         count=count+1\n",
    "# df = df.drop(rows_to_remove)\n",
    "# df.to_csv(csv_file, index=False)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to the desired size\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet = CustomDataset('/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/celebSetIdentity.csv', transform=transform)\n",
    "trainloader = DataLoader(trainSet, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "testSet = CustomDataset('/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/celebSetIdentityTest.csv', transform=transform)\n",
    "testloader = DataLoader(testSet, batch_size=16, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        # print(npimg.shape)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tempIter = iter(testloader)\n",
    "# images,image_pairs = next(tempIter)\n",
    "# imshow(images[0])\n",
    "# print(labels['age'][0],labels['gender'][0],labels['ethnicity'][0])\n",
    "# print(image_pairs)\n",
    "image, label = next(tempIter)\n",
    "imshow(image[0])\n",
    "# imshow(image_pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear, Conv2d, BatchNorm1d, BatchNorm2d, PReLU, ReLU, Sigmoid, Dropout, MaxPool2d, \\\n",
    "    AdaptiveAvgPool2d, Sequential, Module\n",
    "from collections import namedtuple\n",
    "\n",
    "\n",
    "# Support: ['IR_50', 'IR_101', 'IR_152', 'IR_SE_50', 'IR_SE_101', 'IR_SE_152']\n",
    "\n",
    "\n",
    "class Flatten(Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "def l2_norm(input, axis=1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class SEModule(Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(\n",
    "            channels, channels // reduction, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight.data)\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(\n",
    "            channels // reduction, channels, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "class bottleneck_IR(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False), BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False), PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False), BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class bottleneck_IR_SE(Module):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(bottleneck_IR_SE, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            SEModule(depth, 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "\n",
    "\n",
    "def get_block(in_channel, depth, num_units, stride=2):\n",
    "\n",
    "    return [Bottleneck(in_channel, depth, stride)] + [Bottleneck(depth, depth, 1) for i in range(num_units - 1)]\n",
    "\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=8),\n",
    "            get_block(in_channel=128, depth=256, num_units=36),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, input_size, num_layers, mode='ir'):\n",
    "        super(Backbone, self).__init__()\n",
    "        assert input_size[0] in [112, 224], \"input_size should be [112, 112] or [224, 224]\"\n",
    "        assert num_layers in [50, 100, 152], \"num_layers should be 50, 100 or 152\"\n",
    "        assert mode in ['ir', 'ir_se'], \"mode should be ir or ir_se\"\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if mode == 'ir':\n",
    "            unit_module = bottleneck_IR\n",
    "        elif mode == 'ir_se':\n",
    "            unit_module = bottleneck_IR_SE\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64),\n",
    "                                      PReLU(64))\n",
    "        if input_size[0] == 112:\n",
    "            self.output_layer = Sequential(BatchNorm2d(512),\n",
    "                                           Dropout(),\n",
    "                                           Flatten(),\n",
    "                                           Linear(512 * 7 * 7, 512),\n",
    "                                           BatchNorm1d(512))\n",
    "        else:\n",
    "            self.output_layer = Sequential(BatchNorm2d(512),\n",
    "                                           Dropout(),\n",
    "                                           Flatten(),\n",
    "                                           Linear(512 * 14 * 14, 512),\n",
    "                                           BatchNorm1d(512))\n",
    "\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel,\n",
    "                                bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        x = self.body(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def IR_50(input_size):\n",
    "    \"\"\"Constructs a ir-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_101(input_size):\n",
    "    \"\"\"Constructs a ir-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_152(input_size):\n",
    "    \"\"\"Constructs a ir-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_50(input_size):\n",
    "    \"\"\"Constructs a ir_se-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_101(input_size):\n",
    "    \"\"\"Constructs a ir_se-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_152(input_size):\n",
    "    \"\"\"Constructs a ir_se-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir_se')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcFaceModel = IR_50([112,112])\n",
    "arcFaceModel.load_state_dict(torch.load(\"/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/Data/ArcFace/backbone_ir50_ms1m_epoch120.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.data['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_age_value(original_age_value):\n",
    "    return (original_age_value - trainSet.data['age'].min())/(trainSet.data['age'].max() - trainSet.data['age'].min())\n",
    "\n",
    "\n",
    "def get_original_age_value(normalized_age_value):\n",
    "    return normalized_age_value * (trainSet.data['age'].max()  - trainSet.data['age'].min()) + trainSet.data['age'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import MSELoss\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "from torch.nn.parallel import DataParallel\n",
    "\n",
    "class GenderDet(nn.Module):\n",
    "    def __init__(self, compression_size):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(compression_size,64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "\n",
    "class AgeDet(nn.Module):\n",
    "    def __init__(self, compression_size):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(compression_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 4)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "class EthnicityDet(nn.Module):\n",
    "    def __init__(self, compression_size):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(compression_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "class IdentityDet(nn.Module):\n",
    "    def __init__(self, compression_size):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(compression_size, 64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64, 80))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "\n",
    "class Matryoshka_CE_Loss(nn.Module):\n",
    "    def __init__(self, relative_importance = 1.0):\n",
    "        super(Matryoshka_CE_Loss, self).__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.relative_importance = relative_importance # usually set to all ones\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        loss = 0\n",
    "        for i in range(len(output)):\n",
    "            # loss += self.relative_importance[i] * self.criterion(output[i], target)\n",
    "            loss += self.relative_importance * self.criterion(output[i], target)\n",
    "        return loss\n",
    "\n",
    "class MRL_Linear_Layer(nn.Module):\n",
    "    def __init__(self, nesting_list, num_classes=1000, efficient=False, **kwargs):\n",
    "        super(MRL_Linear_Layer, self).__init__()\n",
    "        self.nesting_list=nesting_list\n",
    "        self.num_classes=num_classes # Number of classes for classification\n",
    "        self.efficient = efficient\n",
    "        if self.efficient:\n",
    "            setattr(self, f\"nesting_classifier_{0}\", nn.Linear(nesting_list[-1], self.num_classes, **kwargs))\t\t\n",
    "        else:\t\n",
    "            for i, num_feat in enumerate(self.nesting_list):\n",
    "                setattr(self, f\"nesting_classifier_{i}\", nn.Linear(num_feat, self.num_classes, **kwargs))\t\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        nesting_logits = ()\n",
    "        for i, num_feat in enumerate(self.nesting_list):\n",
    "            if self.efficient:\n",
    "                if self.nesting_classifier_0.bias is None:\n",
    "                    nesting_logits+= (torch.matmul(x[:, :num_feat], (self.nesting_classifier_0.weight[:, :num_feat]).t()), )\n",
    "                else:\n",
    "                    nesting_logits+= (torch.matmul(x[:, :num_feat], (self.nesting_classifier_0.weight[:, :num_feat]).t()) + self.nesting_classifier_0.bias, )\n",
    "            else:\n",
    "                nesting_logits +=  (getattr(self, f\"nesting_classifier_{i}\")(x[:, :num_feat]),)\n",
    "\n",
    "        return nesting_logits\n",
    "\n",
    "class MRL_Model(nn.Module):\n",
    "    def __init__(self, compression_size, efficient=False):\n",
    "        super(MRL_Model, self).__init__()\n",
    "        self.ll1 = MRL_Linear_Layer([256], num_classes = compression_size, efficient = efficient)\n",
    "        self.ll2 = MRL_Linear_Layer([compression_size], num_classes = 80, efficient = efficient)\n",
    "        # self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        x = self.ll1(x)\n",
    "        return self.ll2(x[0]), x\n",
    "    \n",
    "\n",
    "class CompressionLoss(nn.Module):\n",
    "    def __init__(self, batch_size):\n",
    "        super(CompressionLoss, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, img, genuine_imgs, imposter_imgs, genuine_sim, imposter_sim):\n",
    "        # img -> base image embedding\n",
    "        # genuine_imgs, imposter_imgs -> Compressed embeddings of dimension 128\n",
    "        # genuine_sim, imposter_sim -> cosine smilairty scores of uncompressed embeddings of dimension 512\n",
    "\n",
    "\n",
    "        # Compute cosine similarity loss\n",
    "        genuine_loss = 0\n",
    "        for i in range(len(genuine_imgs)):\n",
    "            sim_score = F.cosine_similarity(img, genuine_imgs[i])\n",
    "            genuine_loss += torch.mean(torch.abs(sim_score - genuine_sim[i].view(-1)))\n",
    "\n",
    "        imp_loss = 0\n",
    "        for i in range(len(imposter_imgs)):\n",
    "            imp_sim_score = F.cosine_similarity(img, imposter_imgs[i])\n",
    "            imp_loss += torch.mean(torch.abs(imp_sim_score - imposter_sim[i].view(-1)))\n",
    "\n",
    "        \n",
    "        # Compute Covariance Loss\n",
    "        # matrix -> Concatenates compressed genuine and imposter embeddings\n",
    "        \n",
    "        matrix = torch.cat([genuine_imgs[0], imposter_imgs[0]], dim=0)\n",
    "        for i in range(1, len(genuine_imgs)):\n",
    "            matrix = torch.cat([matrix, genuine_imgs[i]], dim = 0)\n",
    "            matrix = torch.cat([matrix, imposter_imgs[i]], dim = 0)\n",
    "\n",
    "\n",
    "        mean_matrix = torch.mean(matrix, dim = 0)\n",
    "        mx = torch.matmul(mean_matrix.t(), mean_matrix)\n",
    "        vx = torch.matmul(matrix.t(), matrix) / self.batch_size # Dividing by batch size as done here https://github.com/human-analysis/hers-encrypted-image-search/blob/master/deep_mds%2B%2B/nntools/tensorflow/networks/deepmds.py#L94\n",
    "        cov_matrix = mx - vx\n",
    "        diag = torch.diag(cov_matrix.diag())\n",
    "        cov_loss = torch.mean(torch.abs(cov_matrix - diag))\n",
    "        \n",
    "        # Compute Supervise Loss - Not used for ArcFace\n",
    "        # # g_dist -> Concatenates compressed genuine embeddings\n",
    "        # g_dist = torch.cat([genuine_imgs[0], genuine_imgs[1]], dim = 0)\n",
    "        # for i in range(2, len(genuine_imgs)):\n",
    "        #     g_dist = torch.cat([g_dist, genuine_imgs[i]], dim = 0)\n",
    "\n",
    "        # # g_dist -> Concatenates compressed imposter embeddings\n",
    "        # imp_dist = torch.cat([imposter_imgs[0], imposter_imgs[1]], dim = 0)\n",
    "        # for i in range(2, len(imposter_imgs)):\n",
    "        #     imp_dist = torch.cat([imp_dist, imposter_imgs[i]], dim = 0)\n",
    "\n",
    "        # gloss = (torch.mean(g_dist) + 1.0) * 0.5\n",
    "        # iloss = (torch.mean(imp_dist) + 1.0) * 0.5\n",
    "\n",
    "        # lda_term = iloss / gloss\n",
    "        # return genuine_loss + imp_loss + 10 * cov_loss \n",
    "        return 10*genuine_loss + imp_loss + cov_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class faceAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1=nn.Linear(128,64)\n",
    "        self.dropout1=nn.Dropout(0.2)\n",
    "        self.layer2=nn.Linear(64,32)\n",
    "        #self.layer3=nn.Linear(1024,512)\n",
    "        # self.layer4=nn.Linear(128,64)\n",
    "        self.dropout2=nn.Dropout(0.2)\n",
    "        self.genderOut = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "        self.ageOut = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,4)\n",
    "        )\n",
    "        self.ethnicityOut = nn.Sequential(\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,2)\n",
    "        )\n",
    "\n",
    "        self.identity = nn.Sequential(\n",
    "            nn.Linear(128,64), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(64,80))\n",
    "        # self.maxVal = 0\n",
    "        # self.min=0\n",
    "        \n",
    "    \n",
    "    def writeResult(self,result):\n",
    "       output_directory=\"\"\n",
    "       file_name = \"resultAge.txt\"\n",
    "\n",
    "       with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in result:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        #print(\"Input\",x[0])\n",
    "        # x=self.layer1(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "        # x=self.layer2(x)\n",
    "        # x = nn.ReLU()(x)\n",
    "\n",
    "        gender = self.genderOut(x)\n",
    "        age = self.ageOut(x)\n",
    "        ethn = self.ethnicityOut(x)\n",
    "        id = self.identity(x)\n",
    "        # identity = self.identity(x)\n",
    "        return gender, age, ethn, id\n",
    "    \n",
    "    \n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False    \n",
    "    \n",
    "    def trainMRL(self, compressed_dim, trainloader, arcFace, MRL_Model, MRL_Loss, device, episodes):\n",
    "        # input_dim = 512\n",
    "        # compressed_dim = 128\n",
    "        model = MRL_Model\n",
    "        # Define optimizer and loss function\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        MRLoss = MRL_Loss.to(device)\n",
    "        model.train()\n",
    "        for ep in range(episodes):\n",
    "            total_loss = 0\n",
    "            print(\"Starting \" + str(ep))\n",
    "\n",
    "            for img, data in trainloader:\n",
    "                img = img.to(device=device)\n",
    "                label = data['name'].to(device=device)\n",
    "                # input = img[:, [2, 1, 0], :, :]\n",
    "                #print(inputs.shape)\n",
    "                embeddings = arcFace(img)\n",
    "                output, _ = model(embeddings)\n",
    "                loss = MRLoss(output, label)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                total_loss += loss.item()\n",
    "            print(f\"Epoch [{ep + 1}/{episodes}], Loss: {total_loss}\")\n",
    "        torch.save(model, f'MRL_Model_512x{compressed_dim}_ArcFace_{episodes}.pt')\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "    def testMRL(self, trainloader, testloader, arcFace, MRL_Model, idModel, genderModel, ageModel, ethModel, device, episodes):\n",
    "        # self.train()\n",
    "        learningRate = 0.001\n",
    "        gender_loss = nn.CrossEntropyLoss().to(device) \n",
    "        age_loss = nn.CrossEntropyLoss().to(device) \n",
    "        ethn_loss = nn.CrossEntropyLoss().to(device)\n",
    "        identityLoss = nn.CrossEntropyLoss().to(device)\n",
    "        IdOptimizer = torch.optim.Adam(idModel.parameters(), lr=learningRate)\n",
    "        AgeOptimizer = torch.optim.Adam(ageModel.parameters(), lr=learningRate)\n",
    "        GenderOptimizer = torch.optim.Adam(genderModel.parameters(), lr=learningRate)\n",
    "        EthOptimizer = torch.optim.Adam(ethModel.parameters(), lr=learningRate)\n",
    "        model = MRL_Model\n",
    "        model.eval()\n",
    "        idModel.train()\n",
    "        genderModel.train()\n",
    "        ageModel.train()\n",
    "        ethModel.train()\n",
    "        for ep in range(0, episodes):\n",
    "            total_gender_loss = 0\n",
    "            total_age_loss = 0\n",
    "            total_ethn_loss = 0\n",
    "            total_id_loss = 0\n",
    "            for i, data in enumerate(trainloader):\n",
    "\n",
    "                inputs = data[0].to(device=device)\n",
    "                age_label = (data[1][\"age\"]).to(device=device)\n",
    "                gender_label = data[1][\"gender\"].to(device=device)\n",
    "                ethn_label = data[1][\"ethnicity\"].to(device=device)\n",
    "                id_label = data[1][\"name\"].to(device=device)\n",
    "                embeddings = arcFace(inputs)\n",
    "                output, compressedOutput = model(embeddings)\n",
    "                # print(output[0].shape)\n",
    "                # print(compressedOutput[0].shape)\n",
    "                # return\n",
    "                output1 = torch.clone(compressedOutput[0])\n",
    "                id = idModel(output1)\n",
    "                output2 = torch.clone(compressedOutput[0])\n",
    "                gender = genderModel(output2)\n",
    "                output3 = torch.clone(compressedOutput[0])\n",
    "                age = ageModel(output3)\n",
    "                output4 = torch.clone(compressedOutput[0])\n",
    "                eth = ethModel(output4)\n",
    "                # gender, age, ethn, id = self(new_output)\n",
    "\n",
    "                idLoss = identityLoss(id, id_label) \n",
    "                ageLoss = age_loss(age, age_label) \n",
    "                genLoss =  gender_loss(gender, gender_label)\n",
    "                ethLoss = ethn_loss(eth, ethn_label) \n",
    "                \n",
    "                IdOptimizer.zero_grad() \n",
    "                AgeOptimizer.zero_grad() \n",
    "                GenderOptimizer.zero_grad() \n",
    "                EthOptimizer.zero_grad()\n",
    "\n",
    "                idLoss.backward(retain_graph = True)\n",
    "                ageLoss.backward(retain_graph = True)\n",
    "                genLoss.backward(retain_graph = True)\n",
    "                ethLoss.backward(retain_graph = True) \n",
    "                \n",
    "                IdOptimizer.step() \n",
    "                AgeOptimizer.step() \n",
    "                GenderOptimizer.step() \n",
    "                EthOptimizer.step()\n",
    "                \n",
    "                total_gender_loss += genLoss.item()\n",
    "                total_age_loss += ageLoss.item()\n",
    "                total_ethn_loss += ethLoss.item()\n",
    "                total_id_loss += idLoss.item()\n",
    "            print(f\"Epoch [{ep + 1}/{episodes}], Id Loss: {total_id_loss}, Gender Loss: {total_gender_loss}, Age Loss: {total_age_loss}, Eth Loss: {total_ethn_loss} \")\n",
    "        print(\"Training done!\")\n",
    "\n",
    "        # self.eval()\n",
    "        count = 0\n",
    "        genderAcc = 0\n",
    "        ageAcc = 0\n",
    "        ethnAcc = 0\n",
    "        idAcc = 0\n",
    "        for i, data in enumerate(testloader):\n",
    "\n",
    "            inputs = data[0].to(device=device)\n",
    "            age_label = (data[1][\"age\"]).to(device=device)\n",
    "            gender_label = data[1][\"gender\"].to(device=device)\n",
    "            ethn_label = data[1][\"ethnicity\"].to(device=device)\n",
    "            id_label = data[1][\"name\"].to(device = device)\n",
    "            embeddings = arcFace(inputs)\n",
    "            output, compressedOutput = model(embeddings)\n",
    "            # gender, age, ethn, id = self(compressedOutput[0])\n",
    "\n",
    "            output1 = torch.clone(compressedOutput[0])\n",
    "            id = idModel(output1)\n",
    "            output2 = torch.clone(compressedOutput[0])\n",
    "            gender = genderModel(output2)\n",
    "            output3 = torch.clone(compressedOutput[0])\n",
    "            age = ageModel(output3)\n",
    "            output4 = torch.clone(compressedOutput[0])\n",
    "            eth = ethModel(output4)\n",
    "\n",
    "            predictedGender = torch.argmax(gender, dim = 1)\n",
    "            predictedEthn = torch.argmax(eth, dim = 1)\n",
    "            predictedAge = torch.argmax(age, dim = 1)\n",
    "            predictedId = torch.argmax(id, dim = 1)\n",
    "            for j in range(0, predictedGender.shape[0]):\n",
    "                count = count + 1\n",
    "                if(predictedGender[j].item()==gender_label[j].item()):\n",
    "                    genderAcc = genderAcc + 1\n",
    "            \n",
    "                if(predictedEthn[j].item()==ethn_label[j].item()):\n",
    "                    ethnAcc = ethnAcc + 1\n",
    "\n",
    "                if(predictedAge[j].item() == age_label[j].item()):\n",
    "                    ageAcc = ageAcc + 1\n",
    "                \n",
    "                if(predictedId[j].item() == id_label[j].item()):\n",
    "                    idAcc = idAcc + 1\n",
    "\n",
    "        print(\"Id Accuracy : \", idAcc / count, \"Gender Accuracy : \", genderAcc / count, \" Age Acc : \", ageAcc / count, \" ethnAcc : \", ethnAcc/count)\n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Backbone(\n",
       "  (input_layer): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (output_layer): Sequential(\n",
       "    (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Flatten()\n",
       "    (3): Linear(in_features=25088, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (body): Sequential(\n",
       "    (0): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=64)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): bottleneck_IR(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=128)\n",
       "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): bottleneck_IR(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (19): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (20): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=256)\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (21): bottleneck_IR(\n",
       "      (shortcut_layer): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (22): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (23): bottleneck_IR(\n",
       "      (shortcut_layer): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "      (res_layer): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (2): PReLU(num_parameters=512)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "FAmodel=faceAnalytics()\n",
    "# nesting_list = [64, 128, 256]\n",
    "# num_classes = 80\n",
    "compression_size = 256\n",
    "MRL_model = MRL_Model(compression_size)\n",
    "# MRL_model = torch.load('/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/MRL_Model_512x64_ArcFace_20.pt')\n",
    "MRL_Loss = Matryoshka_CE_Loss()\n",
    "FAmodel.to(device)\n",
    "MRL_model.to(device)\n",
    "arcFaceModel.to(device)\n",
    "arcFaceModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 0\n",
      "Epoch [1/20], Loss: 500.50058460235596\n",
      "Starting 1\n",
      "Epoch [2/20], Loss: 374.60414123535156\n",
      "Starting 2\n",
      "Epoch [3/20], Loss: 278.2711144685745\n",
      "Starting 3\n",
      "Epoch [4/20], Loss: 214.74215281009674\n",
      "Starting 4\n",
      "Epoch [5/20], Loss: 174.56163436174393\n",
      "Starting 5\n",
      "Epoch [6/20], Loss: 147.80152130126953\n",
      "Starting 6\n",
      "Epoch [7/20], Loss: 128.72493305802345\n",
      "Starting 7\n",
      "Epoch [8/20], Loss: 114.14976951479912\n",
      "Starting 8\n",
      "Epoch [9/20], Loss: 102.49664607644081\n",
      "Starting 9\n",
      "Epoch [10/20], Loss: 92.89421361684799\n",
      "Starting 10\n",
      "Epoch [11/20], Loss: 84.70674900710583\n",
      "Starting 11\n",
      "Epoch [12/20], Loss: 77.556860730052\n",
      "Starting 12\n",
      "Epoch [13/20], Loss: 71.38453320413828\n",
      "Starting 13\n",
      "Epoch [14/20], Loss: 65.75863551348448\n",
      "Starting 14\n",
      "Epoch [15/20], Loss: 60.760798901319504\n",
      "Starting 15\n",
      "Epoch [16/20], Loss: 56.13069296628237\n",
      "Starting 16\n",
      "Epoch [17/20], Loss: 51.973463866859674\n",
      "Starting 17\n",
      "Epoch [18/20], Loss: 48.138040233403444\n",
      "Starting 18\n",
      "Epoch [19/20], Loss: 44.59223452210426\n",
      "Starting 19\n",
      "Epoch [20/20], Loss: 41.341445568948984\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "FAmodel.trainMRL(compression_size, trainloader, arcFaceModel, MRL_model, MRL_Loss, device, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Id Loss: 384.4756257534027, Gender Loss: 45.012040726840496, Age Loss: 105.01387766003609, Eth Loss: 41.65078818053007 \n",
      "Epoch [2/5], Id Loss: 133.85926458239555, Gender Loss: 23.8991395868361, Age Loss: 76.93986541032791, Eth Loss: 18.707006962038577 \n",
      "Epoch [3/5], Id Loss: 79.07191544771194, Gender Loss: 18.39983718842268, Age Loss: 63.45277412235737, Eth Loss: 12.192165865097195 \n",
      "Epoch [4/5], Id Loss: 57.71447614580393, Gender Loss: 15.807818291708827, Age Loss: 53.67795714735985, Eth Loss: 9.02058609481901 \n",
      "Epoch [5/5], Id Loss: 43.84950467199087, Gender Loss: 13.71296157661709, Age Loss: 46.66993102431297, Eth Loss: 5.744692137290258 \n",
      "Training done!\n",
      "Id Accuracy :  0.910625 Gender Accuracy :  0.970625  Age Acc :  0.776875  ethnAcc :  0.953125\n"
     ]
    }
   ],
   "source": [
    "idModel = IdentityDet(compression_size)\n",
    "idModel.to(device)\n",
    "ageModel = AgeDet(compression_size)\n",
    "ageModel.to(device)\n",
    "genderModel = GenderDet(compression_size)\n",
    "genderModel.to(device)\n",
    "ethModel = EthnicityDet(compression_size)\n",
    "ethModel.to(device)\n",
    "FAmodel.testMRL(trainloader, testloader, arcFaceModel, MRL_model, idModel, genderModel, ageModel, ethModel, device, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is Face Verification experiment. Fails to complete since memory is insufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 2 has a total capacty of 79.15 GiB of which 13.44 MiB is free. Including non-PyTorch memory, this process has 79.14 GiB memory in use. Of the allocated memory 74.77 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m iden_label \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# inputs = inputs[:, [2, 1, 0], :, :]    \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m embeddings \u001b[39m=\u001b[39m arcFaceModel(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m _, compressedOutput \u001b[39m=\u001b[39m MRL_model(embeddings)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# compressed_img1 = compressionModel1(embeddings)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# compressed_img2 = compressionModel2(compressed_img1)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# compressed = combinedModel(embeddings)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(compressedOutput)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb Cell 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=166'>167</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=167'>168</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layer(x)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=168'>169</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbody(x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_layer(x)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/llm/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb Cell 22\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=62'>63</a>\u001b[0m shortcut \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut_layer(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=63'>64</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mres_layer(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mreturn\u001b[39;00m res \u001b[39m+\u001b[39m shortcut\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 2 has a total capacty of 79.15 GiB of which 13.44 MiB is free. Including non-PyTorch memory, this process has 79.14 GiB memory in use. Of the allocated memory 74.77 GiB is allocated by PyTorch, and 2.77 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "MRL_model = torch.load('/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/MRL_Model_ArcFace_20.pt')\n",
    "MRL_model.to(device)\n",
    "arcFaceModel.to(device) \n",
    "MRL_model.eval()\n",
    "processedTensor = torch.zeros((len(testSet), 128))\n",
    "identityLabel = torch.zeros((len(testSet)))\n",
    "count = 0\n",
    "\n",
    "for i,data in enumerate(testloader):\n",
    "    \n",
    "    inputs = data[0].to(device=device)\n",
    "    iden_label = data[1]['name'].to(device=device)\n",
    "    # inputs = inputs[:, [2, 1, 0], :, :]    \n",
    "    embeddings = arcFaceModel(inputs)\n",
    "    _, compressedOutput = MRL_model(embeddings)\n",
    "    # compressed_img1 = compressionModel1(embeddings)\n",
    "    # compressed_img2 = compressionModel2(compressed_img1)\n",
    "    # compressed = combinedModel(embeddings)\n",
    "    # print(compressedOutput)\n",
    "    processedTensor[count : count + embeddings.shape[0]] = compressedOutput[0]\n",
    "    identityLabel[count:count + iden_label.shape[0]] = torch.tensor(iden_label)\n",
    "\n",
    "\n",
    "    count = count + embeddings.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'processedTensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb Cell 23\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m identityAccuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m(count \u001b[39m<\u001b[39m processedTensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     currentFace \u001b[39m=\u001b[39m processedTensor[count : count \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/kaushik3/PolyProtect/PolyProtect_HEAAN/HEAAN/code/CompressionCode/CompressionArcFaceCelebSet_MRL.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     cosine_similarity \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcosine_similarity(currentFace, processedTensor)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processedTensor' is not defined"
     ]
    }
   ],
   "source": [
    "identityAccuracy = 0\n",
    "\n",
    "count = 0\n",
    "\n",
    "while(count < processedTensor.shape[0]):\n",
    "\n",
    "    currentFace = processedTensor[count : count + 1]\n",
    "    cosine_similarity = nn.functional.cosine_similarity(currentFace, processedTensor)\n",
    "    if(identityLabel[torch.topk(cosine_similarity, k = 2)[1][1]].item() == identityLabel[count].item()):\n",
    "        identityAccuracy = identityAccuracy +1\n",
    "    count = count + 1\n",
    "    # print(count)\n",
    "print(identityAccuracy/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
