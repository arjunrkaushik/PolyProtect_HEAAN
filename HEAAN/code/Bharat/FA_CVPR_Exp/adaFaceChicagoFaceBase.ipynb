{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrad/byalavar/miniconda3/envs/train/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.gender_mapping = {'M': 0, 'F': 1}\n",
    "        self.ethnicity_mapping = {'A': 0, 'B': 1, 'L': 2, 'W': 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "        \n",
    "    def getAgeLabel(self,value1):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        if(class_ranges[0][0]<=value1 and value1<class_ranges[0][1]):\n",
    "            return 0\n",
    "        elif(class_ranges[1][0]<=value1 and value1<class_ranges[1][1]):\n",
    "            return 1\n",
    "        elif(class_ranges[2][0]<=value1 and value1<class_ranges[2][1]):\n",
    "            return 2\n",
    "        elif(class_ranges[3][0]<=value1 and value1<class_ranges[3][1]):\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        folder_path  = '/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/Images/CFD/'+row['Model'] # Assuming images are in a folder named 'images'\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        image_file_path = os.path.join(folder_path, image_files[0])\n",
    "    \n",
    "\n",
    "        image = Image.open(image_file_path)\n",
    "        age = row['AgeRated']\n",
    "        \n",
    "        if(row['AgeRated']<=0):\n",
    "            age=35\n",
    "        label = {\n",
    "            'age': self.getAgeLabel(age),\n",
    "            'gender': self.gender_mapping.get(row['GenderSelf'], 0),  # -1 for unknown\n",
    "            'ethnicity': self.ethnicity_mapping.get(row['EthnicitySelf'], 0)\n",
    "        \n",
    "        }\n",
    "        #print(row['name'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/home/csgrad/byalavar/FHE/celebSet/celebSET_final_v1.csv'  # Replace with the actual path to your CSV file\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Create a list to store the indices of rows with missing files\n",
    "# rows_to_remove = []\n",
    "# count=0\n",
    "# # Iterate through the DataFrame and check if the files exist\n",
    "# for index, row in df.iterrows():\n",
    "#     image_path = '/home/csgrad/byalavar/FHE/celebSet/CELEBTEST/CELEBTEST/'+row['name']+'/' + row['filename'] \n",
    "#     if not os.path.exists(image_path):\n",
    "#         rows_to_remove.append(index)\n",
    "#         count=count+1\n",
    "# df = df.drop(rows_to_remove)\n",
    "# df.to_csv(csv_file, index=False)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to the desired size\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "transformAugment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "transformAugment2 = transforms.Compose([\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine([-45,45]),\n",
    "    transforms.ElasticTransform(),\n",
    "    transforms.GaussianBlur([3,3]),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "# trainloader = DataLoader(trainSet, batch_size=128, shuffle=False)\n",
    "\n",
    "dataSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#datasetAugment = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transformAugment)\n",
    "\n",
    "\n",
    "#dataSet = torch.utils.data.ConcatDataset([dataSet])\n",
    "\n",
    "\n",
    "\n",
    "# Specify the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(dataSet))\n",
    "testSize = len(dataSet) - train_size\n",
    "\n",
    "# Use random_split to create training and validation datasets\n",
    "train_dataset, test_dataset = random_split(dataSet, [train_size, testSize])\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(0) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "tempIter = iter(testloader)\n",
    "images,labels = next(tempIter)\n",
    "imshow(images[0])\n",
    "print(labels['age'][0],labels['gender'][0],labels['ethnicity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d, Linear\n",
    "from torch.nn import BatchNorm1d, BatchNorm2d\n",
    "from torch.nn import ReLU, Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.nn import PReLU\n",
    "import os\n",
    "\n",
    "def build_model(model_name='ir_50'):\n",
    "    if model_name == 'ir_101':\n",
    "        return IR_101(input_size=(112,112))\n",
    "    elif model_name == 'ir_50':\n",
    "        return IR_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_se_50':\n",
    "        return IR_SE_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_34':\n",
    "        return IR_34(input_size=(112,112))\n",
    "    elif model_name == 'ir_18':\n",
    "        return IR_18(input_size=(112,112))\n",
    "    else:\n",
    "        raise ValueError('not a correct model name', model_name)\n",
    "\n",
    "def initialize_weights(modules):\n",
    "    \"\"\" Weight initilize, conv2d and linear is initialized with kaiming_normal\n",
    "    \"\"\"\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class Flatten(Module):\n",
    "    \"\"\" Flat tensor\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class LinearBlock(Module):\n",
    "    \"\"\" Convolution block without no-linear activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_c, kernel, stride, padding, groups=groups, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNAP(Module):\n",
    "    \"\"\" Global Norm-Aware Pooling block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c):\n",
    "        super(GNAP, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(in_c, affine=False)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bn2 = BatchNorm1d(in_c, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x_norm = torch.norm(x, 2, 1, True)\n",
    "        x_norm_mean = torch.mean(x_norm)\n",
    "        weight = x_norm_mean / x_norm\n",
    "        x = x * weight\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        feature = self.bn2(x)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GDC(Module):\n",
    "    \"\"\" Global Depthwise Convolution block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, embedding_size):\n",
    "        super(GDC, self).__init__()\n",
    "        self.conv_6_dw = LinearBlock(in_c, in_c,\n",
    "                                     groups=in_c,\n",
    "                                     kernel=(7, 7),\n",
    "                                     stride=(1, 1),\n",
    "                                     padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(in_c, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_6_dw(x)\n",
    "        x = self.conv_6_flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SEModule(Module):\n",
    "    \"\"\" SE block\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(channels, channels // reduction,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight.data)\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(channels // reduction, channels,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlockIR(Module):\n",
    "    \"\"\" BasicBlock for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BottleneckIR(Module):\n",
    "    \"\"\" BasicBlock with bottleneck for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIR, self).__init__()\n",
    "        reduction_channel = depth // 4\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, reduction_channel, (1, 1), (1, 1), 0, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, reduction_channel, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, depth, (1, 1), stride, 0, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BasicBlockIRSE(BasicBlockIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class BottleneckIRSE(BottleneckIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "\n",
    "\n",
    "def get_block(in_channel, depth, num_units, stride=2):\n",
    "\n",
    "    return [Bottleneck(in_channel, depth, stride)] +\\\n",
    "           [Bottleneck(depth, depth, 1) for i in range(num_units - 1)]\n",
    "\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 18:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=2),\n",
    "            get_block(in_channel=64, depth=128, num_units=2),\n",
    "            get_block(in_channel=128, depth=256, num_units=2),\n",
    "            get_block(in_channel=256, depth=512, num_units=2)\n",
    "        ]\n",
    "    elif num_layers == 34:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=6),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=8),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 200:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=24),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, input_size, num_layers, mode='ir'):\n",
    "        \"\"\" Args:\n",
    "            input_size: input_size of backbone\n",
    "            num_layers: num_layers of backbone\n",
    "            mode: support ir or irse\n",
    "        \"\"\"\n",
    "        super(Backbone, self).__init__()\n",
    "        assert input_size[0] in [112, 224], \\\n",
    "            \"input_size should be [112, 112] or [224, 224]\"\n",
    "        assert num_layers in [18, 34, 50, 100, 152, 200], \\\n",
    "            \"num_layers should be 18, 34, 50, 100 or 152\"\n",
    "        assert mode in ['ir', 'ir_se'], \\\n",
    "            \"mode should be ir or ir_se\"\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64), PReLU(64))\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if num_layers <= 100:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BasicBlockIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BasicBlockIRSE\n",
    "            output_channel = 512\n",
    "        else:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BottleneckIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BottleneckIRSE\n",
    "            output_channel = 2048\n",
    "\n",
    "        if input_size[0] == 112:\n",
    "            self.output_layer = Sequential(BatchNorm2d(output_channel),\n",
    "                                        Dropout(0.4), Flatten(),\n",
    "                                        Linear(output_channel * 7 * 7, 512),\n",
    "                                        BatchNorm1d(512, affine=False))\n",
    "        else:\n",
    "            self.output_layer = Sequential(\n",
    "                BatchNorm2d(output_channel), Dropout(0.4), Flatten(),\n",
    "                Linear(output_channel * 14 * 14, 512),\n",
    "                BatchNorm1d(512, affine=False))\n",
    "\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel, bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "\n",
    "        initialize_weights(self.modules())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # current code only supports one extra image\n",
    "        # it comes with a extra dimension for number of extra image. We will just squeeze it out for now\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        for idx, module in enumerate(self.body):\n",
    "            x = module(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        norm = torch.norm(x, 2, 1, True)\n",
    "        output = torch.div(x, norm)\n",
    "\n",
    "        return output, norm\n",
    "\n",
    "\n",
    "\n",
    "def IR_18(input_size):\n",
    "    \"\"\" Constructs a ir-18 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 18, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_34(input_size):\n",
    "    \"\"\" Constructs a ir-34 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 34, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_50(input_size):\n",
    "    \"\"\" Constructs a ir-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_101(input_size):\n",
    "    \"\"\" Constructs a ir-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_152(input_size):\n",
    "    \"\"\" Constructs a ir-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_200(input_size):\n",
    "    \"\"\" Constructs a ir-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_50(input_size):\n",
    "    \"\"\" Constructs a ir_se-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_101(input_size):\n",
    "    \"\"\" Constructs a ir_se-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_152(input_size):\n",
    "    \"\"\" Constructs a ir_se-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_200(input_size):\n",
    "    \"\"\" Constructs a ir_se-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "adaface_models = {\n",
    "    'ir_18':\"/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaface_ir18_webface4m.ckpt\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_pretrained_model(architecture='ir_18'):\n",
    "    # load model and pretrained statedict\n",
    "    assert architecture in adaface_models.keys()\n",
    "    model = build_model(architecture)\n",
    "    statedict = torch.load(adaface_models[architecture])['state_dict']\n",
    "    model_statedict = {key[6:]:val for key, val in statedict.items() if key.startswith('model.')}\n",
    "    model.load_state_dict(model_statedict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def to_input(pil_rgb_image):\n",
    "    np_img = np.array(pil_rgb_image)\n",
    "    brg_img = ((np_img[:,:,::-1] / 255.) - 0.5) / 0.5\n",
    "    tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m adaFaceModel \u001b[39m=\u001b[39m load_pretrained_model(\u001b[39m'\u001b[39m\u001b[39mir_18\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m bgr_image \u001b[39m=\u001b[39m images[:, [\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m], :, :]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(bgr_image\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "adaFaceModel = load_pretrained_model('ir_18')\n",
    "\n",
    "print(images.shape)\n",
    "bgr_image = images[:, [2, 1, 0], :, :]\n",
    "print(bgr_image.shape)\n",
    "\n",
    "\n",
    "#feature, _ = adaFaceModel(bgr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m adaFaceModel\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i,data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(trainloader):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     inputs \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaFaceChicagoFaceBase.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m             \u001b[39m#inputs = inputs.type(torch.double)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "processedTensor = torch.zeros((len(train_dataset),512))\n",
    "#processedTensor = torch.zeros((len(train_dataloader.dataset),128))\n",
    "ageLabelTensor = torch.zeros((len(train_dataset)))\n",
    "genderLabelTensor = torch.zeros((len(train_dataset)))\n",
    "ethnLabelTensor = torch.zeros((len(train_dataset)))\n",
    "adaFaceModel.to(device)\n",
    "count = 0\n",
    "\n",
    "for i,data in enumerate(trainloader):\n",
    "    \n",
    "    inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "    age_label = data[1]['age'].to(device=device)\n",
    "    gender_label = data[1]['gender'].to(device=device)\n",
    "    ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "    #race_label = data[\"race\"].to(device=device)\n",
    "    #inputs = inputs.cpu().detach().numpy()\n",
    "    #inputs = np.transpose(inputs, (0, 2, 3, 1))\n",
    "    #print(inputs.shape)\n",
    "\n",
    "    inputs = inputs[:, [2, 1, 0], :, :]\n",
    "    embeddings,_ = adaFaceModel(inputs)\n",
    "  \n",
    "   \n",
    "\n",
    "    processedTensor[count:count+embeddings.shape[0]] = embeddings\n",
    "    ageLabelTensor[count:count+age_label.shape[0]] = age_label\n",
    "    genderLabelTensor[count:count+gender_label.shape[0]] = gender_label\n",
    "    ethnLabelTensor[count:count+ethn_label.shape[0]] = ethn_label\n",
    "\n",
    "    count = count + embeddings.shape[0]\n",
    "    \n",
    "    print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(processedTensor,\"adaFaceCfBaseInputs.pt\")\n",
    "torch.save(ageLabelTensor,\"adaFaceCfBaseAge.pt\")\n",
    "torch.save(genderLabelTensor,\"adaFaceCfBaseGender.pt\")\n",
    "torch.save(ethnLabelTensor,\"adaFaceCfBaseEthn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class faceAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1=nn.Sequential(nn.Linear(512,512),nn.Dropout(0.5),nn.ReLU(),nn.Linear(512,256))\n",
    "        \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "        self.layer2=nn.Linear(256,128)\n",
    "        #self.layer3=nn.Linear(1024,512)\n",
    "        self.layer4=nn.Linear(128,64)\n",
    "        self.dropout2=nn.Dropout(0.5)\n",
    "        self.genderOut=nn.Sequential(nn.Linear(64,32),nn.ReLU(),nn.Linear(32,2))\n",
    "        self.ageOut=nn.Linear(64,4)\n",
    "        self.ethnicityOut = nn.Linear(64,4)\n",
    "\n",
    "        # self.maxVal = 0\n",
    "        # self.min=0\n",
    "        \n",
    "    \n",
    "    def writeResult(self,result):\n",
    "       output_directory=\"\"\n",
    "       file_name = \"resultAge.txt\"\n",
    "\n",
    "       with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in result:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        #print(\"Input\",x[0])\n",
    "        x=self.layer1(x)\n",
    "        #x=nn.functional.tanh(x)\n",
    "        #print(x[0])\n",
    "        #x=nn.functional.relu(x)\n",
    "        #x=self.dropout1(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        x=self.layer2(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        #self.writeResult(x[0])\n",
    "       # x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        #print(torch.max(torch.abs(x)))\n",
    "        #x=nn.functional.relu(x)\n",
    "        \n",
    "        x=self.dropout2(x)\n",
    "        gender=self.genderOut(x)\n",
    "        #gender = nn.functional.relu(gender)\n",
    "        age=self.ageOut(x)\n",
    "\n",
    "        ethn = self.ethnicityOut(x)\n",
    "        #self.writeResult(age[0])\n",
    "        #print(gender)\n",
    "        return gender,age,ethn\n",
    "    \n",
    "    \n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False    \n",
    "    \n",
    "\n",
    "    def trainModel(self,trainloader,testloader,adaFace,device,episodes):\n",
    "        self.train()\n",
    "        #maxVal = 0\n",
    "        learningRate=0.005\n",
    "        gender_loss = nn.CrossEntropyLoss() \n",
    "        age_loss = nn.CrossEntropyLoss() \n",
    "        ethn_loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learningRate)\n",
    "        # optimizer = torch.optim.SGD(self.parameters(), lr=learningRate,\n",
    "        # momentum=0.9, weight_decay=5e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=episodes)\n",
    "        trainingAcc = []\n",
    "        for e in range(0,episodes):\n",
    "         total_training_loss =0\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         ageAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "    \n",
    "         batchSize = 256\n",
    "         \n",
    "        #  ageLabelTensor = ageLabelTensor.type(torch.LongTensor)\n",
    "        #  genderLabelTensor = genderLabelTensor.type(torch.LongTensor)\n",
    "        #  ethnLabelTensor = ethnLabelTensor.type(torch.LongTensor)\n",
    "\n",
    "        #  while(count<tempPT.shape[0]):\n",
    "        #     if(count+batchSize<=tempPT.shape[0]):\n",
    "        #      inputs = tempPT[count:count+batchSize].to(device=device)\n",
    "        #      age_label = ageLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      gender_label = genderLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      ethn_label = ethnLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #     else:\n",
    "        #        inputs = tempPT[count:].to(device=device)\n",
    "        #        age_label = ageLabelTensor[count:].to(device=device)\n",
    "        #        gender_label = genderLabelTensor[count:].to(device=device)\n",
    "        #        ethn_label = ethnLabelTensor[count:].to(device=device)\n",
    "           \n",
    "        #     gender,age,ethn = self(inputs)\n",
    "            # age=torch.squeeze(age)\n",
    "            # age=age.type(torch.float32)\n",
    "            #print(age.shape,age_label.shape)\n",
    "            #print(gender.shape,gender_label.shape)\n",
    "            # predictedGender = torch.argmax(gender,dim=1)\n",
    "            # predictedGender = predictedGender.type(torch.float32)\n",
    "            #print(gender)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "         for i,data in enumerate(trainloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "\n",
    "            ageLoss = age_loss(age,age_label)\n",
    "           \n",
    "            loss = 3*gender_loss(gender,gender_label) + ageLoss + 2*ethn_loss(ethn,ethn_label) \n",
    "            #print(gender)\n",
    "            #print(gender_label)\n",
    "            #totalGenderLoss = totalGenderLoss + loss.item()\n",
    "            loss.backward()\n",
    "            #print(\"Loss:\",loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #total_training_loss = total_training_loss+loss.item()*512\n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #print(predictedGender)\n",
    "            #print(gender_label)\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j].item()):\n",
    "                    genderAcc=genderAcc+1\n",
    "            \n",
    "                if(predictedEthn[j].item()==ethn_label[j].item()):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "  \n",
    "                if(predictedAge[j].item()==age_label[j].item()):\n",
    "                    ageAcc=ageAcc+1\n",
    "  \n",
    "         genderAccuracy =  genderAcc/count\n",
    "         trainingAcc.append(genderAccuracy)\n",
    "         print(\"Gender Accuracy:\", genderAccuracy,\"Age Acc:\", ageAcc/count, \" ethnAcc:\", ethnAcc/count)\n",
    "         #print(\"total training loss:\",total_training_loss/16595,\"\\n\")\n",
    "         #print(\"\\n\")\n",
    "         #scheduler.step()\n",
    "         #print(\"max observed value: \", maxVal)\n",
    "         if(e%2==0):\n",
    "          self.test(testloader,adaFace,device)\n",
    "             \n",
    "        return trainingAcc\n",
    "\n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def test(self,testloader,adaFace,device):\n",
    "\n",
    "         self.eval()\n",
    "         age_loss = nn.L1Loss()\n",
    "\n",
    "         totalAgeError = 0\n",
    "         genderAccuracy = 0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "         maxAge = 0\n",
    "         minAge = 0\n",
    "         ageAccuracy = 0\n",
    "         total_training_loss =0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         \n",
    "         batchSize = 128\n",
    "\n",
    "         for i,data in enumerate(testloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "         \n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #age = get_original_age_value(age)\n",
    "\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j]):\n",
    "                    genderAcc=genderAcc+1\n",
    "                if(predictedEthn[j].item()==ethn_label[j]):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "                if(predictedAge[j].item()==age_label[j]):\n",
    "                   ageAccuracy = ageAccuracy +1\n",
    "\n",
    "         genderAccuracy =  genderAcc/count\n",
    "         \n",
    "         print(\"Gender Accuracy:\", genderAccuracy,\"Age Accuracy:\", ageAccuracy/count, \" ethnAcc:\", ethnAcc/count)\n",
    "\n",
    "         return genderAccuracy,totalAgeError\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Accuracy: 0.5241090146750524 Age Acc: 0.7295597484276729  ethnAcc: 0.29559748427672955\n",
      "Gender Accuracy: 0.45 Age Accuracy: 0.85  ethnAcc: 0.26666666666666666\n",
      "Gender Accuracy: 0.4947589098532495 Age Acc: 0.8469601677148847  ethnAcc: 0.32914046121593293\n",
      "Gender Accuracy: 0.4716981132075472 Age Acc: 0.8469601677148847  ethnAcc: 0.350104821802935\n",
      "Gender Accuracy: 0.55 Age Accuracy: 0.85  ethnAcc: 0.475\n",
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.8469601677148847  ethnAcc: 0.35429769392033544\n",
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.8469601677148847  ethnAcc: 0.3689727463312369\n",
      "Gender Accuracy: 0.55 Age Accuracy: 0.85  ethnAcc: 0.35\n",
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.8469601677148847  ethnAcc: 0.44863731656184486\n",
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.8469601677148847  ethnAcc: 0.59958071278826\n",
      "Gender Accuracy: 0.5 Age Accuracy: 0.85  ethnAcc: 0.5333333333333333\n",
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.8469601677148847  ethnAcc: 0.59958071278826\n",
      "Gender Accuracy: 0.5660377358490566 Age Acc: 0.8469601677148847  ethnAcc: 0.5786163522012578\n",
      "Gender Accuracy: 0.5666666666666667 Age Accuracy: 0.85  ethnAcc: 0.55\n",
      "Gender Accuracy: 0.5870020964360587 Age Acc: 0.8469601677148847  ethnAcc: 0.6352201257861635\n",
      "Gender Accuracy: 0.7064989517819706 Age Acc: 0.8469601677148847  ethnAcc: 0.6477987421383647\n",
      "Gender Accuracy: 0.7 Age Accuracy: 0.85  ethnAcc: 0.5833333333333334\n",
      "Gender Accuracy: 0.7484276729559748 Age Acc: 0.8469601677148847  ethnAcc: 0.6289308176100629\n",
      "Gender Accuracy: 0.7672955974842768 Age Acc: 0.8469601677148847  ethnAcc: 0.6771488469601677\n",
      "Gender Accuracy: 0.7916666666666666 Age Accuracy: 0.85  ethnAcc: 0.575\n",
      "Gender Accuracy: 0.8113207547169812 Age Acc: 0.8469601677148847  ethnAcc: 0.6813417190775681\n",
      "Gender Accuracy: 0.8406708595387841 Age Acc: 0.8469601677148847  ethnAcc: 0.6960167714884696\n",
      "Gender Accuracy: 0.7916666666666666 Age Accuracy: 0.85  ethnAcc: 0.6\n"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model.to(device)\n",
    "adaFaceModel.to(device)\n",
    "adaFaceModel.eval()\n",
    "trainingAcc = model.trainModel(trainloader,testloader,adaFaceModel,device,15)\n",
    "#torch.save(model,\"bestFaceAn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35.3753],\n",
      "        [34.8900],\n",
      "        [35.9449],\n",
      "        [35.1217],\n",
      "        [35.7582],\n",
      "        [35.6678],\n",
      "        [35.2125],\n",
      "        [36.1453],\n",
      "        [35.4029],\n",
      "        [35.2653],\n",
      "        [35.0805],\n",
      "        [35.3967],\n",
      "        [35.5769],\n",
      "        [35.7067],\n",
      "        [35.9907],\n",
      "        [35.8430],\n",
      "        [35.9960],\n",
      "        [35.7801],\n",
      "        [36.0240],\n",
      "        [35.3092],\n",
      "        [34.7713],\n",
      "        [35.2087],\n",
      "        [35.2737],\n",
      "        [34.7884],\n",
      "        [34.8579],\n",
      "        [35.5894],\n",
      "        [35.0393],\n",
      "        [35.1824],\n",
      "        [35.2798],\n",
      "        [35.3226],\n",
      "        [34.7159],\n",
      "        [34.9689],\n",
      "        [34.7194],\n",
      "        [34.5731],\n",
      "        [35.1871],\n",
      "        [34.6003],\n",
      "        [35.5002],\n",
      "        [35.1668],\n",
      "        [35.6073],\n",
      "        [35.7567],\n",
      "        [35.5327],\n",
      "        [35.1987],\n",
      "        [35.2451],\n",
      "        [34.9374],\n",
      "        [35.2929],\n",
      "        [34.3929],\n",
      "        [34.5153],\n",
      "        [35.3669],\n",
      "        [34.5637],\n",
      "        [35.0643],\n",
      "        [34.7852],\n",
      "        [34.8137],\n",
      "        [35.1823],\n",
      "        [34.5501],\n",
      "        [34.4022],\n",
      "        [34.5978],\n",
      "        [34.9801],\n",
      "        [35.3785],\n",
      "        [35.3309],\n",
      "        [35.3094],\n",
      "        [34.4434],\n",
      "        [34.4440],\n",
      "        [34.7743],\n",
      "        [34.8726],\n",
      "        [34.4675],\n",
      "        [34.9710],\n",
      "        [34.8205],\n",
      "        [34.9515],\n",
      "        [34.4587],\n",
      "        [34.8638],\n",
      "        [34.6174],\n",
      "        [34.3467],\n",
      "        [35.1777],\n",
      "        [34.3238],\n",
      "        [34.5169],\n",
      "        [34.4216],\n",
      "        [35.1418],\n",
      "        [35.1291],\n",
      "        [35.2088],\n",
      "        [34.7792],\n",
      "        [35.4482],\n",
      "        [34.2262],\n",
      "        [34.2712],\n",
      "        [35.4014],\n",
      "        [34.4724],\n",
      "        [34.9141],\n",
      "        [34.9530],\n",
      "        [34.7307],\n",
      "        [34.6980],\n",
      "        [34.5458],\n",
      "        [34.8650],\n",
      "        [34.6202],\n",
      "        [34.5739],\n",
      "        [34.4134],\n",
      "        [34.8370],\n",
      "        [34.4672],\n",
      "        [34.4837],\n",
      "        [34.5230],\n",
      "        [34.4193],\n",
      "        [34.5315],\n",
      "        [34.7996],\n",
      "        [34.8419],\n",
      "        [34.9814],\n",
      "        [35.0938],\n",
      "        [35.5417],\n",
      "        [34.5715],\n",
      "        [35.0048],\n",
      "        [35.0402],\n",
      "        [34.8746],\n",
      "        [35.1177],\n",
      "        [35.2236],\n",
      "        [34.6062],\n",
      "        [35.1779],\n",
      "        [34.6547],\n",
      "        [35.3587],\n",
      "        [35.1580],\n",
      "        [34.9708],\n",
      "        [34.8810],\n",
      "        [34.9202],\n",
      "        [35.4713],\n",
      "        [36.2521],\n",
      "        [36.0412],\n",
      "        [35.8995],\n",
      "        [35.5841],\n",
      "        [35.5625],\n",
      "        [35.4475],\n",
      "        [35.7295],\n",
      "        [35.6512]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([36, 38, 33, 37, 43, 42, 37, 39, 40, 38, 38, 38, 36, 45, 34, 38, 45, 38,\n",
      "        41, 42, 41, 44, 44, 45, 46, 43, 49, 49, 40, 40, 46, 41, 48, 43, 44, 46,\n",
      "        44, 44, 49, 49, 36, 36, 36, 36, 36, 33, 27, 35, 32, 35, 31, 35, 36, 35,\n",
      "        35, 35, 33, 36, 32, 32, 28, 31, 28, 28, 28, 28, 28, 28, 31, 31, 26, 28,\n",
      "        29, 29, 28, 28, 28, 28, 28, 28, 44, 49, 44, 44, 41, 43, 45, 38, 44, 43,\n",
      "        30, 49, 49, 30, 37, 47, 41, 37, 35, 35, 47, 47, 42, 47, 42, 40, 40, 43,\n",
      "        42, 49, 47, 38, 45, 42, 44, 50, 40, 40, 40, 45, 34, 34, 34, 34, 30, 34,\n",
      "        41, 40], device='cuda:0')\n",
      "tensor([[35.5908],\n",
      "        [35.1970],\n",
      "        [35.3564],\n",
      "        [35.2313],\n",
      "        [35.9744],\n",
      "        [35.7748],\n",
      "        [35.1981],\n",
      "        [36.1145],\n",
      "        [36.2820],\n",
      "        [35.7477],\n",
      "        [35.3510],\n",
      "        [35.3646],\n",
      "        [35.6046],\n",
      "        [35.6847],\n",
      "        [35.8232],\n",
      "        [35.5912],\n",
      "        [34.7685],\n",
      "        [34.8064],\n",
      "        [35.9165],\n",
      "        [34.2044],\n",
      "        [35.8144],\n",
      "        [36.8804],\n",
      "        [36.2190],\n",
      "        [35.2708],\n",
      "        [35.4765],\n",
      "        [35.6900],\n",
      "        [35.3513],\n",
      "        [35.9896],\n",
      "        [35.9006],\n",
      "        [35.7300],\n",
      "        [35.5070],\n",
      "        [36.1814],\n",
      "        [34.5486],\n",
      "        [35.1370],\n",
      "        [34.6699],\n",
      "        [35.2049],\n",
      "        [34.6361],\n",
      "        [35.0357],\n",
      "        [35.3003],\n",
      "        [35.4785],\n",
      "        [35.2726],\n",
      "        [34.9821],\n",
      "        [35.6880],\n",
      "        [34.8993],\n",
      "        [35.1290],\n",
      "        [34.5569],\n",
      "        [34.6750],\n",
      "        [34.7631],\n",
      "        [34.8707],\n",
      "        [34.7044],\n",
      "        [34.7422],\n",
      "        [35.1428],\n",
      "        [33.8254],\n",
      "        [34.4819],\n",
      "        [34.1235],\n",
      "        [33.9784],\n",
      "        [33.8354],\n",
      "        [34.3219],\n",
      "        [34.0219],\n",
      "        [34.4072],\n",
      "        [34.0714],\n",
      "        [34.3921],\n",
      "        [33.9476],\n",
      "        [34.0390],\n",
      "        [34.0656],\n",
      "        [34.0163],\n",
      "        [34.3066],\n",
      "        [33.9083],\n",
      "        [34.2981],\n",
      "        [34.1271],\n",
      "        [34.1253],\n",
      "        [34.0908],\n",
      "        [35.3379],\n",
      "        [35.1753],\n",
      "        [35.6381],\n",
      "        [35.9315],\n",
      "        [35.7863],\n",
      "        [36.3072],\n",
      "        [35.1858],\n",
      "        [35.4719],\n",
      "        [35.2710],\n",
      "        [35.6580],\n",
      "        [35.3458],\n",
      "        [35.7561],\n",
      "        [35.7932],\n",
      "        [35.7866],\n",
      "        [35.7116],\n",
      "        [35.8126],\n",
      "        [35.0542],\n",
      "        [36.1936],\n",
      "        [36.0494],\n",
      "        [36.0367],\n",
      "        [34.2524],\n",
      "        [35.1225],\n",
      "        [34.8039],\n",
      "        [35.1657],\n",
      "        [34.8633],\n",
      "        [35.0094],\n",
      "        [35.0707],\n",
      "        [34.8928],\n",
      "        [34.5676],\n",
      "        [34.5746],\n",
      "        [34.8142],\n",
      "        [34.5922],\n",
      "        [34.8044],\n",
      "        [34.2854],\n",
      "        [35.7924],\n",
      "        [35.4193],\n",
      "        [35.4458],\n",
      "        [34.9607],\n",
      "        [35.2986],\n",
      "        [35.0042],\n",
      "        [35.7203],\n",
      "        [35.4764],\n",
      "        [35.4616],\n",
      "        [35.6453],\n",
      "        [35.5811],\n",
      "        [35.0138],\n",
      "        [35.1917],\n",
      "        [35.2128],\n",
      "        [35.4942],\n",
      "        [35.0316],\n",
      "        [35.3369],\n",
      "        [34.7188],\n",
      "        [35.2221],\n",
      "        [35.2316],\n",
      "        [35.3422],\n",
      "        [35.4883]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 31, 32, 31, 34, 34, 34, 34, 36, 40, 35, 38, 54, 45, 42, 52, 36, 39,\n",
      "        52, 46, 49, 49, 54, 52, 54, 56, 42, 47, 38, 50, 36, 52, 35, 44, 44, 37,\n",
      "        35, 39, 35, 42, 40, 43, 43, 44, 45, 38, 38, 44, 37, 44, 35, 40, 22, 20,\n",
      "        20, 14, 22, 24, 22, 20, 19, 24, 19, 21, 21, 18, 18, 18, 19, 19, 19, 20,\n",
      "        41, 41, 36, 38, 41, 41, 41, 41, 41, 31, 41, 44, 41, 41, 44, 44, 41, 45,\n",
      "        41, 42, 39, 44, 35, 51, 51, 35, 51, 47, 51, 45, 42, 42, 46, 46, 39, 39,\n",
      "        39, 39, 28, 46, 60, 57, 58, 57, 53, 61, 56, 53, 59, 44, 59, 61, 52, 62,\n",
      "        59, 52], device='cuda:0')\n",
      "tensor([[35.6716],\n",
      "        [35.1297],\n",
      "        [35.2232],\n",
      "        [35.1773],\n",
      "        [35.1076],\n",
      "        [35.1033],\n",
      "        [35.6510],\n",
      "        [35.0427],\n",
      "        [34.9387],\n",
      "        [35.1592],\n",
      "        [35.3419],\n",
      "        [34.7959],\n",
      "        [35.3542],\n",
      "        [34.9941],\n",
      "        [35.3323],\n",
      "        [35.0026],\n",
      "        [34.7597],\n",
      "        [35.2275],\n",
      "        [35.2417],\n",
      "        [35.3213],\n",
      "        [34.7919],\n",
      "        [35.3347],\n",
      "        [35.7698],\n",
      "        [34.9955],\n",
      "        [35.7109],\n",
      "        [36.2404],\n",
      "        [35.3818],\n",
      "        [35.6378],\n",
      "        [36.6203],\n",
      "        [35.9013],\n",
      "        [35.7063],\n",
      "        [35.7928],\n",
      "        [36.1944],\n",
      "        [35.6834],\n",
      "        [35.9556],\n",
      "        [35.6982],\n",
      "        [35.9141],\n",
      "        [36.0318],\n",
      "        [35.7683],\n",
      "        [35.9707],\n",
      "        [36.1653],\n",
      "        [36.0832],\n",
      "        [35.9055],\n",
      "        [35.8411],\n",
      "        [35.1547],\n",
      "        [34.9846],\n",
      "        [35.2182],\n",
      "        [35.1227],\n",
      "        [34.6151],\n",
      "        [34.9115],\n",
      "        [35.2904],\n",
      "        [35.2560],\n",
      "        [35.1627],\n",
      "        [34.8735],\n",
      "        [34.8523],\n",
      "        [35.1542],\n",
      "        [34.9391],\n",
      "        [35.1873],\n",
      "        [34.8206],\n",
      "        [35.0930],\n",
      "        [35.1345],\n",
      "        [35.3721],\n",
      "        [35.0396],\n",
      "        [35.3457],\n",
      "        [34.7716],\n",
      "        [35.7270],\n",
      "        [35.2169],\n",
      "        [35.9665],\n",
      "        [36.0495],\n",
      "        [34.8878],\n",
      "        [35.5672],\n",
      "        [36.0367],\n",
      "        [35.5373],\n",
      "        [35.8219],\n",
      "        [35.0303],\n",
      "        [35.9436],\n",
      "        [35.4115],\n",
      "        [36.1393],\n",
      "        [35.8877],\n",
      "        [36.1495],\n",
      "        [35.6376],\n",
      "        [35.1883],\n",
      "        [34.7152],\n",
      "        [35.1076],\n",
      "        [35.1417],\n",
      "        [34.4864],\n",
      "        [34.5122],\n",
      "        [34.9478],\n",
      "        [34.3896],\n",
      "        [34.9186],\n",
      "        [34.4826],\n",
      "        [34.9237],\n",
      "        [34.8632],\n",
      "        [34.8885],\n",
      "        [34.6944],\n",
      "        [34.5077],\n",
      "        [34.9331],\n",
      "        [34.4756],\n",
      "        [34.7049],\n",
      "        [34.6700],\n",
      "        [34.1618],\n",
      "        [34.8048],\n",
      "        [34.9063],\n",
      "        [34.8158],\n",
      "        [36.1041],\n",
      "        [35.1679],\n",
      "        [35.6690],\n",
      "        [35.5321],\n",
      "        [34.9810],\n",
      "        [35.6375],\n",
      "        [34.8390],\n",
      "        [35.8340],\n",
      "        [34.5673],\n",
      "        [35.5223],\n",
      "        [35.6042],\n",
      "        [35.3888],\n",
      "        [35.3246],\n",
      "        [35.2683],\n",
      "        [34.5957],\n",
      "        [34.9024],\n",
      "        [35.5123],\n",
      "        [34.8012],\n",
      "        [35.4647],\n",
      "        [35.6990],\n",
      "        [35.3785],\n",
      "        [34.9155],\n",
      "        [35.1936],\n",
      "        [35.6639]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([57, 57, 44, 63, 27, 35, 37, 32, 36, 32, 33, 32, 36, 29, 29, 31, 31, 29,\n",
      "        35, 33, 31, 32, 32, 38, 37, 37, 37, 37, 37, 43, 37, 37, 37, 43, 37, 37,\n",
      "        37, 37, 37, 38, 37, 37, 37, 37, 37, 38, 42, 41, 38, 42, 31, 41, 41, 31,\n",
      "        31, 38, 31, 38, 38, 38, 36, 38, 38, 38, 51, 35, 38, 46, 46, 38, 46, 38,\n",
      "        51, 44, 38, 35, 51, 37, 44, 37, 38, 38, 51, 38, 31, 27, 31, 31, 22, 27,\n",
      "        31, 27, 31, 31, 31, 31, 24, 27, 27, 31, 31, 28, 31, 31, 41, 41, 41, 41,\n",
      "        47, 39, 41, 45, 41, 46, 42, 42, 42, 38, 42, 36, 36, 38, 41, 45, 52, 45,\n",
      "        35, 43], device='cuda:0')\n",
      "tensor([[35.4795],\n",
      "        [35.6666],\n",
      "        [35.8893],\n",
      "        [35.2787],\n",
      "        [34.9508],\n",
      "        [35.3670],\n",
      "        [35.3751],\n",
      "        [35.6291],\n",
      "        [35.4762],\n",
      "        [35.4837],\n",
      "        [35.5142],\n",
      "        [35.0019],\n",
      "        [35.2089],\n",
      "        [35.2128],\n",
      "        [35.4845],\n",
      "        [35.2642],\n",
      "        [35.1375],\n",
      "        [34.4778],\n",
      "        [35.0244],\n",
      "        [34.9095],\n",
      "        [35.0418],\n",
      "        [34.5147],\n",
      "        [34.7461],\n",
      "        [35.0369],\n",
      "        [35.2373],\n",
      "        [34.9923],\n",
      "        [35.0513],\n",
      "        [34.9557],\n",
      "        [35.0776],\n",
      "        [34.6016],\n",
      "        [35.1065],\n",
      "        [34.4345],\n",
      "        [35.0290],\n",
      "        [35.2665],\n",
      "        [34.9426],\n",
      "        [35.1003],\n",
      "        [35.6985],\n",
      "        [36.5956],\n",
      "        [35.7663],\n",
      "        [35.1041],\n",
      "        [36.1409],\n",
      "        [36.7595],\n",
      "        [36.1990],\n",
      "        [35.7948],\n",
      "        [36.0171],\n",
      "        [35.8555],\n",
      "        [36.3284],\n",
      "        [36.0309],\n",
      "        [34.9465],\n",
      "        [35.8947],\n",
      "        [36.5779],\n",
      "        [35.6974],\n",
      "        [36.4422],\n",
      "        [36.1278],\n",
      "        [36.1386],\n",
      "        [36.3792],\n",
      "        [35.3477],\n",
      "        [35.1244],\n",
      "        [35.1181],\n",
      "        [34.7718],\n",
      "        [34.9308],\n",
      "        [35.5438],\n",
      "        [35.1727],\n",
      "        [35.4193],\n",
      "        [34.7622],\n",
      "        [35.1816],\n",
      "        [35.2385],\n",
      "        [35.5055],\n",
      "        [35.1696],\n",
      "        [35.1384],\n",
      "        [35.3725],\n",
      "        [35.9272],\n",
      "        [35.8556],\n",
      "        [35.0302],\n",
      "        [35.1732],\n",
      "        [35.1763],\n",
      "        [35.1862],\n",
      "        [34.4615],\n",
      "        [34.9141],\n",
      "        [34.7764],\n",
      "        [34.9442],\n",
      "        [35.0660],\n",
      "        [34.9732],\n",
      "        [35.4361],\n",
      "        [34.6876],\n",
      "        [35.0154],\n",
      "        [34.7629],\n",
      "        [34.8500],\n",
      "        [35.0277],\n",
      "        [34.9580],\n",
      "        [34.8705],\n",
      "        [34.8615],\n",
      "        [34.8021],\n",
      "        [35.4124],\n",
      "        [34.7570],\n",
      "        [34.8142],\n",
      "        [35.4418],\n",
      "        [35.7955],\n",
      "        [35.1213],\n",
      "        [35.4149],\n",
      "        [35.1159],\n",
      "        [35.6329],\n",
      "        [35.2507],\n",
      "        [34.4524],\n",
      "        [35.2479],\n",
      "        [35.4540],\n",
      "        [35.8907],\n",
      "        [34.9457],\n",
      "        [35.1632],\n",
      "        [35.8660],\n",
      "        [36.0482],\n",
      "        [34.5688],\n",
      "        [35.3720],\n",
      "        [35.1416],\n",
      "        [35.3966],\n",
      "        [35.2632],\n",
      "        [35.6064],\n",
      "        [35.2045],\n",
      "        [35.2445],\n",
      "        [36.0054],\n",
      "        [35.7060],\n",
      "        [35.4776],\n",
      "        [35.4532],\n",
      "        [35.9189],\n",
      "        [35.4298],\n",
      "        [36.0614],\n",
      "        [36.2864],\n",
      "        [35.8412]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([48, 49, 22, 48, 47, 35, 51, 49, 40, 48, 48, 23, 39, 48, 39, 52, 64, 64,\n",
      "        64, 69, 38, 65, 66, 69, 71, 69, 69, 62, 64, 66, 61, 67, 40, 58, 56, 63,\n",
      "        33, 42, 42, 38, 38, 38, 36, 42, 42, 38, 41, 42, 32, 35, 36, 21, 29, 21,\n",
      "        36, 37, 22, 25, 25, 15, 25, 25, 31, 31, 27, 27, 31, 18, 24, 25, 29, 25,\n",
      "        25, 25, 22, 22, 54, 48, 54, 48, 45, 54, 50, 40, 49, 51, 54, 42, 54, 52,\n",
      "        54, 45, 45, 45, 43, 45, 40, 31, 39, 53, 58, 31, 40, 40, 40, 42, 39, 57,\n",
      "        52, 40, 40, 36, 50, 58, 39, 52, 23, 24, 23, 23, 23, 23, 19, 23, 23, 23,\n",
      "        23, 23], device='cuda:0')\n",
      "tensor([[35.6144],\n",
      "        [35.2893],\n",
      "        [35.6544],\n",
      "        [35.3373],\n",
      "        [34.5653],\n",
      "        [35.4691],\n",
      "        [35.2060],\n",
      "        [35.3587],\n",
      "        [34.9862],\n",
      "        [34.8001],\n",
      "        [34.8143],\n",
      "        [35.3639],\n",
      "        [34.8885],\n",
      "        [35.0373],\n",
      "        [34.9672],\n",
      "        [34.4939],\n",
      "        [35.2780],\n",
      "        [35.0649],\n",
      "        [34.7581],\n",
      "        [34.7647],\n",
      "        [35.2495],\n",
      "        [35.1054],\n",
      "        [34.7663],\n",
      "        [34.7225],\n",
      "        [35.5914],\n",
      "        [34.9022],\n",
      "        [34.6351],\n",
      "        [35.1620],\n",
      "        [35.1612],\n",
      "        [35.0974],\n",
      "        [35.1613],\n",
      "        [35.2439],\n",
      "        [35.1459],\n",
      "        [35.8126],\n",
      "        [35.4711],\n",
      "        [35.1724],\n",
      "        [35.1280],\n",
      "        [35.2822],\n",
      "        [35.5129],\n",
      "        [35.3774],\n",
      "        [35.6354],\n",
      "        [35.0499],\n",
      "        [35.1217],\n",
      "        [34.7722],\n",
      "        [34.9898],\n",
      "        [35.3910],\n",
      "        [35.1966],\n",
      "        [35.5621],\n",
      "        [35.0921],\n",
      "        [34.7162],\n",
      "        [35.5062],\n",
      "        [35.4526],\n",
      "        [35.3123],\n",
      "        [35.0316],\n",
      "        [34.5430],\n",
      "        [35.0080],\n",
      "        [35.7929],\n",
      "        [35.3753],\n",
      "        [35.0895],\n",
      "        [35.4575],\n",
      "        [35.1117],\n",
      "        [35.0628],\n",
      "        [35.0176],\n",
      "        [35.1503],\n",
      "        [34.6163],\n",
      "        [35.5882],\n",
      "        [35.2155],\n",
      "        [35.4436],\n",
      "        [34.4796],\n",
      "        [35.0091],\n",
      "        [34.6105],\n",
      "        [34.4541],\n",
      "        [34.5933],\n",
      "        [35.1123],\n",
      "        [34.8238],\n",
      "        [34.6670],\n",
      "        [34.5692],\n",
      "        [35.5169],\n",
      "        [35.4058],\n",
      "        [34.8378],\n",
      "        [34.2255],\n",
      "        [34.2950],\n",
      "        [34.9130],\n",
      "        [34.5225],\n",
      "        [34.3320],\n",
      "        [35.0717],\n",
      "        [34.6032],\n",
      "        [34.8387],\n",
      "        [35.3734],\n",
      "        [35.7447],\n",
      "        [35.2935],\n",
      "        [35.3257],\n",
      "        [35.5311],\n",
      "        [35.6017],\n",
      "        [35.9415],\n",
      "        [35.4047],\n",
      "        [35.2737],\n",
      "        [35.6353],\n",
      "        [35.8708],\n",
      "        [35.2433],\n",
      "        [35.6270],\n",
      "        [35.3618],\n",
      "        [36.2034],\n",
      "        [35.0211],\n",
      "        [35.1217],\n",
      "        [35.4628],\n",
      "        [35.2553],\n",
      "        [36.0134],\n",
      "        [34.5506],\n",
      "        [34.5815],\n",
      "        [34.7117],\n",
      "        [34.2520],\n",
      "        [34.3769],\n",
      "        [34.5910],\n",
      "        [34.5354],\n",
      "        [34.6707],\n",
      "        [34.2979],\n",
      "        [34.4241],\n",
      "        [34.6106],\n",
      "        [34.4812],\n",
      "        [35.0758],\n",
      "        [34.7206],\n",
      "        [34.7231],\n",
      "        [34.4175],\n",
      "        [34.4378],\n",
      "        [34.5189],\n",
      "        [34.3755],\n",
      "        [34.4504]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([25, 23, 23, 23, 23, 23, 23, 24, 35, 39, 37, 37, 35, 35, 35, 40, 35, 35,\n",
      "        35, 40, 35, 35, 35, 35, 39, 35, 35, 44, 46, 46, 41, 46, 45, 47, 41, 41,\n",
      "        45, 48, 25, 51, 45, 46, 25, 41, 47, 42, 46, 43, 51, 51, 51, 42, 51, 44,\n",
      "        51, 40, 49, 47, 46, 49, 44, 44, 45, 47, 40, 40, 46, 46, 36, 28, 36, 35,\n",
      "        33, 30, 39, 32, 39, 32, 29, 30, 35, 35, 35, 35, 29, 39, 36, 36, 41, 41,\n",
      "        35, 35, 30, 33, 33, 37, 37, 31, 39, 34, 31, 40, 43, 32, 32, 43, 40, 43,\n",
      "        31, 36, 28, 28, 28, 26, 26, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28], device='cuda:0')\n",
      "tensor([[34.9354],\n",
      "        [35.5847],\n",
      "        [35.0843],\n",
      "        [34.5578],\n",
      "        [35.3019],\n",
      "        [34.8993],\n",
      "        [34.9238],\n",
      "        [34.8123],\n",
      "        [34.5559],\n",
      "        [34.9041],\n",
      "        [34.7236],\n",
      "        [35.2706],\n",
      "        [34.7996],\n",
      "        [35.0668],\n",
      "        [35.5628],\n",
      "        [35.0146],\n",
      "        [34.9071],\n",
      "        [34.8801],\n",
      "        [34.8271],\n",
      "        [35.1872],\n",
      "        [34.5878],\n",
      "        [34.5235],\n",
      "        [34.2992],\n",
      "        [34.6512],\n",
      "        [34.6249],\n",
      "        [34.5212],\n",
      "        [34.1500],\n",
      "        [34.7980],\n",
      "        [34.6923],\n",
      "        [34.3243],\n",
      "        [34.2346],\n",
      "        [34.2828],\n",
      "        [34.2228],\n",
      "        [34.3608],\n",
      "        [34.6858],\n",
      "        [34.3873],\n",
      "        [34.5244],\n",
      "        [34.4514],\n",
      "        [34.3453],\n",
      "        [34.7674],\n",
      "        [35.8849],\n",
      "        [36.0618],\n",
      "        [35.7256],\n",
      "        [35.5733],\n",
      "        [34.8199],\n",
      "        [35.4566],\n",
      "        [35.6569],\n",
      "        [35.0206],\n",
      "        [35.8021],\n",
      "        [34.9743],\n",
      "        [35.2409],\n",
      "        [35.9429],\n",
      "        [35.8933],\n",
      "        [36.0441],\n",
      "        [36.1695],\n",
      "        [35.5283],\n",
      "        [35.4363],\n",
      "        [35.6680],\n",
      "        [35.5766],\n",
      "        [34.8636],\n",
      "        [35.9381],\n",
      "        [35.0391],\n",
      "        [35.8069],\n",
      "        [35.3174],\n",
      "        [34.8805],\n",
      "        [34.3396],\n",
      "        [35.9616],\n",
      "        [35.0980],\n",
      "        [35.0979],\n",
      "        [34.9715],\n",
      "        [34.7473],\n",
      "        [35.1693],\n",
      "        [35.4876],\n",
      "        [35.0187],\n",
      "        [35.3090],\n",
      "        [35.4881],\n",
      "        [35.2279],\n",
      "        [35.0522],\n",
      "        [34.6560],\n",
      "        [35.0230],\n",
      "        [34.8411],\n",
      "        [35.5551],\n",
      "        [35.2293],\n",
      "        [35.2838],\n",
      "        [35.3332],\n",
      "        [34.4285],\n",
      "        [34.9231],\n",
      "        [34.8155],\n",
      "        [34.7130],\n",
      "        [35.2222],\n",
      "        [34.9147],\n",
      "        [34.6843],\n",
      "        [34.9610],\n",
      "        [34.2048],\n",
      "        [35.3861],\n",
      "        [34.9440],\n",
      "        [35.3340],\n",
      "        [34.9076],\n",
      "        [35.4352],\n",
      "        [34.6392],\n",
      "        [35.1992],\n",
      "        [35.5547],\n",
      "        [35.4188],\n",
      "        [35.5040],\n",
      "        [35.2623],\n",
      "        [35.2231],\n",
      "        [35.3551],\n",
      "        [34.2089],\n",
      "        [36.1320],\n",
      "        [35.1604],\n",
      "        [35.0429],\n",
      "        [35.4114],\n",
      "        [35.7380],\n",
      "        [35.4845],\n",
      "        [34.9338],\n",
      "        [34.5837],\n",
      "        [35.4295],\n",
      "        [36.0695],\n",
      "        [34.4804],\n",
      "        [36.1543],\n",
      "        [35.3321],\n",
      "        [35.1507],\n",
      "        [35.1774],\n",
      "        [34.8528],\n",
      "        [35.0173],\n",
      "        [35.2683],\n",
      "        [34.9862],\n",
      "        [35.0621]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 26, 31, 34, 26, 25, 33, 33, 33, 25, 33, 27, 35, 31, 26, 30, 23, 34,\n",
      "        35, 31, 28, 21, 24, 21, 21, 21, 24, 24, 26, 21, 21, 21, 21, 21, 26, 21,\n",
      "        21, 21, 21, 24, 30, 30, 30, 30, 30, 31, 30, 33, 27, 28, 28, 34, 30, 30,\n",
      "        30, 28, 33, 27, 33, 38, 47, 47, 47, 36, 36, 41, 47, 46, 47, 48, 41, 47,\n",
      "        52, 31, 38, 46, 48, 38, 27, 46, 46, 49, 45, 41, 43, 43, 43, 43, 43, 41,\n",
      "        43, 41, 43, 40, 37, 43, 51, 43, 49, 49, 30, 30, 30, 30, 30, 30, 30, 24,\n",
      "        17, 30, 30, 30, 30, 28, 24, 32, 27, 32, 24, 27, 57, 52, 52, 59, 49, 46,\n",
      "        46, 55], device='cuda:0')\n",
      "tensor([[35.5787],\n",
      "        [35.3184],\n",
      "        [34.7838],\n",
      "        [35.3138],\n",
      "        [36.2333],\n",
      "        [35.3760],\n",
      "        [34.7017],\n",
      "        [34.7551],\n",
      "        [35.1854],\n",
      "        [35.1167],\n",
      "        [34.8667],\n",
      "        [35.5446],\n",
      "        [35.0842],\n",
      "        [35.0810],\n",
      "        [34.9591],\n",
      "        [34.9136],\n",
      "        [35.4882],\n",
      "        [34.9892],\n",
      "        [35.3778],\n",
      "        [35.0248],\n",
      "        [34.9740],\n",
      "        [35.5236],\n",
      "        [35.3771],\n",
      "        [35.2655],\n",
      "        [34.8318],\n",
      "        [35.1147],\n",
      "        [35.0397],\n",
      "        [35.2705],\n",
      "        [35.2720],\n",
      "        [35.3148],\n",
      "        [34.9709],\n",
      "        [34.7626],\n",
      "        [35.1236],\n",
      "        [35.9690],\n",
      "        [35.8185],\n",
      "        [35.1855],\n",
      "        [36.0162],\n",
      "        [36.3036],\n",
      "        [35.4538],\n",
      "        [35.8881],\n",
      "        [36.2321],\n",
      "        [35.7489],\n",
      "        [35.6275],\n",
      "        [35.9719],\n",
      "        [35.5694],\n",
      "        [35.5413],\n",
      "        [35.3599],\n",
      "        [35.3126],\n",
      "        [35.7186],\n",
      "        [35.4608],\n",
      "        [35.7050],\n",
      "        [35.6522],\n",
      "        [34.6701],\n",
      "        [34.5933],\n",
      "        [34.9761],\n",
      "        [34.5039],\n",
      "        [35.2864],\n",
      "        [34.8144],\n",
      "        [34.5630],\n",
      "        [34.6471],\n",
      "        [34.5796],\n",
      "        [34.2417],\n",
      "        [34.8353],\n",
      "        [34.8033],\n",
      "        [34.2711],\n",
      "        [34.9276],\n",
      "        [34.9628],\n",
      "        [34.3316],\n",
      "        [35.5308],\n",
      "        [34.3840],\n",
      "        [34.8614],\n",
      "        [34.6373],\n",
      "        [36.0299],\n",
      "        [35.9143],\n",
      "        [36.2348],\n",
      "        [35.9186],\n",
      "        [35.7079],\n",
      "        [36.2644],\n",
      "        [35.8824],\n",
      "        [35.8047],\n",
      "        [36.1476],\n",
      "        [35.8653],\n",
      "        [36.0065],\n",
      "        [36.1544],\n",
      "        [36.3721],\n",
      "        [35.6363],\n",
      "        [35.2340],\n",
      "        [36.0789],\n",
      "        [36.0321],\n",
      "        [35.6410],\n",
      "        [35.7115],\n",
      "        [35.1184],\n",
      "        [35.3790],\n",
      "        [35.2813],\n",
      "        [35.4760],\n",
      "        [34.9338],\n",
      "        [34.6445],\n",
      "        [34.7922],\n",
      "        [34.9295],\n",
      "        [35.0089],\n",
      "        [34.8993],\n",
      "        [35.1170],\n",
      "        [34.7012],\n",
      "        [34.6902],\n",
      "        [35.1757],\n",
      "        [34.9937],\n",
      "        [34.9860],\n",
      "        [34.8467],\n",
      "        [35.3488],\n",
      "        [35.0205],\n",
      "        [34.9816],\n",
      "        [34.7718],\n",
      "        [35.5287],\n",
      "        [35.3159],\n",
      "        [34.8780],\n",
      "        [35.1130],\n",
      "        [35.2618],\n",
      "        [35.2182],\n",
      "        [35.4153],\n",
      "        [35.5620],\n",
      "        [35.5765],\n",
      "        [34.6176],\n",
      "        [35.1192],\n",
      "        [35.1904],\n",
      "        [35.6753],\n",
      "        [34.8183],\n",
      "        [34.5606],\n",
      "        [35.4210]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([47, 45, 52, 59, 48, 55, 55, 59, 59, 51, 51, 45, 40, 32, 29, 41, 41, 36,\n",
      "        36,  3, 32, 42, 32, 40, 39, 32, 16, 40, 40, 40, 16, 38, 55, 52, 66, 52,\n",
      "        76, 67, 70, 68, 65, 60, 60, 70, 70, 70, 68, 77, 68, 68, 68, 66, 29, 29,\n",
      "        36, 29, 35, 29, 24, 35, 29, 29, 27, 32, 29, 32, 28, 33, 32, 29, 36, 39,\n",
      "        34, 34, 36, 36, 36, 36, 42, 36, 36, 36, 36, 36, 38, 36, 31, 36, 29, 29,\n",
      "        36, 29, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 40, 36, 36,\n",
      "        36, 36, 33, 35, 20, 20, 21, 24, 19, 19, 19, 21, 24, 24, 19, 19, 19, 20,\n",
      "        24, 19], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtest(testloader,arcFaceModel,device)\n",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=191'>192</a>\u001b[0m predictedEthn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(ethn,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m age \u001b[39m=\u001b[39m get_original_age_value(age)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m \u001b[39mprint\u001b[39;49m(age)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mprint\u001b[39m(age_label)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,predictedGender\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[1;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.test(testloader,arcFaceModel,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"arcFaceCelebSetBase.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"negGenderBaseWiki.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ccd692eb0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model92.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "input1=[]\n",
    "for i,data in enumerate(val_dataloader):\n",
    "    \n",
    "    if(count==0):\n",
    "     inputs=resnet(data[\"image\"].to(device))\n",
    "\n",
    " \n",
    "     input1 = polyprotect(0,inputs[0])\n",
    "\n",
    "     break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "tensor([-0.0765, -0.1069, -0.0411,  0.0238,  0.0118,  0.0784, -0.0193, -0.0194,\n",
      "        -0.0132,  0.0487,  0.0409, -0.0441, -0.1003,  0.0050,  0.0179,  0.0378,\n",
      "        -0.0322,  0.0842, -0.0395, -0.0201,  0.0457, -0.0654, -0.0586,  0.0188,\n",
      "        -0.0772,  0.0069,  0.0861, -0.0244,  0.0486, -0.0309, -0.0071,  0.0655,\n",
      "        -0.1047,  0.0400,  0.0215, -0.0451,  0.0729, -0.0582, -0.0285,  0.0711,\n",
      "        -0.0588, -0.0468, -0.0742, -0.0929,  0.0281,  0.0036, -0.0665, -0.0713,\n",
      "        -0.0775,  0.0966,  0.0213,  0.0536, -0.0497, -0.0261,  0.0736, -0.0707,\n",
      "        -0.0635,  0.0039,  0.0356,  0.0208, -0.0432,  0.0132,  0.0090, -0.0508,\n",
      "         0.0649, -0.0474,  0.0852,  0.0400,  0.0783,  0.0792, -0.0682, -0.0400,\n",
      "         0.0074, -0.0067,  0.0327,  0.0179, -0.0077, -0.0110,  0.0008,  0.0626,\n",
      "         0.0268, -0.0395, -0.0766,  0.0686, -0.0601,  0.0466,  0.0655,  0.0477,\n",
      "        -0.0761,  0.0306,  0.0702, -0.0810,  0.0598,  0.0180, -0.0715, -0.0503,\n",
      "        -0.0228, -0.0253,  0.0304, -0.0354, -0.0314, -0.0703, -0.0203,  0.0615,\n",
      "         0.0830,  0.0707,  0.0716, -0.0595, -0.0409, -0.0479, -0.0437,  0.0757,\n",
      "        -0.0215, -0.0659,  0.0782, -0.0438,  0.0741, -0.1035, -0.0170,  0.0418,\n",
      "         0.0713, -0.0575,  0.0096, -0.0349, -0.0885,  0.0735,  0.0153, -0.0870],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2496, device='cuda:0', grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    print(param[0])\n",
    "    print(torch.dot(input1,param[1]))\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"input1.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in input1:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ageAccuracy:  0.638671875\n",
      "ageAccuracy:  0.62109375\n",
      "ageAccuracy:  0.6087239583333334\n",
      "ageAccuracy:  0.6162109375\n",
      "ageAccuracy:  0.626953125\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.62890625\n",
      "ageAccuracy:  0.628662109375\n",
      "ageAccuracy:  0.6271701388888888\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.6296164772727273\n",
      "ageAccuracy:  0.6300455729166666\n",
      "ageAccuracy:  0.6275540865384616\n",
      "ageAccuracy:  0.6256975446428571\n",
      "ageAccuracy:  0.62578125\n",
      "ageAccuracy:  0.627197265625\n",
      "ageAccuracy:  0.6246553308823529\n",
      "ageAccuracy:  0.6252170138888888\n",
      "ageAccuracy:  0.6258223684210527\n",
      "ageAccuracy:  0.62392578125\n",
      "ageAccuracy:  0.6255580357142857\n",
      "ageAccuracy:  0.6242009943181818\n",
      "ageAccuracy:  0.6240658967391305\n",
      "ageAccuracy:  0.624267578125\n",
      "ageAccuracy:  0.6246875\n",
      "ageAccuracy:  0.6246995192307693\n",
      "ageAccuracy:  0.6237702546296297\n",
      "ageAccuracy:  0.6241629464285714\n",
      "ageAccuracy:  0.6245285560344828\n",
      "ageAccuracy:  0.6251953125\n",
      "ageAccuracy:  0.6246219758064516\n",
      "ageAccuracy:  0.62457275390625\n",
      "ageAccuracy:  0.6244081439393939\n",
      "ageAccuracy:  0.6249425551470589\n",
      "ageAccuracy:  0.6246651785714286\n",
      "ageAccuracy:  0.6248372395833334\n",
      "ageAccuracy:  0.6230996621621622\n",
      "ageAccuracy:  0.6235608552631579\n",
      "ageAccuracy:  0.6234475160256411\n",
      "ageAccuracy:  0.62275390625\n",
      "ageAccuracy:  0.6228563262195121\n",
      "ageAccuracy:  0.6216982886904762\n",
      "ageAccuracy:  0.6209574854651163\n",
      "ageAccuracy:  0.6209161931818182\n",
      "ageAccuracy:  0.6213541666666667\n",
      "ageAccuracy:  0.621475883152174\n",
      "ageAccuracy:  0.6214261968085106\n",
      "ageAccuracy:  0.62158203125\n",
      "ageAccuracy:  0.6218510841836735\n",
      "ageAccuracy:  0.6220703125\n",
      "ageAccuracy:  0.6222043504901961\n",
      "ageAccuracy:  0.6222581129807693\n",
      "ageAccuracy:  0.6218676297169812\n",
      "ageAccuracy:  0.6221426504629629\n",
      "ageAccuracy:  0.6223011363636364\n",
      "ageAccuracy:  0.6221400669642857\n",
      "ageAccuracy:  0.621813322368421\n",
      "ageAccuracy:  0.6223060344827587\n",
      "ageAccuracy:  0.6223847987288136\n",
      "ageAccuracy:  0.6228515625\n",
      "ageAccuracy:  0.6227587090163934\n",
      "ageAccuracy:  0.6231098790322581\n",
      "ageAccuracy:  0.6231398809523809\n",
      "ageAccuracy:  0.623321533203125\n",
      "ageAccuracy:  0.6232572115384616\n",
      "ageAccuracy:  0.6234907670454546\n",
      "ageAccuracy:  0.6238922574626866\n",
      "ageAccuracy:  0.6239372702205882\n",
      "ageAccuracy:  0.6240942028985508\n",
      "ageAccuracy:  0.6241908482142857\n",
      "ageAccuracy:  0.6242572623239436\n",
      "ageAccuracy:  0.6239691840277778\n",
      "ageAccuracy:  0.6239030393835616\n",
      "ageAccuracy:  0.6237595016891891\n",
      "ageAccuracy:  0.62421875\n",
      "ageAccuracy:  0.624254728618421\n",
      "ageAccuracy:  0.624416599025974\n",
      "ageAccuracy:  0.624198717948718\n",
      "ageAccuracy:  0.6240302367217028\n",
      "Test Gender Accuracy: 0.9118510045752934 \n",
      "\n",
      "Test Age Accuracy: 0.6240302367217028 \n",
      "\n",
      "Test Age Loss: 0.313527571161588 \n",
      "\n",
      "\n",
      "\n",
      "Max 0\n",
      "Min 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9118510045752934, 4815.783493041992)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/modelUsing0.pt\")\n",
    "model.to(device)\n",
    "model.test(dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"modelUsing0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-0.0608, -0.0217,  0.0529, -0.0089,  0.0091,  0.0046, -0.0850,  0.0737,\n",
      "         0.0143,  0.0217, -0.0977,  0.0810, -0.0564,  0.0011,  0.0722, -0.0247,\n",
      "         0.0400, -0.0504, -0.0266,  0.0041,  0.0306, -0.0060, -0.0088, -0.0187,\n",
      "         0.0724, -0.0828, -0.0848, -0.0345, -0.0290,  0.0105,  0.0145, -0.0039,\n",
      "        -0.0052, -0.0191,  0.0698, -0.0620, -0.0487, -0.1063,  0.0467, -0.0002,\n",
      "         0.0537,  0.0358, -0.0329,  0.0654, -0.0006, -0.1011, -0.0192, -0.0640,\n",
      "        -0.0694,  0.0320, -0.1085,  0.0418, -0.0238, -0.0615, -0.0560,  0.0657,\n",
      "        -0.0512,  0.0451, -0.0391,  0.0244, -0.0777, -0.0340,  0.0475,  0.0886,\n",
      "         0.0003, -0.0109, -0.0577, -0.0619, -0.0323, -0.0008, -0.0176,  0.0066,\n",
      "         0.0504,  0.0278, -0.0135,  0.0303,  0.0313, -0.0311,  0.0308, -0.0487,\n",
      "         0.0603, -0.0842,  0.0063, -0.0263,  0.0686,  0.0789,  0.0931,  0.0091,\n",
      "        -0.0183, -0.0787,  0.0457,  0.0954,  0.0281, -0.0374,  0.0159, -0.0512,\n",
      "        -0.0433, -0.0511, -0.0834,  0.0953, -0.1000,  0.0523, -0.0116,  0.0425,\n",
      "        -0.0527, -0.0206, -0.0190, -0.0797,  0.0660, -0.0485, -0.0466,  0.0153,\n",
      "        -0.0169,  0.0452, -0.0746, -0.0683,  0.0565,  0.0540, -0.0384,  0.0310,\n",
      "         0.0139,  0.0437, -0.0087, -0.0292,  0.0351, -0.0614, -0.0722,  0.0297,\n",
      "         0.1136,  0.0672, -0.0866,  0.1015, -0.0465,  0.0330,  0.0159, -0.0102,\n",
      "         0.0414,  0.0236,  0.0637,  0.0466,  0.0528, -0.0651, -0.0702, -0.0829,\n",
      "        -0.0911,  0.0808, -0.0970,  0.0308,  0.1084,  0.0431,  0.0110,  0.0354,\n",
      "        -0.0004,  0.0313, -0.0509,  0.0891, -0.0619, -0.0549,  0.0235, -0.0453,\n",
      "         0.0305,  0.0650,  0.0026,  0.0656,  0.0059,  0.0531, -0.0560,  0.0448,\n",
      "         0.0648, -0.0330, -0.0089, -0.1149,  0.0918, -0.0469,  0.0221, -0.0289,\n",
      "         0.0285,  0.1076, -0.0770, -0.0513,  0.0834,  0.0107, -0.0912, -0.0662,\n",
      "        -0.0766,  0.0287,  0.0123, -0.0207, -0.0837, -0.0780,  0.0546,  0.0836,\n",
      "        -0.0027,  0.1223, -0.0599, -0.0164,  0.0038,  0.0645,  0.0602, -0.0260,\n",
      "        -0.1117, -0.0681, -0.0433,  0.0739,  0.0762,  0.0478,  0.0897, -0.0819,\n",
      "         0.0830, -0.0597,  0.0852,  0.0506,  0.0303,  0.0344, -0.0822, -0.0732,\n",
      "        -0.0964,  0.0137, -0.0595, -0.0760,  0.0394,  0.0083, -0.0690,  0.0529,\n",
      "         0.0407, -0.0937,  0.0200,  0.0386,  0.0058,  0.0301, -0.0113,  0.0929,\n",
      "         0.0309, -0.0483, -0.0190, -0.0249,  0.0614, -0.0806,  0.0442,  0.0468,\n",
      "         0.0455,  0.0116, -0.0451, -0.0917,  0.0322, -0.0705,  0.0507, -0.0204,\n",
      "         0.0007, -0.0027,  0.0428,  0.0796, -0.0316,  0.0552, -0.0604,  0.0575,\n",
      "         0.0360,  0.0643,  0.0433, -0.0074,  0.0539, -0.0003,  0.0321,  0.0552,\n",
      "         0.0537, -0.0608, -0.0301,  0.0042,  0.0934,  0.0286, -0.1056, -0.0474,\n",
      "        -0.0313, -0.0984,  0.0300,  0.0091, -0.0760,  0.0004, -0.0812,  0.0902,\n",
      "        -0.0741,  0.0695, -0.0525, -0.0741,  0.0278, -0.0640, -0.0199, -0.0633,\n",
      "         0.0149, -0.0275, -0.0856, -0.0580, -0.0747, -0.0139,  0.0040,  0.0315,\n",
      "        -0.0552, -0.0549,  0.0007, -0.0453, -0.0781,  0.0112,  0.0050,  0.0232,\n",
      "        -0.0420,  0.0694,  0.0666,  0.0664,  0.0244, -0.0461, -0.0278, -0.0601,\n",
      "         0.0799, -0.0605, -0.0106, -0.0346,  0.0085,  0.0739, -0.0433, -0.0053,\n",
      "         0.0755, -0.0756, -0.0710, -0.0266,  0.0126, -0.0906,  0.0843, -0.0450,\n",
      "        -0.0306,  0.0114, -0.0750,  0.0695,  0.0847,  0.0204,  0.0869,  0.0717,\n",
      "         0.0892,  0.0096, -0.0551, -0.0669, -0.0853, -0.0864,  0.1047, -0.0818,\n",
      "        -0.0770,  0.0931,  0.0221,  0.0545, -0.0748,  0.0771,  0.0588, -0.0495,\n",
      "         0.0075, -0.0071, -0.0681,  0.0002,  0.0290, -0.0568, -0.0345,  0.0315,\n",
      "         0.0363, -0.0928,  0.0599, -0.0570,  0.0604,  0.0524,  0.0424, -0.1010,\n",
      "        -0.1053, -0.0505, -0.0577,  0.0719,  0.0369,  0.0338,  0.0068,  0.0026,\n",
      "         0.0439,  0.0258, -0.0427,  0.0594, -0.0648, -0.0282, -0.0707, -0.0582,\n",
      "        -0.0210, -0.0880,  0.0366, -0.0133, -0.0476,  0.0635, -0.0333,  0.0534,\n",
      "        -0.0450,  0.0781, -0.0265, -0.0237,  0.0189, -0.0033, -0.0879,  0.0066,\n",
      "        -0.0582,  0.0313, -0.0012, -0.0256,  0.0776, -0.0801,  0.0883, -0.0772,\n",
      "        -0.0547,  0.0284, -0.0085, -0.0172, -0.0248, -0.0611, -0.0257, -0.0427,\n",
      "        -0.0368,  0.0097, -0.0731,  0.0816, -0.0421, -0.0192, -0.0546,  0.0163,\n",
      "         0.0369,  0.0193, -0.0264, -0.0645, -0.0581, -0.0677, -0.0154,  0.0552,\n",
      "        -0.0798,  0.0711,  0.0431,  0.0272, -0.0204,  0.0371, -0.0032,  0.0675,\n",
      "        -0.0399, -0.0378, -0.0247,  0.0556, -0.0469, -0.0313,  0.0346, -0.0774,\n",
      "         0.0135, -0.0863, -0.0374, -0.0790,  0.0758, -0.0534, -0.0496, -0.0032,\n",
      "         0.0652, -0.0750, -0.0940, -0.0387, -0.0594, -0.0751,  0.0502,  0.0511,\n",
      "        -0.0417,  0.0018, -0.0762, -0.0004,  0.0037,  0.0627,  0.0120,  0.0338,\n",
      "        -0.0688,  0.0400,  0.0855,  0.0265,  0.0423, -0.0375,  0.0245,  0.0013,\n",
      "         0.0121, -0.0373, -0.0252,  0.0247,  0.0048,  0.0476,  0.0585, -0.0490,\n",
      "         0.0448, -0.0205, -0.0537, -0.0524,  0.0103,  0.0989, -0.0534,  0.0832,\n",
      "         0.0281,  0.0697, -0.0782,  0.0404, -0.0589,  0.0134, -0.0148, -0.0104,\n",
      "         0.0143, -0.0749, -0.0312,  0.0053, -0.0827, -0.0643, -0.0590,  0.0067],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    count=count+1\n",
    "    if(count==2):\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 tensor([[0.1725, 0.7784, 0.7692, 0.3667]])\n",
      "param Parameter containing:\n",
      "tensor([[ 0.0794, -0.2791,  0.0171, -0.2814],\n",
      "        [-0.0677, -0.3197, -0.2683, -0.3466]], requires_grad=True)\n",
      "param Parameter containing:\n",
      "tensor([ 0.0877, -0.3602], requires_grad=True)\n",
      "tensor([[-0.2058, -0.9542]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a=nn.Linear(4,2)\n",
    "input1=torch.rand((1,4))\n",
    "print(\"input1\",input1)\n",
    "for param in a.parameters():\n",
    "    print(\"param\",param)\n",
    "print(a(input1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m        ageBias \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(ageBias),\u001b[39mlen\u001b[39;49m(ageBias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"modelUsing0.pt\")\n",
    "model.to(device)\n",
    "count=0\n",
    "ageBias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==7):\n",
    "       ageBias = param.tolist()\n",
    "    count=count+1\n",
    "print(len(ageBias),len(ageBias[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09601110219955444]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007277209311723709,\n",
       " -0.0321158841252327,\n",
       " -0.031418390572071075,\n",
       " -0.006457424722611904,\n",
       " 0.0034283681306988,\n",
       " 0.018647771328687668,\n",
       " 0.010360945016145706,\n",
       " -0.046598006039857864,\n",
       " -0.05573476478457451,\n",
       " 0.01843833737075329,\n",
       " 0.0027071069926023483,\n",
       " 0.03294723108410835,\n",
       " 0.02504689060151577,\n",
       " -0.03142755106091499,\n",
       " -0.022691987454891205,\n",
       " 0.03483140096068382,\n",
       " -0.05341877415776253,\n",
       " 0.04222894087433815,\n",
       " -0.01728733628988266,\n",
       " -0.04929398000240326,\n",
       " 0.00046024261973798275,\n",
       " -0.044817082583904266,\n",
       " 0.0034655649214982986,\n",
       " -0.03304927796125412,\n",
       " -0.0016231774352490902,\n",
       " -0.04087826982140541,\n",
       " 0.01253503654152155,\n",
       " -0.030864598229527473,\n",
       " -0.013328468427062035,\n",
       " 0.012476014904677868,\n",
       " -0.037187058478593826,\n",
       " 0.006219789385795593,\n",
       " -0.013966446742415428,\n",
       " 0.01565675437450409,\n",
       " 0.0035794111900031567,\n",
       " -0.005585063714534044,\n",
       " 0.006055895704776049,\n",
       " 0.00048314392915926874,\n",
       " -0.010381164960563183,\n",
       " -0.018931696191430092,\n",
       " 0.012918422929942608,\n",
       " 0.014919551089406013,\n",
       " -0.015488061122596264,\n",
       " -0.01959354802966118,\n",
       " 0.038306545466184616,\n",
       " -0.05790992081165314,\n",
       " -0.017201725393533707,\n",
       " -0.03371630981564522,\n",
       " -0.024791700765490532,\n",
       " -0.031961359083652496,\n",
       " -0.030725467950105667,\n",
       " -0.045284777879714966,\n",
       " -0.012051970697939396,\n",
       " 0.01729130558669567,\n",
       " -0.058299340307712555,\n",
       " -0.008241587318480015,\n",
       " 0.008392270654439926,\n",
       " 0.012528457678854465,\n",
       " -0.02050808258354664,\n",
       " 0.018400557339191437,\n",
       " -0.05368071794509888,\n",
       " -0.04868054389953613,\n",
       " -0.011333262547850609,\n",
       " 0.036896102130413055,\n",
       " -0.029022417962551117,\n",
       " 0.023950502276420593,\n",
       " 0.019032996147871017,\n",
       " 0.0386575311422348,\n",
       " 0.04340917244553566,\n",
       " -0.05563858523964882,\n",
       " -0.02269531600177288,\n",
       " -0.008079467341303825,\n",
       " 0.027136100456118584,\n",
       " 0.024767564609646797,\n",
       " 0.0464879646897316,\n",
       " -0.034298501908779144,\n",
       " -0.05876478925347328,\n",
       " 0.019566943868994713,\n",
       " -0.00596601003780961,\n",
       " 0.012794088572263718,\n",
       " 0.028237752616405487,\n",
       " 0.0027152879629284143,\n",
       " -0.018138255923986435,\n",
       " 0.024093421176075935,\n",
       " 0.014445447362959385,\n",
       " -0.029630817472934723,\n",
       " -0.009077931754291058,\n",
       " 0.04275999963283539,\n",
       " 0.019907813519239426,\n",
       " 0.03173178434371948,\n",
       " -0.010339722968637943,\n",
       " 0.021917376667261124,\n",
       " 0.00547691760584712,\n",
       " 0.04024359956383705,\n",
       " 0.00037949683610349894,\n",
       " -0.043355707079172134,\n",
       " -0.029875755310058594,\n",
       " 0.012577931396663189,\n",
       " -0.01590362749993801,\n",
       " -0.02837674878537655,\n",
       " -0.0026315744034945965,\n",
       " 0.029960552230477333,\n",
       " 0.048201654106378555,\n",
       " 0.05135548114776611,\n",
       " -0.059926338493824005,\n",
       " -0.022241834551095963,\n",
       " -0.047569092363119125,\n",
       " 0.007798505946993828,\n",
       " 0.024846207350492477,\n",
       " -0.06639613211154938,\n",
       " -0.0007212079362943769,\n",
       " -0.022007303312420845,\n",
       " 0.0007844719802960753,\n",
       " -0.03660847619175911,\n",
       " 0.010727467015385628,\n",
       " -0.024773655459284782,\n",
       " 0.015029202215373516,\n",
       " 0.009059355594217777,\n",
       " 0.02116716280579567,\n",
       " 0.04279369115829468,\n",
       " -0.07188471406698227,\n",
       " -0.002769036218523979,\n",
       " 0.03128764033317566,\n",
       " 0.018925964832305908,\n",
       " -0.01784098893404007,\n",
       " 0.029889674857258797,\n",
       " 0.0049612135626375675,\n",
       " -0.006710418500006199]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with shape (512, 128)\n",
    "\n",
    "\n",
    "# Define the directory where you want to save the text files\n",
    "output_directory = \"ageWeights\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Write each list to a separate text file\n",
    "\n",
    "\n",
    "# Write each list to a separate text file\n",
    "for i, sublist in enumerate(ageWeights):\n",
    "    # Define the file name with leading zeros\n",
    "    file_name = f\"{i:03d}.txt\"\n",
    "\n",
    "    # Write each value in the sublist on a new line\n",
    "    with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in sublist:\n",
    "            file.write(f\"{value}\\n\")\n",
    "\n",
    "print(\"Files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 39\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m        \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(layer1Bias),\u001b[39mlen\u001b[39;49m(layer1Bias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "layer1Bias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==2):\n",
    "       layer1Bias = param.tolist()\n",
    "       break\n",
    "    count=count+1\n",
    "print(len(layer1Bias),len(layer1Bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"ageBias.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in ageBias:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
