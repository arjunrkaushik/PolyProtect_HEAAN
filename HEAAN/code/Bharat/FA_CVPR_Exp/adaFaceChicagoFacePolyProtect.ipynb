{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrad/byalavar/miniconda3/envs/train/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.gender_mapping = {'M': 0, 'F': 1}\n",
    "        self.ethnicity_mapping = {'A': 0, 'B': 1, 'L': 2, 'W': 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "        \n",
    "    def getAgeLabel(self,value1):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        if(class_ranges[0][0]<=value1 and value1<class_ranges[0][1]):\n",
    "            return 0\n",
    "        elif(class_ranges[1][0]<=value1 and value1<class_ranges[1][1]):\n",
    "            return 1\n",
    "        elif(class_ranges[2][0]<=value1 and value1<class_ranges[2][1]):\n",
    "            return 2\n",
    "        elif(class_ranges[3][0]<=value1 and value1<class_ranges[3][1]):\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        folder_path  = '/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/Images/CFD/'+row['Model'] # Assuming images are in a folder named 'images'\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        image_file_path = os.path.join(folder_path, image_files[0])\n",
    "    \n",
    "\n",
    "        image = Image.open(image_file_path)\n",
    "        age = row['AgeRated']\n",
    "        \n",
    "        if(row['AgeRated']<=0):\n",
    "            age=35\n",
    "        label = {\n",
    "            'age': self.getAgeLabel(age),\n",
    "            'gender': self.gender_mapping.get(row['GenderSelf'], 0),  # -1 for unknown\n",
    "            'ethnicity': self.ethnicity_mapping.get(row['EthnicitySelf'], 0)\n",
    "        \n",
    "        }\n",
    "        #print(row['name'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/home/csgrad/byalavar/FHE/celebSet/celebSET_final_v1.csv'  # Replace with the actual path to your CSV file\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Create a list to store the indices of rows with missing files\n",
    "# rows_to_remove = []\n",
    "# count=0\n",
    "# # Iterate through the DataFrame and check if the files exist\n",
    "# for index, row in df.iterrows():\n",
    "#     image_path = '/home/csgrad/byalavar/FHE/celebSet/CELEBTEST/CELEBTEST/'+row['name']+'/' + row['filename'] \n",
    "#     if not os.path.exists(image_path):\n",
    "#         rows_to_remove.append(index)\n",
    "#         count=count+1\n",
    "# df = df.drop(rows_to_remove)\n",
    "# df.to_csv(csv_file, index=False)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to the desired size\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "transformAugment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "transformAugment2 = transforms.Compose([\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine([-45,45]),\n",
    "    transforms.ElasticTransform(),\n",
    "    transforms.GaussianBlur([3,3]),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "# trainloader = DataLoader(trainSet, batch_size=128, shuffle=False)\n",
    "\n",
    "dataSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#datasetAugment = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transformAugment)\n",
    "\n",
    "\n",
    "#dataSet = torch.utils.data.ConcatDataset([dataSet])\n",
    "\n",
    "\n",
    "\n",
    "# Specify the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(dataSet))\n",
    "testSize = len(dataSet) - train_size\n",
    "\n",
    "# Use random_split to create training and validation datasets\n",
    "train_dataset, test_dataset = random_split(dataSet, [train_size, testSize])\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) tensor(0) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "tempIter = iter(testloader)\n",
    "images,labels = next(tempIter)\n",
    "imshow(images[0])\n",
    "print(labels['age'][0],labels['gender'][0],labels['ethnicity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d, Linear\n",
    "from torch.nn import BatchNorm1d, BatchNorm2d\n",
    "from torch.nn import ReLU, Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.nn import PReLU\n",
    "import os\n",
    "\n",
    "def build_model(model_name='ir_50'):\n",
    "    if model_name == 'ir_101':\n",
    "        return IR_101(input_size=(112,112))\n",
    "    elif model_name == 'ir_50':\n",
    "        return IR_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_se_50':\n",
    "        return IR_SE_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_34':\n",
    "        return IR_34(input_size=(112,112))\n",
    "    elif model_name == 'ir_18':\n",
    "        return IR_18(input_size=(112,112))\n",
    "    else:\n",
    "        raise ValueError('not a correct model name', model_name)\n",
    "\n",
    "def initialize_weights(modules):\n",
    "    \"\"\" Weight initilize, conv2d and linear is initialized with kaiming_normal\n",
    "    \"\"\"\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class Flatten(Module):\n",
    "    \"\"\" Flat tensor\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class LinearBlock(Module):\n",
    "    \"\"\" Convolution block without no-linear activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_c, kernel, stride, padding, groups=groups, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNAP(Module):\n",
    "    \"\"\" Global Norm-Aware Pooling block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c):\n",
    "        super(GNAP, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(in_c, affine=False)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bn2 = BatchNorm1d(in_c, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x_norm = torch.norm(x, 2, 1, True)\n",
    "        x_norm_mean = torch.mean(x_norm)\n",
    "        weight = x_norm_mean / x_norm\n",
    "        x = x * weight\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        feature = self.bn2(x)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GDC(Module):\n",
    "    \"\"\" Global Depthwise Convolution block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, embedding_size):\n",
    "        super(GDC, self).__init__()\n",
    "        self.conv_6_dw = LinearBlock(in_c, in_c,\n",
    "                                     groups=in_c,\n",
    "                                     kernel=(7, 7),\n",
    "                                     stride=(1, 1),\n",
    "                                     padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(in_c, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_6_dw(x)\n",
    "        x = self.conv_6_flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SEModule(Module):\n",
    "    \"\"\" SE block\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(channels, channels // reduction,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight.data)\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(channels // reduction, channels,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlockIR(Module):\n",
    "    \"\"\" BasicBlock for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BottleneckIR(Module):\n",
    "    \"\"\" BasicBlock with bottleneck for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIR, self).__init__()\n",
    "        reduction_channel = depth // 4\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, reduction_channel, (1, 1), (1, 1), 0, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, reduction_channel, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, depth, (1, 1), stride, 0, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BasicBlockIRSE(BasicBlockIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class BottleneckIRSE(BottleneckIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "\n",
    "\n",
    "def get_block(in_channel, depth, num_units, stride=2):\n",
    "\n",
    "    return [Bottleneck(in_channel, depth, stride)] +\\\n",
    "           [Bottleneck(depth, depth, 1) for i in range(num_units - 1)]\n",
    "\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 18:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=2),\n",
    "            get_block(in_channel=64, depth=128, num_units=2),\n",
    "            get_block(in_channel=128, depth=256, num_units=2),\n",
    "            get_block(in_channel=256, depth=512, num_units=2)\n",
    "        ]\n",
    "    elif num_layers == 34:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=6),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=8),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 200:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=24),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, input_size, num_layers, mode='ir'):\n",
    "        \"\"\" Args:\n",
    "            input_size: input_size of backbone\n",
    "            num_layers: num_layers of backbone\n",
    "            mode: support ir or irse\n",
    "        \"\"\"\n",
    "        super(Backbone, self).__init__()\n",
    "        assert input_size[0] in [112, 224], \\\n",
    "            \"input_size should be [112, 112] or [224, 224]\"\n",
    "        assert num_layers in [18, 34, 50, 100, 152, 200], \\\n",
    "            \"num_layers should be 18, 34, 50, 100 or 152\"\n",
    "        assert mode in ['ir', 'ir_se'], \\\n",
    "            \"mode should be ir or ir_se\"\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64), PReLU(64))\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if num_layers <= 100:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BasicBlockIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BasicBlockIRSE\n",
    "            output_channel = 512\n",
    "        else:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BottleneckIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BottleneckIRSE\n",
    "            output_channel = 2048\n",
    "\n",
    "        if input_size[0] == 112:\n",
    "            self.output_layer = Sequential(BatchNorm2d(output_channel),\n",
    "                                        Dropout(0.4), Flatten(),\n",
    "                                        Linear(output_channel * 7 * 7, 512),\n",
    "                                        BatchNorm1d(512, affine=False))\n",
    "        else:\n",
    "            self.output_layer = Sequential(\n",
    "                BatchNorm2d(output_channel), Dropout(0.4), Flatten(),\n",
    "                Linear(output_channel * 14 * 14, 512),\n",
    "                BatchNorm1d(512, affine=False))\n",
    "\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel, bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "\n",
    "        initialize_weights(self.modules())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # current code only supports one extra image\n",
    "        # it comes with a extra dimension for number of extra image. We will just squeeze it out for now\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        for idx, module in enumerate(self.body):\n",
    "            x = module(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        norm = torch.norm(x, 2, 1, True)\n",
    "        output = torch.div(x, norm)\n",
    "\n",
    "        return output, norm\n",
    "\n",
    "\n",
    "\n",
    "def IR_18(input_size):\n",
    "    \"\"\" Constructs a ir-18 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 18, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_34(input_size):\n",
    "    \"\"\" Constructs a ir-34 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 34, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_50(input_size):\n",
    "    \"\"\" Constructs a ir-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_101(input_size):\n",
    "    \"\"\" Constructs a ir-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_152(input_size):\n",
    "    \"\"\" Constructs a ir-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_200(input_size):\n",
    "    \"\"\" Constructs a ir-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_50(input_size):\n",
    "    \"\"\" Constructs a ir_se-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_101(input_size):\n",
    "    \"\"\" Constructs a ir_se-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_152(input_size):\n",
    "    \"\"\" Constructs a ir_se-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_200(input_size):\n",
    "    \"\"\" Constructs a ir_se-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "adaface_models = {\n",
    "    'ir_18':\"/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaface_ir18_webface4m.ckpt\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_pretrained_model(architecture='ir_18'):\n",
    "    # load model and pretrained statedict\n",
    "    assert architecture in adaface_models.keys()\n",
    "    model = build_model(architecture)\n",
    "    statedict = torch.load(adaface_models[architecture])['state_dict']\n",
    "    model_statedict = {key[6:]:val for key, val in statedict.items() if key.startswith('model.')}\n",
    "    model.load_state_dict(model_statedict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def to_input(pil_rgb_image):\n",
    "    np_img = np.array(pil_rgb_image)\n",
    "    brg_img = ((np_img[:,:,::-1] / 255.) - 0.5) / 0.5\n",
    "    tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 112, 112])\n",
      "torch.Size([64, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "adaFaceModel = load_pretrained_model('ir_18')\n",
    "\n",
    "print(images.shape)\n",
    "bgr_image = images[:, [2, 1, 0], :, :]\n",
    "print(bgr_image.shape)\n",
    "\n",
    "\n",
    "#feature, _ = adaFaceModel(bgr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:1\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "def generate_C(C_range, m):\n",
    "    \"\"\" Randomly generates m coefficients for the PolyProtect mapping.\n",
    "\n",
    "    **Inputs:**\n",
    "\n",
    "    C_range : integer\n",
    "        The absolute min/max values of the coefficients range.\n",
    "\n",
    "    m : int\n",
    "        The number of coefficients to generate.\n",
    "\n",
    "    **Outputs:**\n",
    "\n",
    "    C : 1D numpy array of integers\n",
    "        Array of m coefficients.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate coefficient range (excluding 0):\n",
    "    neg_range = numpy.arange(-1 * C_range, 0)\n",
    "    pos_range = numpy.arange(1, C_range + 1)\n",
    "    whole_range = numpy.concatenate([neg_range, pos_range])\n",
    "\n",
    "    # Randomly generate m unique coefficients:\n",
    "    C = numpy.random.permutation(whole_range)[0 : m] # randomly permute the whole range and pick the first few m values\n",
    "\n",
    "    return C\n",
    "\n",
    "\n",
    "def generate_E(m):\n",
    "    \"\"\" Randomly generates m exponents for the PolyProtect mapping.\n",
    "\n",
    "    **Inputs:**\n",
    "\n",
    "    m : int\n",
    "        The number of exponents to generate.\n",
    "\n",
    "    **Outputs:**\n",
    "\n",
    "    E : 1D numpy array of integers\n",
    "        Array of m exponents.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly generate m unique exponents:\n",
    "    E = numpy.random.permutation(range(1, m + 1))[0 : m] # permute the integers in the range [1, m]\n",
    "\n",
    "    return E\n",
    "\n",
    "\n",
    "def polyprotect(overlap, V):\n",
    "    \"\"\" Maps an embedding to a PolyProtected template.\n",
    "\n",
    "    **Inputs:**\n",
    "\n",
    "    overlap : int\n",
    "        The amount of overlap between sets of embedding elements used to generate each PolyProtected element (0, 1, 2, 3, or 4).\n",
    "\n",
    "    V : torch.Tensor\n",
    "        The embedding as a PyTorch tensor.\n",
    "\n",
    "    **Outputs:**\n",
    "\n",
    "    P : torch.Tensor\n",
    "        The PolyProtected template as a PyTorch tensor.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    C = torch.tensor([-42, -35, 31, 4], dtype=torch.float32, device=V.device)\n",
    "    E = torch.tensor([3, 2, 1, 4], dtype=torch.float32, device=V.device)\n",
    "    # C = torch.tensor(generate_C(50,5),dtype=torch.float32,device=V.device)\n",
    "    # E = torch.tensor(generate_E(5),dtype=torch.float32,device=V.device)\n",
    "\n",
    "    if C.shape[0] != E.shape[0]:\n",
    "        print(\"Number of coefficients and exponents must be the same.\")\n",
    "        return None\n",
    "    #print(\"here\")\n",
    "    m = C.shape[0]  # number of embedding elements used to generate each PolyProtected element\n",
    "    step_size = m - overlap \n",
    "    decimal_remainder, integer = math.modf((V.shape[0] - m) / step_size)\n",
    "    if decimal_remainder > 0:\n",
    "        padding = math.ceil((1 - decimal_remainder) * step_size)\n",
    "    else:\n",
    "        padding = 0\n",
    "   # print(\"here1\")\n",
    "    # Pad V by \"padding\" zeros at the end\n",
    "    V = torch.cat((V, torch.zeros(padding, device=V.device)), dim=0)\n",
    "\n",
    "    starting_indices = torch.arange(0, V.shape[0] - m + 1, step_size)\n",
    "    #print(\"here2\")\n",
    "    P = torch.zeros(len(starting_indices), device=V.device)\n",
    "    \n",
    "    for storage_ind, ind in enumerate(starting_indices):\n",
    "        \n",
    "        final_ind = ind + m\n",
    "        crnt_word = V[ind:final_ind]\n",
    "        P[storage_ind] = torch.sum(C * (crnt_word ** E))\n",
    "    #print(\"here3\")\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class faceAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layer1=nn.Sequential(nn.Linear(128,512),nn.Dropout(0.5),nn.ReLU(),nn.Linear(512,256))\n",
    "        \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "        self.layer2=nn.Linear(256,128)\n",
    "        #self.layer3=nn.Linear(1024,512)\n",
    "        self.layer4=nn.Linear(128,64)\n",
    "        self.dropout2=nn.Dropout(0.5)\n",
    "        self.genderOut=nn.Sequential(nn.Linear(64,32),nn.ReLU(),nn.Linear(32,2))\n",
    "        self.ageOut=nn.Linear(64,4)\n",
    "        self.ethnicityOut = nn.Linear(64,4)\n",
    "\n",
    "        # self.maxVal = 0\n",
    "        # self.min=0\n",
    "        \n",
    "    \n",
    "    def writeResult(self,result):\n",
    "       output_directory=\"\"\n",
    "       file_name = \"resultAge.txt\"\n",
    "\n",
    "       with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in result:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        #print(\"Input\",x[0])\n",
    "        x=self.layer1(x)\n",
    "        #x=nn.functional.tanh(x)\n",
    "        #print(x[0])\n",
    "        #x=nn.functional.relu(x)\n",
    "        #x=self.dropout1(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        x=self.layer2(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        #self.writeResult(x[0])\n",
    "       # x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        #print(torch.max(torch.abs(x)))\n",
    "        #x=nn.functional.relu(x)\n",
    "        \n",
    "        x=self.dropout2(x)\n",
    "        gender=self.genderOut(x)\n",
    "        #gender = nn.functional.relu(gender)\n",
    "        age=self.ageOut(x)\n",
    "\n",
    "        ethn = self.ethnicityOut(x)\n",
    "        #self.writeResult(age[0])\n",
    "        #print(gender)\n",
    "        return gender,age,ethn\n",
    "    \n",
    "    \n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False    \n",
    "    \n",
    "\n",
    "    def trainModel(self,trainloader,testloader,adaFace,device,episodes):\n",
    "        self.train()\n",
    "        #maxVal = 0\n",
    "        learningRate=0.005\n",
    "        gender_loss = nn.CrossEntropyLoss() \n",
    "        age_loss = nn.CrossEntropyLoss() \n",
    "        ethn_loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learningRate)\n",
    "        # optimizer = torch.optim.SGD(self.parameters(), lr=learningRate,\n",
    "        # momentum=0.9, weight_decay=5e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=episodes)\n",
    "        trainingAcc = []\n",
    "        for e in range(0,episodes):\n",
    "         total_training_loss =0\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         ageAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "    \n",
    "         batchSize = 256\n",
    "         \n",
    "        #  ageLabelTensor = ageLabelTensor.type(torch.LongTensor)\n",
    "        #  genderLabelTensor = genderLabelTensor.type(torch.LongTensor)\n",
    "        #  ethnLabelTensor = ethnLabelTensor.type(torch.LongTensor)\n",
    "\n",
    "        #  while(count<tempPT.shape[0]):\n",
    "        #     if(count+batchSize<=tempPT.shape[0]):\n",
    "        #      inputs = tempPT[count:count+batchSize].to(device=device)\n",
    "        #      age_label = ageLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      gender_label = genderLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      ethn_label = ethnLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #     else:\n",
    "        #        inputs = tempPT[count:].to(device=device)\n",
    "        #        age_label = ageLabelTensor[count:].to(device=device)\n",
    "        #        gender_label = genderLabelTensor[count:].to(device=device)\n",
    "        #        ethn_label = ethnLabelTensor[count:].to(device=device)\n",
    "           \n",
    "        #     gender,age,ethn = self(inputs)\n",
    "            # age=torch.squeeze(age)\n",
    "            # age=age.type(torch.float32)\n",
    "            #print(age.shape,age_label.shape)\n",
    "            #print(gender.shape,gender_label.shape)\n",
    "            # predictedGender = torch.argmax(gender,dim=1)\n",
    "            # predictedGender = predictedGender.type(torch.float32)\n",
    "            #print(gender)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "         for i,data in enumerate(trainloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            \n",
    "            inputUpdated = torch.zeros((embeddings.shape[0], 128),device=device)\n",
    "            for t in range(0,embeddings.shape[0]):\n",
    "             #print(inputs[t].shape,\"inputs[t]\")   \n",
    "             inputUpdated[t] = polyprotect(0,embeddings[t])\n",
    "\n",
    "            gender,age,ethn = self(inputUpdated)\n",
    "\n",
    "            ageLoss = age_loss(age,age_label)\n",
    "           \n",
    "            loss = 3*gender_loss(gender,gender_label) + ageLoss + 2*ethn_loss(ethn,ethn_label) \n",
    "            #print(gender)\n",
    "            #print(gender_label)\n",
    "            #totalGenderLoss = totalGenderLoss + loss.item()\n",
    "            loss.backward()\n",
    "            #print(\"Loss:\",loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #total_training_loss = total_training_loss+loss.item()*512\n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #print(predictedGender)\n",
    "            #print(gender_label)\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j].item()):\n",
    "                    genderAcc=genderAcc+1\n",
    "            \n",
    "                if(predictedEthn[j].item()==ethn_label[j].item()):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "  \n",
    "                if(predictedAge[j].item()==age_label[j].item()):\n",
    "                    ageAcc=ageAcc+1\n",
    "  \n",
    "         genderAccuracy =  genderAcc/count\n",
    "         trainingAcc.append(genderAccuracy)\n",
    "         print(\"Gender Accuracy:\", genderAccuracy,\"Age Acc:\", ageAcc/count, \" ethnAcc:\", ethnAcc/count)\n",
    "         #print(\"total training loss:\",total_training_loss/16595,\"\\n\")\n",
    "         #print(\"\\n\")\n",
    "         #scheduler.step()\n",
    "         #print(\"max observed value: \", maxVal)\n",
    "         if(e%2==0):\n",
    "          self.test(testloader,adaFace,device)\n",
    "             \n",
    "        return trainingAcc\n",
    "\n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def test(self,testloader,adaFace,device):\n",
    "\n",
    "         self.eval()\n",
    "         age_loss = nn.L1Loss()\n",
    "\n",
    "         totalAgeError = 0\n",
    "         genderAccuracy = 0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "         maxAge = 0\n",
    "         minAge = 0\n",
    "         ageAccuracy = 0\n",
    "         total_training_loss =0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         \n",
    "         batchSize = 128\n",
    "\n",
    "         for i,data in enumerate(testloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            \n",
    "            inputUpdated = torch.zeros((embeddings.shape[0], 128),device=device)\n",
    "            for t in range(0,embeddings.shape[0]):\n",
    "             #print(inputs[t].shape,\"inputs[t]\")   \n",
    "             inputUpdated[t] = polyprotect(0,embeddings[t])\n",
    "\n",
    "            gender,age,ethn = self(inputUpdated)\n",
    "         \n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #age = get_original_age_value(age)\n",
    "\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j]):\n",
    "                    genderAcc=genderAcc+1\n",
    "                if(predictedEthn[j].item()==ethn_label[j]):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "                if(predictedAge[j].item()==age_label[j]):\n",
    "                   ageAccuracy = ageAccuracy +1\n",
    "\n",
    "         genderAccuracy =  genderAcc/count\n",
    "         \n",
    "         print(\"Gender Accuracy:\", genderAccuracy,\"Age Accuracy:\", ageAccuracy/count, \" ethnAcc:\", ethnAcc/count)\n",
    "\n",
    "         return genderAccuracy,totalAgeError\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Accuracy: 0.5052410901467506 Age Acc: 0.7924528301886793  ethnAcc: 0.27882599580712786\n",
      "Gender Accuracy: 0.525 Age Accuracy: 0.825  ethnAcc: 0.3333333333333333\n",
      "Gender Accuracy: 0.6771488469601677 Age Acc: 0.8532494758909853  ethnAcc: 0.46750524109014674\n",
      "Gender Accuracy: 0.7484276729559748 Age Acc: 0.8532494758909853  ethnAcc: 0.5345911949685535\n",
      "Gender Accuracy: 0.7833333333333333 Age Accuracy: 0.825  ethnAcc: 0.375\n",
      "Gender Accuracy: 0.8113207547169812 Age Acc: 0.8469601677148847  ethnAcc: 0.559748427672956\n",
      "Gender Accuracy: 0.8155136268343816 Age Acc: 0.8532494758909853  ethnAcc: 0.6142557651991615\n",
      "Gender Accuracy: 0.7916666666666666 Age Accuracy: 0.825  ethnAcc: 0.525\n",
      "Gender Accuracy: 0.8301886792452831 Age Acc: 0.8406708595387841  ethnAcc: 0.6226415094339622\n",
      "Gender Accuracy: 0.8322851153039832 Age Acc: 0.8385744234800838  ethnAcc: 0.6310272536687631\n",
      "Gender Accuracy: 0.775 Age Accuracy: 0.825  ethnAcc: 0.4583333333333333\n",
      "Gender Accuracy: 0.8763102725366876 Age Acc: 0.8511530398322851  ethnAcc: 0.6352201257861635\n",
      "Gender Accuracy: 0.8637316561844863 Age Acc: 0.8553459119496856  ethnAcc: 0.6750524109014675\n",
      "Gender Accuracy: 0.8333333333333334 Age Accuracy: 0.8083333333333333  ethnAcc: 0.6\n",
      "Gender Accuracy: 0.8637316561844863 Age Acc: 0.8469601677148847  ethnAcc: 0.6834381551362684\n",
      "Gender Accuracy: 0.8805031446540881 Age Acc: 0.8532494758909853  ethnAcc: 0.6918238993710691\n",
      "Gender Accuracy: 0.7916666666666666 Age Accuracy: 0.825  ethnAcc: 0.6166666666666667\n",
      "Gender Accuracy: 0.8784067085953878 Age Acc: 0.8490566037735849  ethnAcc: 0.689727463312369\n",
      "Gender Accuracy: 0.8888888888888888 Age Acc: 0.8532494758909853  ethnAcc: 0.7044025157232704\n",
      "Gender Accuracy: 0.6833333333333333 Age Accuracy: 0.825  ethnAcc: 0.5666666666666667\n",
      "Gender Accuracy: 0.7987421383647799 Age Acc: 0.8406708595387841  ethnAcc: 0.6792452830188679\n",
      "Gender Accuracy: 0.8532494758909853 Age Acc: 0.8532494758909853  ethnAcc: 0.6855345911949685\n",
      "Gender Accuracy: 0.8083333333333333 Age Accuracy: 0.825  ethnAcc: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model.to(device)\n",
    "adaFaceModel.to(device)\n",
    "adaFaceModel.eval()\n",
    "trainingAcc = model.trainModel(trainloader,testloader,adaFaceModel,device,15)\n",
    "#torch.save(model,\"bestFaceAn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35.3753],\n",
      "        [34.8900],\n",
      "        [35.9449],\n",
      "        [35.1217],\n",
      "        [35.7582],\n",
      "        [35.6678],\n",
      "        [35.2125],\n",
      "        [36.1453],\n",
      "        [35.4029],\n",
      "        [35.2653],\n",
      "        [35.0805],\n",
      "        [35.3967],\n",
      "        [35.5769],\n",
      "        [35.7067],\n",
      "        [35.9907],\n",
      "        [35.8430],\n",
      "        [35.9960],\n",
      "        [35.7801],\n",
      "        [36.0240],\n",
      "        [35.3092],\n",
      "        [34.7713],\n",
      "        [35.2087],\n",
      "        [35.2737],\n",
      "        [34.7884],\n",
      "        [34.8579],\n",
      "        [35.5894],\n",
      "        [35.0393],\n",
      "        [35.1824],\n",
      "        [35.2798],\n",
      "        [35.3226],\n",
      "        [34.7159],\n",
      "        [34.9689],\n",
      "        [34.7194],\n",
      "        [34.5731],\n",
      "        [35.1871],\n",
      "        [34.6003],\n",
      "        [35.5002],\n",
      "        [35.1668],\n",
      "        [35.6073],\n",
      "        [35.7567],\n",
      "        [35.5327],\n",
      "        [35.1987],\n",
      "        [35.2451],\n",
      "        [34.9374],\n",
      "        [35.2929],\n",
      "        [34.3929],\n",
      "        [34.5153],\n",
      "        [35.3669],\n",
      "        [34.5637],\n",
      "        [35.0643],\n",
      "        [34.7852],\n",
      "        [34.8137],\n",
      "        [35.1823],\n",
      "        [34.5501],\n",
      "        [34.4022],\n",
      "        [34.5978],\n",
      "        [34.9801],\n",
      "        [35.3785],\n",
      "        [35.3309],\n",
      "        [35.3094],\n",
      "        [34.4434],\n",
      "        [34.4440],\n",
      "        [34.7743],\n",
      "        [34.8726],\n",
      "        [34.4675],\n",
      "        [34.9710],\n",
      "        [34.8205],\n",
      "        [34.9515],\n",
      "        [34.4587],\n",
      "        [34.8638],\n",
      "        [34.6174],\n",
      "        [34.3467],\n",
      "        [35.1777],\n",
      "        [34.3238],\n",
      "        [34.5169],\n",
      "        [34.4216],\n",
      "        [35.1418],\n",
      "        [35.1291],\n",
      "        [35.2088],\n",
      "        [34.7792],\n",
      "        [35.4482],\n",
      "        [34.2262],\n",
      "        [34.2712],\n",
      "        [35.4014],\n",
      "        [34.4724],\n",
      "        [34.9141],\n",
      "        [34.9530],\n",
      "        [34.7307],\n",
      "        [34.6980],\n",
      "        [34.5458],\n",
      "        [34.8650],\n",
      "        [34.6202],\n",
      "        [34.5739],\n",
      "        [34.4134],\n",
      "        [34.8370],\n",
      "        [34.4672],\n",
      "        [34.4837],\n",
      "        [34.5230],\n",
      "        [34.4193],\n",
      "        [34.5315],\n",
      "        [34.7996],\n",
      "        [34.8419],\n",
      "        [34.9814],\n",
      "        [35.0938],\n",
      "        [35.5417],\n",
      "        [34.5715],\n",
      "        [35.0048],\n",
      "        [35.0402],\n",
      "        [34.8746],\n",
      "        [35.1177],\n",
      "        [35.2236],\n",
      "        [34.6062],\n",
      "        [35.1779],\n",
      "        [34.6547],\n",
      "        [35.3587],\n",
      "        [35.1580],\n",
      "        [34.9708],\n",
      "        [34.8810],\n",
      "        [34.9202],\n",
      "        [35.4713],\n",
      "        [36.2521],\n",
      "        [36.0412],\n",
      "        [35.8995],\n",
      "        [35.5841],\n",
      "        [35.5625],\n",
      "        [35.4475],\n",
      "        [35.7295],\n",
      "        [35.6512]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([36, 38, 33, 37, 43, 42, 37, 39, 40, 38, 38, 38, 36, 45, 34, 38, 45, 38,\n",
      "        41, 42, 41, 44, 44, 45, 46, 43, 49, 49, 40, 40, 46, 41, 48, 43, 44, 46,\n",
      "        44, 44, 49, 49, 36, 36, 36, 36, 36, 33, 27, 35, 32, 35, 31, 35, 36, 35,\n",
      "        35, 35, 33, 36, 32, 32, 28, 31, 28, 28, 28, 28, 28, 28, 31, 31, 26, 28,\n",
      "        29, 29, 28, 28, 28, 28, 28, 28, 44, 49, 44, 44, 41, 43, 45, 38, 44, 43,\n",
      "        30, 49, 49, 30, 37, 47, 41, 37, 35, 35, 47, 47, 42, 47, 42, 40, 40, 43,\n",
      "        42, 49, 47, 38, 45, 42, 44, 50, 40, 40, 40, 45, 34, 34, 34, 34, 30, 34,\n",
      "        41, 40], device='cuda:0')\n",
      "tensor([[35.5908],\n",
      "        [35.1970],\n",
      "        [35.3564],\n",
      "        [35.2313],\n",
      "        [35.9744],\n",
      "        [35.7748],\n",
      "        [35.1981],\n",
      "        [36.1145],\n",
      "        [36.2820],\n",
      "        [35.7477],\n",
      "        [35.3510],\n",
      "        [35.3646],\n",
      "        [35.6046],\n",
      "        [35.6847],\n",
      "        [35.8232],\n",
      "        [35.5912],\n",
      "        [34.7685],\n",
      "        [34.8064],\n",
      "        [35.9165],\n",
      "        [34.2044],\n",
      "        [35.8144],\n",
      "        [36.8804],\n",
      "        [36.2190],\n",
      "        [35.2708],\n",
      "        [35.4765],\n",
      "        [35.6900],\n",
      "        [35.3513],\n",
      "        [35.9896],\n",
      "        [35.9006],\n",
      "        [35.7300],\n",
      "        [35.5070],\n",
      "        [36.1814],\n",
      "        [34.5486],\n",
      "        [35.1370],\n",
      "        [34.6699],\n",
      "        [35.2049],\n",
      "        [34.6361],\n",
      "        [35.0357],\n",
      "        [35.3003],\n",
      "        [35.4785],\n",
      "        [35.2726],\n",
      "        [34.9821],\n",
      "        [35.6880],\n",
      "        [34.8993],\n",
      "        [35.1290],\n",
      "        [34.5569],\n",
      "        [34.6750],\n",
      "        [34.7631],\n",
      "        [34.8707],\n",
      "        [34.7044],\n",
      "        [34.7422],\n",
      "        [35.1428],\n",
      "        [33.8254],\n",
      "        [34.4819],\n",
      "        [34.1235],\n",
      "        [33.9784],\n",
      "        [33.8354],\n",
      "        [34.3219],\n",
      "        [34.0219],\n",
      "        [34.4072],\n",
      "        [34.0714],\n",
      "        [34.3921],\n",
      "        [33.9476],\n",
      "        [34.0390],\n",
      "        [34.0656],\n",
      "        [34.0163],\n",
      "        [34.3066],\n",
      "        [33.9083],\n",
      "        [34.2981],\n",
      "        [34.1271],\n",
      "        [34.1253],\n",
      "        [34.0908],\n",
      "        [35.3379],\n",
      "        [35.1753],\n",
      "        [35.6381],\n",
      "        [35.9315],\n",
      "        [35.7863],\n",
      "        [36.3072],\n",
      "        [35.1858],\n",
      "        [35.4719],\n",
      "        [35.2710],\n",
      "        [35.6580],\n",
      "        [35.3458],\n",
      "        [35.7561],\n",
      "        [35.7932],\n",
      "        [35.7866],\n",
      "        [35.7116],\n",
      "        [35.8126],\n",
      "        [35.0542],\n",
      "        [36.1936],\n",
      "        [36.0494],\n",
      "        [36.0367],\n",
      "        [34.2524],\n",
      "        [35.1225],\n",
      "        [34.8039],\n",
      "        [35.1657],\n",
      "        [34.8633],\n",
      "        [35.0094],\n",
      "        [35.0707],\n",
      "        [34.8928],\n",
      "        [34.5676],\n",
      "        [34.5746],\n",
      "        [34.8142],\n",
      "        [34.5922],\n",
      "        [34.8044],\n",
      "        [34.2854],\n",
      "        [35.7924],\n",
      "        [35.4193],\n",
      "        [35.4458],\n",
      "        [34.9607],\n",
      "        [35.2986],\n",
      "        [35.0042],\n",
      "        [35.7203],\n",
      "        [35.4764],\n",
      "        [35.4616],\n",
      "        [35.6453],\n",
      "        [35.5811],\n",
      "        [35.0138],\n",
      "        [35.1917],\n",
      "        [35.2128],\n",
      "        [35.4942],\n",
      "        [35.0316],\n",
      "        [35.3369],\n",
      "        [34.7188],\n",
      "        [35.2221],\n",
      "        [35.2316],\n",
      "        [35.3422],\n",
      "        [35.4883]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 31, 32, 31, 34, 34, 34, 34, 36, 40, 35, 38, 54, 45, 42, 52, 36, 39,\n",
      "        52, 46, 49, 49, 54, 52, 54, 56, 42, 47, 38, 50, 36, 52, 35, 44, 44, 37,\n",
      "        35, 39, 35, 42, 40, 43, 43, 44, 45, 38, 38, 44, 37, 44, 35, 40, 22, 20,\n",
      "        20, 14, 22, 24, 22, 20, 19, 24, 19, 21, 21, 18, 18, 18, 19, 19, 19, 20,\n",
      "        41, 41, 36, 38, 41, 41, 41, 41, 41, 31, 41, 44, 41, 41, 44, 44, 41, 45,\n",
      "        41, 42, 39, 44, 35, 51, 51, 35, 51, 47, 51, 45, 42, 42, 46, 46, 39, 39,\n",
      "        39, 39, 28, 46, 60, 57, 58, 57, 53, 61, 56, 53, 59, 44, 59, 61, 52, 62,\n",
      "        59, 52], device='cuda:0')\n",
      "tensor([[35.6716],\n",
      "        [35.1297],\n",
      "        [35.2232],\n",
      "        [35.1773],\n",
      "        [35.1076],\n",
      "        [35.1033],\n",
      "        [35.6510],\n",
      "        [35.0427],\n",
      "        [34.9387],\n",
      "        [35.1592],\n",
      "        [35.3419],\n",
      "        [34.7959],\n",
      "        [35.3542],\n",
      "        [34.9941],\n",
      "        [35.3323],\n",
      "        [35.0026],\n",
      "        [34.7597],\n",
      "        [35.2275],\n",
      "        [35.2417],\n",
      "        [35.3213],\n",
      "        [34.7919],\n",
      "        [35.3347],\n",
      "        [35.7698],\n",
      "        [34.9955],\n",
      "        [35.7109],\n",
      "        [36.2404],\n",
      "        [35.3818],\n",
      "        [35.6378],\n",
      "        [36.6203],\n",
      "        [35.9013],\n",
      "        [35.7063],\n",
      "        [35.7928],\n",
      "        [36.1944],\n",
      "        [35.6834],\n",
      "        [35.9556],\n",
      "        [35.6982],\n",
      "        [35.9141],\n",
      "        [36.0318],\n",
      "        [35.7683],\n",
      "        [35.9707],\n",
      "        [36.1653],\n",
      "        [36.0832],\n",
      "        [35.9055],\n",
      "        [35.8411],\n",
      "        [35.1547],\n",
      "        [34.9846],\n",
      "        [35.2182],\n",
      "        [35.1227],\n",
      "        [34.6151],\n",
      "        [34.9115],\n",
      "        [35.2904],\n",
      "        [35.2560],\n",
      "        [35.1627],\n",
      "        [34.8735],\n",
      "        [34.8523],\n",
      "        [35.1542],\n",
      "        [34.9391],\n",
      "        [35.1873],\n",
      "        [34.8206],\n",
      "        [35.0930],\n",
      "        [35.1345],\n",
      "        [35.3721],\n",
      "        [35.0396],\n",
      "        [35.3457],\n",
      "        [34.7716],\n",
      "        [35.7270],\n",
      "        [35.2169],\n",
      "        [35.9665],\n",
      "        [36.0495],\n",
      "        [34.8878],\n",
      "        [35.5672],\n",
      "        [36.0367],\n",
      "        [35.5373],\n",
      "        [35.8219],\n",
      "        [35.0303],\n",
      "        [35.9436],\n",
      "        [35.4115],\n",
      "        [36.1393],\n",
      "        [35.8877],\n",
      "        [36.1495],\n",
      "        [35.6376],\n",
      "        [35.1883],\n",
      "        [34.7152],\n",
      "        [35.1076],\n",
      "        [35.1417],\n",
      "        [34.4864],\n",
      "        [34.5122],\n",
      "        [34.9478],\n",
      "        [34.3896],\n",
      "        [34.9186],\n",
      "        [34.4826],\n",
      "        [34.9237],\n",
      "        [34.8632],\n",
      "        [34.8885],\n",
      "        [34.6944],\n",
      "        [34.5077],\n",
      "        [34.9331],\n",
      "        [34.4756],\n",
      "        [34.7049],\n",
      "        [34.6700],\n",
      "        [34.1618],\n",
      "        [34.8048],\n",
      "        [34.9063],\n",
      "        [34.8158],\n",
      "        [36.1041],\n",
      "        [35.1679],\n",
      "        [35.6690],\n",
      "        [35.5321],\n",
      "        [34.9810],\n",
      "        [35.6375],\n",
      "        [34.8390],\n",
      "        [35.8340],\n",
      "        [34.5673],\n",
      "        [35.5223],\n",
      "        [35.6042],\n",
      "        [35.3888],\n",
      "        [35.3246],\n",
      "        [35.2683],\n",
      "        [34.5957],\n",
      "        [34.9024],\n",
      "        [35.5123],\n",
      "        [34.8012],\n",
      "        [35.4647],\n",
      "        [35.6990],\n",
      "        [35.3785],\n",
      "        [34.9155],\n",
      "        [35.1936],\n",
      "        [35.6639]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([57, 57, 44, 63, 27, 35, 37, 32, 36, 32, 33, 32, 36, 29, 29, 31, 31, 29,\n",
      "        35, 33, 31, 32, 32, 38, 37, 37, 37, 37, 37, 43, 37, 37, 37, 43, 37, 37,\n",
      "        37, 37, 37, 38, 37, 37, 37, 37, 37, 38, 42, 41, 38, 42, 31, 41, 41, 31,\n",
      "        31, 38, 31, 38, 38, 38, 36, 38, 38, 38, 51, 35, 38, 46, 46, 38, 46, 38,\n",
      "        51, 44, 38, 35, 51, 37, 44, 37, 38, 38, 51, 38, 31, 27, 31, 31, 22, 27,\n",
      "        31, 27, 31, 31, 31, 31, 24, 27, 27, 31, 31, 28, 31, 31, 41, 41, 41, 41,\n",
      "        47, 39, 41, 45, 41, 46, 42, 42, 42, 38, 42, 36, 36, 38, 41, 45, 52, 45,\n",
      "        35, 43], device='cuda:0')\n",
      "tensor([[35.4795],\n",
      "        [35.6666],\n",
      "        [35.8893],\n",
      "        [35.2787],\n",
      "        [34.9508],\n",
      "        [35.3670],\n",
      "        [35.3751],\n",
      "        [35.6291],\n",
      "        [35.4762],\n",
      "        [35.4837],\n",
      "        [35.5142],\n",
      "        [35.0019],\n",
      "        [35.2089],\n",
      "        [35.2128],\n",
      "        [35.4845],\n",
      "        [35.2642],\n",
      "        [35.1375],\n",
      "        [34.4778],\n",
      "        [35.0244],\n",
      "        [34.9095],\n",
      "        [35.0418],\n",
      "        [34.5147],\n",
      "        [34.7461],\n",
      "        [35.0369],\n",
      "        [35.2373],\n",
      "        [34.9923],\n",
      "        [35.0513],\n",
      "        [34.9557],\n",
      "        [35.0776],\n",
      "        [34.6016],\n",
      "        [35.1065],\n",
      "        [34.4345],\n",
      "        [35.0290],\n",
      "        [35.2665],\n",
      "        [34.9426],\n",
      "        [35.1003],\n",
      "        [35.6985],\n",
      "        [36.5956],\n",
      "        [35.7663],\n",
      "        [35.1041],\n",
      "        [36.1409],\n",
      "        [36.7595],\n",
      "        [36.1990],\n",
      "        [35.7948],\n",
      "        [36.0171],\n",
      "        [35.8555],\n",
      "        [36.3284],\n",
      "        [36.0309],\n",
      "        [34.9465],\n",
      "        [35.8947],\n",
      "        [36.5779],\n",
      "        [35.6974],\n",
      "        [36.4422],\n",
      "        [36.1278],\n",
      "        [36.1386],\n",
      "        [36.3792],\n",
      "        [35.3477],\n",
      "        [35.1244],\n",
      "        [35.1181],\n",
      "        [34.7718],\n",
      "        [34.9308],\n",
      "        [35.5438],\n",
      "        [35.1727],\n",
      "        [35.4193],\n",
      "        [34.7622],\n",
      "        [35.1816],\n",
      "        [35.2385],\n",
      "        [35.5055],\n",
      "        [35.1696],\n",
      "        [35.1384],\n",
      "        [35.3725],\n",
      "        [35.9272],\n",
      "        [35.8556],\n",
      "        [35.0302],\n",
      "        [35.1732],\n",
      "        [35.1763],\n",
      "        [35.1862],\n",
      "        [34.4615],\n",
      "        [34.9141],\n",
      "        [34.7764],\n",
      "        [34.9442],\n",
      "        [35.0660],\n",
      "        [34.9732],\n",
      "        [35.4361],\n",
      "        [34.6876],\n",
      "        [35.0154],\n",
      "        [34.7629],\n",
      "        [34.8500],\n",
      "        [35.0277],\n",
      "        [34.9580],\n",
      "        [34.8705],\n",
      "        [34.8615],\n",
      "        [34.8021],\n",
      "        [35.4124],\n",
      "        [34.7570],\n",
      "        [34.8142],\n",
      "        [35.4418],\n",
      "        [35.7955],\n",
      "        [35.1213],\n",
      "        [35.4149],\n",
      "        [35.1159],\n",
      "        [35.6329],\n",
      "        [35.2507],\n",
      "        [34.4524],\n",
      "        [35.2479],\n",
      "        [35.4540],\n",
      "        [35.8907],\n",
      "        [34.9457],\n",
      "        [35.1632],\n",
      "        [35.8660],\n",
      "        [36.0482],\n",
      "        [34.5688],\n",
      "        [35.3720],\n",
      "        [35.1416],\n",
      "        [35.3966],\n",
      "        [35.2632],\n",
      "        [35.6064],\n",
      "        [35.2045],\n",
      "        [35.2445],\n",
      "        [36.0054],\n",
      "        [35.7060],\n",
      "        [35.4776],\n",
      "        [35.4532],\n",
      "        [35.9189],\n",
      "        [35.4298],\n",
      "        [36.0614],\n",
      "        [36.2864],\n",
      "        [35.8412]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([48, 49, 22, 48, 47, 35, 51, 49, 40, 48, 48, 23, 39, 48, 39, 52, 64, 64,\n",
      "        64, 69, 38, 65, 66, 69, 71, 69, 69, 62, 64, 66, 61, 67, 40, 58, 56, 63,\n",
      "        33, 42, 42, 38, 38, 38, 36, 42, 42, 38, 41, 42, 32, 35, 36, 21, 29, 21,\n",
      "        36, 37, 22, 25, 25, 15, 25, 25, 31, 31, 27, 27, 31, 18, 24, 25, 29, 25,\n",
      "        25, 25, 22, 22, 54, 48, 54, 48, 45, 54, 50, 40, 49, 51, 54, 42, 54, 52,\n",
      "        54, 45, 45, 45, 43, 45, 40, 31, 39, 53, 58, 31, 40, 40, 40, 42, 39, 57,\n",
      "        52, 40, 40, 36, 50, 58, 39, 52, 23, 24, 23, 23, 23, 23, 19, 23, 23, 23,\n",
      "        23, 23], device='cuda:0')\n",
      "tensor([[35.6144],\n",
      "        [35.2893],\n",
      "        [35.6544],\n",
      "        [35.3373],\n",
      "        [34.5653],\n",
      "        [35.4691],\n",
      "        [35.2060],\n",
      "        [35.3587],\n",
      "        [34.9862],\n",
      "        [34.8001],\n",
      "        [34.8143],\n",
      "        [35.3639],\n",
      "        [34.8885],\n",
      "        [35.0373],\n",
      "        [34.9672],\n",
      "        [34.4939],\n",
      "        [35.2780],\n",
      "        [35.0649],\n",
      "        [34.7581],\n",
      "        [34.7647],\n",
      "        [35.2495],\n",
      "        [35.1054],\n",
      "        [34.7663],\n",
      "        [34.7225],\n",
      "        [35.5914],\n",
      "        [34.9022],\n",
      "        [34.6351],\n",
      "        [35.1620],\n",
      "        [35.1612],\n",
      "        [35.0974],\n",
      "        [35.1613],\n",
      "        [35.2439],\n",
      "        [35.1459],\n",
      "        [35.8126],\n",
      "        [35.4711],\n",
      "        [35.1724],\n",
      "        [35.1280],\n",
      "        [35.2822],\n",
      "        [35.5129],\n",
      "        [35.3774],\n",
      "        [35.6354],\n",
      "        [35.0499],\n",
      "        [35.1217],\n",
      "        [34.7722],\n",
      "        [34.9898],\n",
      "        [35.3910],\n",
      "        [35.1966],\n",
      "        [35.5621],\n",
      "        [35.0921],\n",
      "        [34.7162],\n",
      "        [35.5062],\n",
      "        [35.4526],\n",
      "        [35.3123],\n",
      "        [35.0316],\n",
      "        [34.5430],\n",
      "        [35.0080],\n",
      "        [35.7929],\n",
      "        [35.3753],\n",
      "        [35.0895],\n",
      "        [35.4575],\n",
      "        [35.1117],\n",
      "        [35.0628],\n",
      "        [35.0176],\n",
      "        [35.1503],\n",
      "        [34.6163],\n",
      "        [35.5882],\n",
      "        [35.2155],\n",
      "        [35.4436],\n",
      "        [34.4796],\n",
      "        [35.0091],\n",
      "        [34.6105],\n",
      "        [34.4541],\n",
      "        [34.5933],\n",
      "        [35.1123],\n",
      "        [34.8238],\n",
      "        [34.6670],\n",
      "        [34.5692],\n",
      "        [35.5169],\n",
      "        [35.4058],\n",
      "        [34.8378],\n",
      "        [34.2255],\n",
      "        [34.2950],\n",
      "        [34.9130],\n",
      "        [34.5225],\n",
      "        [34.3320],\n",
      "        [35.0717],\n",
      "        [34.6032],\n",
      "        [34.8387],\n",
      "        [35.3734],\n",
      "        [35.7447],\n",
      "        [35.2935],\n",
      "        [35.3257],\n",
      "        [35.5311],\n",
      "        [35.6017],\n",
      "        [35.9415],\n",
      "        [35.4047],\n",
      "        [35.2737],\n",
      "        [35.6353],\n",
      "        [35.8708],\n",
      "        [35.2433],\n",
      "        [35.6270],\n",
      "        [35.3618],\n",
      "        [36.2034],\n",
      "        [35.0211],\n",
      "        [35.1217],\n",
      "        [35.4628],\n",
      "        [35.2553],\n",
      "        [36.0134],\n",
      "        [34.5506],\n",
      "        [34.5815],\n",
      "        [34.7117],\n",
      "        [34.2520],\n",
      "        [34.3769],\n",
      "        [34.5910],\n",
      "        [34.5354],\n",
      "        [34.6707],\n",
      "        [34.2979],\n",
      "        [34.4241],\n",
      "        [34.6106],\n",
      "        [34.4812],\n",
      "        [35.0758],\n",
      "        [34.7206],\n",
      "        [34.7231],\n",
      "        [34.4175],\n",
      "        [34.4378],\n",
      "        [34.5189],\n",
      "        [34.3755],\n",
      "        [34.4504]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([25, 23, 23, 23, 23, 23, 23, 24, 35, 39, 37, 37, 35, 35, 35, 40, 35, 35,\n",
      "        35, 40, 35, 35, 35, 35, 39, 35, 35, 44, 46, 46, 41, 46, 45, 47, 41, 41,\n",
      "        45, 48, 25, 51, 45, 46, 25, 41, 47, 42, 46, 43, 51, 51, 51, 42, 51, 44,\n",
      "        51, 40, 49, 47, 46, 49, 44, 44, 45, 47, 40, 40, 46, 46, 36, 28, 36, 35,\n",
      "        33, 30, 39, 32, 39, 32, 29, 30, 35, 35, 35, 35, 29, 39, 36, 36, 41, 41,\n",
      "        35, 35, 30, 33, 33, 37, 37, 31, 39, 34, 31, 40, 43, 32, 32, 43, 40, 43,\n",
      "        31, 36, 28, 28, 28, 26, 26, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28], device='cuda:0')\n",
      "tensor([[34.9354],\n",
      "        [35.5847],\n",
      "        [35.0843],\n",
      "        [34.5578],\n",
      "        [35.3019],\n",
      "        [34.8993],\n",
      "        [34.9238],\n",
      "        [34.8123],\n",
      "        [34.5559],\n",
      "        [34.9041],\n",
      "        [34.7236],\n",
      "        [35.2706],\n",
      "        [34.7996],\n",
      "        [35.0668],\n",
      "        [35.5628],\n",
      "        [35.0146],\n",
      "        [34.9071],\n",
      "        [34.8801],\n",
      "        [34.8271],\n",
      "        [35.1872],\n",
      "        [34.5878],\n",
      "        [34.5235],\n",
      "        [34.2992],\n",
      "        [34.6512],\n",
      "        [34.6249],\n",
      "        [34.5212],\n",
      "        [34.1500],\n",
      "        [34.7980],\n",
      "        [34.6923],\n",
      "        [34.3243],\n",
      "        [34.2346],\n",
      "        [34.2828],\n",
      "        [34.2228],\n",
      "        [34.3608],\n",
      "        [34.6858],\n",
      "        [34.3873],\n",
      "        [34.5244],\n",
      "        [34.4514],\n",
      "        [34.3453],\n",
      "        [34.7674],\n",
      "        [35.8849],\n",
      "        [36.0618],\n",
      "        [35.7256],\n",
      "        [35.5733],\n",
      "        [34.8199],\n",
      "        [35.4566],\n",
      "        [35.6569],\n",
      "        [35.0206],\n",
      "        [35.8021],\n",
      "        [34.9743],\n",
      "        [35.2409],\n",
      "        [35.9429],\n",
      "        [35.8933],\n",
      "        [36.0441],\n",
      "        [36.1695],\n",
      "        [35.5283],\n",
      "        [35.4363],\n",
      "        [35.6680],\n",
      "        [35.5766],\n",
      "        [34.8636],\n",
      "        [35.9381],\n",
      "        [35.0391],\n",
      "        [35.8069],\n",
      "        [35.3174],\n",
      "        [34.8805],\n",
      "        [34.3396],\n",
      "        [35.9616],\n",
      "        [35.0980],\n",
      "        [35.0979],\n",
      "        [34.9715],\n",
      "        [34.7473],\n",
      "        [35.1693],\n",
      "        [35.4876],\n",
      "        [35.0187],\n",
      "        [35.3090],\n",
      "        [35.4881],\n",
      "        [35.2279],\n",
      "        [35.0522],\n",
      "        [34.6560],\n",
      "        [35.0230],\n",
      "        [34.8411],\n",
      "        [35.5551],\n",
      "        [35.2293],\n",
      "        [35.2838],\n",
      "        [35.3332],\n",
      "        [34.4285],\n",
      "        [34.9231],\n",
      "        [34.8155],\n",
      "        [34.7130],\n",
      "        [35.2222],\n",
      "        [34.9147],\n",
      "        [34.6843],\n",
      "        [34.9610],\n",
      "        [34.2048],\n",
      "        [35.3861],\n",
      "        [34.9440],\n",
      "        [35.3340],\n",
      "        [34.9076],\n",
      "        [35.4352],\n",
      "        [34.6392],\n",
      "        [35.1992],\n",
      "        [35.5547],\n",
      "        [35.4188],\n",
      "        [35.5040],\n",
      "        [35.2623],\n",
      "        [35.2231],\n",
      "        [35.3551],\n",
      "        [34.2089],\n",
      "        [36.1320],\n",
      "        [35.1604],\n",
      "        [35.0429],\n",
      "        [35.4114],\n",
      "        [35.7380],\n",
      "        [35.4845],\n",
      "        [34.9338],\n",
      "        [34.5837],\n",
      "        [35.4295],\n",
      "        [36.0695],\n",
      "        [34.4804],\n",
      "        [36.1543],\n",
      "        [35.3321],\n",
      "        [35.1507],\n",
      "        [35.1774],\n",
      "        [34.8528],\n",
      "        [35.0173],\n",
      "        [35.2683],\n",
      "        [34.9862],\n",
      "        [35.0621]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 26, 31, 34, 26, 25, 33, 33, 33, 25, 33, 27, 35, 31, 26, 30, 23, 34,\n",
      "        35, 31, 28, 21, 24, 21, 21, 21, 24, 24, 26, 21, 21, 21, 21, 21, 26, 21,\n",
      "        21, 21, 21, 24, 30, 30, 30, 30, 30, 31, 30, 33, 27, 28, 28, 34, 30, 30,\n",
      "        30, 28, 33, 27, 33, 38, 47, 47, 47, 36, 36, 41, 47, 46, 47, 48, 41, 47,\n",
      "        52, 31, 38, 46, 48, 38, 27, 46, 46, 49, 45, 41, 43, 43, 43, 43, 43, 41,\n",
      "        43, 41, 43, 40, 37, 43, 51, 43, 49, 49, 30, 30, 30, 30, 30, 30, 30, 24,\n",
      "        17, 30, 30, 30, 30, 28, 24, 32, 27, 32, 24, 27, 57, 52, 52, 59, 49, 46,\n",
      "        46, 55], device='cuda:0')\n",
      "tensor([[35.5787],\n",
      "        [35.3184],\n",
      "        [34.7838],\n",
      "        [35.3138],\n",
      "        [36.2333],\n",
      "        [35.3760],\n",
      "        [34.7017],\n",
      "        [34.7551],\n",
      "        [35.1854],\n",
      "        [35.1167],\n",
      "        [34.8667],\n",
      "        [35.5446],\n",
      "        [35.0842],\n",
      "        [35.0810],\n",
      "        [34.9591],\n",
      "        [34.9136],\n",
      "        [35.4882],\n",
      "        [34.9892],\n",
      "        [35.3778],\n",
      "        [35.0248],\n",
      "        [34.9740],\n",
      "        [35.5236],\n",
      "        [35.3771],\n",
      "        [35.2655],\n",
      "        [34.8318],\n",
      "        [35.1147],\n",
      "        [35.0397],\n",
      "        [35.2705],\n",
      "        [35.2720],\n",
      "        [35.3148],\n",
      "        [34.9709],\n",
      "        [34.7626],\n",
      "        [35.1236],\n",
      "        [35.9690],\n",
      "        [35.8185],\n",
      "        [35.1855],\n",
      "        [36.0162],\n",
      "        [36.3036],\n",
      "        [35.4538],\n",
      "        [35.8881],\n",
      "        [36.2321],\n",
      "        [35.7489],\n",
      "        [35.6275],\n",
      "        [35.9719],\n",
      "        [35.5694],\n",
      "        [35.5413],\n",
      "        [35.3599],\n",
      "        [35.3126],\n",
      "        [35.7186],\n",
      "        [35.4608],\n",
      "        [35.7050],\n",
      "        [35.6522],\n",
      "        [34.6701],\n",
      "        [34.5933],\n",
      "        [34.9761],\n",
      "        [34.5039],\n",
      "        [35.2864],\n",
      "        [34.8144],\n",
      "        [34.5630],\n",
      "        [34.6471],\n",
      "        [34.5796],\n",
      "        [34.2417],\n",
      "        [34.8353],\n",
      "        [34.8033],\n",
      "        [34.2711],\n",
      "        [34.9276],\n",
      "        [34.9628],\n",
      "        [34.3316],\n",
      "        [35.5308],\n",
      "        [34.3840],\n",
      "        [34.8614],\n",
      "        [34.6373],\n",
      "        [36.0299],\n",
      "        [35.9143],\n",
      "        [36.2348],\n",
      "        [35.9186],\n",
      "        [35.7079],\n",
      "        [36.2644],\n",
      "        [35.8824],\n",
      "        [35.8047],\n",
      "        [36.1476],\n",
      "        [35.8653],\n",
      "        [36.0065],\n",
      "        [36.1544],\n",
      "        [36.3721],\n",
      "        [35.6363],\n",
      "        [35.2340],\n",
      "        [36.0789],\n",
      "        [36.0321],\n",
      "        [35.6410],\n",
      "        [35.7115],\n",
      "        [35.1184],\n",
      "        [35.3790],\n",
      "        [35.2813],\n",
      "        [35.4760],\n",
      "        [34.9338],\n",
      "        [34.6445],\n",
      "        [34.7922],\n",
      "        [34.9295],\n",
      "        [35.0089],\n",
      "        [34.8993],\n",
      "        [35.1170],\n",
      "        [34.7012],\n",
      "        [34.6902],\n",
      "        [35.1757],\n",
      "        [34.9937],\n",
      "        [34.9860],\n",
      "        [34.8467],\n",
      "        [35.3488],\n",
      "        [35.0205],\n",
      "        [34.9816],\n",
      "        [34.7718],\n",
      "        [35.5287],\n",
      "        [35.3159],\n",
      "        [34.8780],\n",
      "        [35.1130],\n",
      "        [35.2618],\n",
      "        [35.2182],\n",
      "        [35.4153],\n",
      "        [35.5620],\n",
      "        [35.5765],\n",
      "        [34.6176],\n",
      "        [35.1192],\n",
      "        [35.1904],\n",
      "        [35.6753],\n",
      "        [34.8183],\n",
      "        [34.5606],\n",
      "        [35.4210]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([47, 45, 52, 59, 48, 55, 55, 59, 59, 51, 51, 45, 40, 32, 29, 41, 41, 36,\n",
      "        36,  3, 32, 42, 32, 40, 39, 32, 16, 40, 40, 40, 16, 38, 55, 52, 66, 52,\n",
      "        76, 67, 70, 68, 65, 60, 60, 70, 70, 70, 68, 77, 68, 68, 68, 66, 29, 29,\n",
      "        36, 29, 35, 29, 24, 35, 29, 29, 27, 32, 29, 32, 28, 33, 32, 29, 36, 39,\n",
      "        34, 34, 36, 36, 36, 36, 42, 36, 36, 36, 36, 36, 38, 36, 31, 36, 29, 29,\n",
      "        36, 29, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 40, 36, 36,\n",
      "        36, 36, 33, 35, 20, 20, 21, 24, 19, 19, 19, 21, 24, 24, 19, 19, 19, 20,\n",
      "        24, 19], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtest(testloader,arcFaceModel,device)\n",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=191'>192</a>\u001b[0m predictedEthn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(ethn,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m age \u001b[39m=\u001b[39m get_original_age_value(age)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m \u001b[39mprint\u001b[39;49m(age)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mprint\u001b[39m(age_label)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,predictedGender\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[1;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.test(testloader,arcFaceModel,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"arcFaceCelebSetBase.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"negGenderBaseWiki.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ccd692eb0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model92.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "input1=[]\n",
    "for i,data in enumerate(val_dataloader):\n",
    "    \n",
    "    if(count==0):\n",
    "     inputs=resnet(data[\"image\"].to(device))\n",
    "\n",
    " \n",
    "     input1 = polyprotect(0,inputs[0])\n",
    "\n",
    "     break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "tensor([-0.0765, -0.1069, -0.0411,  0.0238,  0.0118,  0.0784, -0.0193, -0.0194,\n",
      "        -0.0132,  0.0487,  0.0409, -0.0441, -0.1003,  0.0050,  0.0179,  0.0378,\n",
      "        -0.0322,  0.0842, -0.0395, -0.0201,  0.0457, -0.0654, -0.0586,  0.0188,\n",
      "        -0.0772,  0.0069,  0.0861, -0.0244,  0.0486, -0.0309, -0.0071,  0.0655,\n",
      "        -0.1047,  0.0400,  0.0215, -0.0451,  0.0729, -0.0582, -0.0285,  0.0711,\n",
      "        -0.0588, -0.0468, -0.0742, -0.0929,  0.0281,  0.0036, -0.0665, -0.0713,\n",
      "        -0.0775,  0.0966,  0.0213,  0.0536, -0.0497, -0.0261,  0.0736, -0.0707,\n",
      "        -0.0635,  0.0039,  0.0356,  0.0208, -0.0432,  0.0132,  0.0090, -0.0508,\n",
      "         0.0649, -0.0474,  0.0852,  0.0400,  0.0783,  0.0792, -0.0682, -0.0400,\n",
      "         0.0074, -0.0067,  0.0327,  0.0179, -0.0077, -0.0110,  0.0008,  0.0626,\n",
      "         0.0268, -0.0395, -0.0766,  0.0686, -0.0601,  0.0466,  0.0655,  0.0477,\n",
      "        -0.0761,  0.0306,  0.0702, -0.0810,  0.0598,  0.0180, -0.0715, -0.0503,\n",
      "        -0.0228, -0.0253,  0.0304, -0.0354, -0.0314, -0.0703, -0.0203,  0.0615,\n",
      "         0.0830,  0.0707,  0.0716, -0.0595, -0.0409, -0.0479, -0.0437,  0.0757,\n",
      "        -0.0215, -0.0659,  0.0782, -0.0438,  0.0741, -0.1035, -0.0170,  0.0418,\n",
      "         0.0713, -0.0575,  0.0096, -0.0349, -0.0885,  0.0735,  0.0153, -0.0870],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2496, device='cuda:0', grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    print(param[0])\n",
    "    print(torch.dot(input1,param[1]))\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"input1.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in input1:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ageAccuracy:  0.638671875\n",
      "ageAccuracy:  0.62109375\n",
      "ageAccuracy:  0.6087239583333334\n",
      "ageAccuracy:  0.6162109375\n",
      "ageAccuracy:  0.626953125\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.62890625\n",
      "ageAccuracy:  0.628662109375\n",
      "ageAccuracy:  0.6271701388888888\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.6296164772727273\n",
      "ageAccuracy:  0.6300455729166666\n",
      "ageAccuracy:  0.6275540865384616\n",
      "ageAccuracy:  0.6256975446428571\n",
      "ageAccuracy:  0.62578125\n",
      "ageAccuracy:  0.627197265625\n",
      "ageAccuracy:  0.6246553308823529\n",
      "ageAccuracy:  0.6252170138888888\n",
      "ageAccuracy:  0.6258223684210527\n",
      "ageAccuracy:  0.62392578125\n",
      "ageAccuracy:  0.6255580357142857\n",
      "ageAccuracy:  0.6242009943181818\n",
      "ageAccuracy:  0.6240658967391305\n",
      "ageAccuracy:  0.624267578125\n",
      "ageAccuracy:  0.6246875\n",
      "ageAccuracy:  0.6246995192307693\n",
      "ageAccuracy:  0.6237702546296297\n",
      "ageAccuracy:  0.6241629464285714\n",
      "ageAccuracy:  0.6245285560344828\n",
      "ageAccuracy:  0.6251953125\n",
      "ageAccuracy:  0.6246219758064516\n",
      "ageAccuracy:  0.62457275390625\n",
      "ageAccuracy:  0.6244081439393939\n",
      "ageAccuracy:  0.6249425551470589\n",
      "ageAccuracy:  0.6246651785714286\n",
      "ageAccuracy:  0.6248372395833334\n",
      "ageAccuracy:  0.6230996621621622\n",
      "ageAccuracy:  0.6235608552631579\n",
      "ageAccuracy:  0.6234475160256411\n",
      "ageAccuracy:  0.62275390625\n",
      "ageAccuracy:  0.6228563262195121\n",
      "ageAccuracy:  0.6216982886904762\n",
      "ageAccuracy:  0.6209574854651163\n",
      "ageAccuracy:  0.6209161931818182\n",
      "ageAccuracy:  0.6213541666666667\n",
      "ageAccuracy:  0.621475883152174\n",
      "ageAccuracy:  0.6214261968085106\n",
      "ageAccuracy:  0.62158203125\n",
      "ageAccuracy:  0.6218510841836735\n",
      "ageAccuracy:  0.6220703125\n",
      "ageAccuracy:  0.6222043504901961\n",
      "ageAccuracy:  0.6222581129807693\n",
      "ageAccuracy:  0.6218676297169812\n",
      "ageAccuracy:  0.6221426504629629\n",
      "ageAccuracy:  0.6223011363636364\n",
      "ageAccuracy:  0.6221400669642857\n",
      "ageAccuracy:  0.621813322368421\n",
      "ageAccuracy:  0.6223060344827587\n",
      "ageAccuracy:  0.6223847987288136\n",
      "ageAccuracy:  0.6228515625\n",
      "ageAccuracy:  0.6227587090163934\n",
      "ageAccuracy:  0.6231098790322581\n",
      "ageAccuracy:  0.6231398809523809\n",
      "ageAccuracy:  0.623321533203125\n",
      "ageAccuracy:  0.6232572115384616\n",
      "ageAccuracy:  0.6234907670454546\n",
      "ageAccuracy:  0.6238922574626866\n",
      "ageAccuracy:  0.6239372702205882\n",
      "ageAccuracy:  0.6240942028985508\n",
      "ageAccuracy:  0.6241908482142857\n",
      "ageAccuracy:  0.6242572623239436\n",
      "ageAccuracy:  0.6239691840277778\n",
      "ageAccuracy:  0.6239030393835616\n",
      "ageAccuracy:  0.6237595016891891\n",
      "ageAccuracy:  0.62421875\n",
      "ageAccuracy:  0.624254728618421\n",
      "ageAccuracy:  0.624416599025974\n",
      "ageAccuracy:  0.624198717948718\n",
      "ageAccuracy:  0.6240302367217028\n",
      "Test Gender Accuracy: 0.9118510045752934 \n",
      "\n",
      "Test Age Accuracy: 0.6240302367217028 \n",
      "\n",
      "Test Age Loss: 0.313527571161588 \n",
      "\n",
      "\n",
      "\n",
      "Max 0\n",
      "Min 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9118510045752934, 4815.783493041992)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/modelUsing0.pt\")\n",
    "model.to(device)\n",
    "model.test(dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"modelUsing0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-0.0608, -0.0217,  0.0529, -0.0089,  0.0091,  0.0046, -0.0850,  0.0737,\n",
      "         0.0143,  0.0217, -0.0977,  0.0810, -0.0564,  0.0011,  0.0722, -0.0247,\n",
      "         0.0400, -0.0504, -0.0266,  0.0041,  0.0306, -0.0060, -0.0088, -0.0187,\n",
      "         0.0724, -0.0828, -0.0848, -0.0345, -0.0290,  0.0105,  0.0145, -0.0039,\n",
      "        -0.0052, -0.0191,  0.0698, -0.0620, -0.0487, -0.1063,  0.0467, -0.0002,\n",
      "         0.0537,  0.0358, -0.0329,  0.0654, -0.0006, -0.1011, -0.0192, -0.0640,\n",
      "        -0.0694,  0.0320, -0.1085,  0.0418, -0.0238, -0.0615, -0.0560,  0.0657,\n",
      "        -0.0512,  0.0451, -0.0391,  0.0244, -0.0777, -0.0340,  0.0475,  0.0886,\n",
      "         0.0003, -0.0109, -0.0577, -0.0619, -0.0323, -0.0008, -0.0176,  0.0066,\n",
      "         0.0504,  0.0278, -0.0135,  0.0303,  0.0313, -0.0311,  0.0308, -0.0487,\n",
      "         0.0603, -0.0842,  0.0063, -0.0263,  0.0686,  0.0789,  0.0931,  0.0091,\n",
      "        -0.0183, -0.0787,  0.0457,  0.0954,  0.0281, -0.0374,  0.0159, -0.0512,\n",
      "        -0.0433, -0.0511, -0.0834,  0.0953, -0.1000,  0.0523, -0.0116,  0.0425,\n",
      "        -0.0527, -0.0206, -0.0190, -0.0797,  0.0660, -0.0485, -0.0466,  0.0153,\n",
      "        -0.0169,  0.0452, -0.0746, -0.0683,  0.0565,  0.0540, -0.0384,  0.0310,\n",
      "         0.0139,  0.0437, -0.0087, -0.0292,  0.0351, -0.0614, -0.0722,  0.0297,\n",
      "         0.1136,  0.0672, -0.0866,  0.1015, -0.0465,  0.0330,  0.0159, -0.0102,\n",
      "         0.0414,  0.0236,  0.0637,  0.0466,  0.0528, -0.0651, -0.0702, -0.0829,\n",
      "        -0.0911,  0.0808, -0.0970,  0.0308,  0.1084,  0.0431,  0.0110,  0.0354,\n",
      "        -0.0004,  0.0313, -0.0509,  0.0891, -0.0619, -0.0549,  0.0235, -0.0453,\n",
      "         0.0305,  0.0650,  0.0026,  0.0656,  0.0059,  0.0531, -0.0560,  0.0448,\n",
      "         0.0648, -0.0330, -0.0089, -0.1149,  0.0918, -0.0469,  0.0221, -0.0289,\n",
      "         0.0285,  0.1076, -0.0770, -0.0513,  0.0834,  0.0107, -0.0912, -0.0662,\n",
      "        -0.0766,  0.0287,  0.0123, -0.0207, -0.0837, -0.0780,  0.0546,  0.0836,\n",
      "        -0.0027,  0.1223, -0.0599, -0.0164,  0.0038,  0.0645,  0.0602, -0.0260,\n",
      "        -0.1117, -0.0681, -0.0433,  0.0739,  0.0762,  0.0478,  0.0897, -0.0819,\n",
      "         0.0830, -0.0597,  0.0852,  0.0506,  0.0303,  0.0344, -0.0822, -0.0732,\n",
      "        -0.0964,  0.0137, -0.0595, -0.0760,  0.0394,  0.0083, -0.0690,  0.0529,\n",
      "         0.0407, -0.0937,  0.0200,  0.0386,  0.0058,  0.0301, -0.0113,  0.0929,\n",
      "         0.0309, -0.0483, -0.0190, -0.0249,  0.0614, -0.0806,  0.0442,  0.0468,\n",
      "         0.0455,  0.0116, -0.0451, -0.0917,  0.0322, -0.0705,  0.0507, -0.0204,\n",
      "         0.0007, -0.0027,  0.0428,  0.0796, -0.0316,  0.0552, -0.0604,  0.0575,\n",
      "         0.0360,  0.0643,  0.0433, -0.0074,  0.0539, -0.0003,  0.0321,  0.0552,\n",
      "         0.0537, -0.0608, -0.0301,  0.0042,  0.0934,  0.0286, -0.1056, -0.0474,\n",
      "        -0.0313, -0.0984,  0.0300,  0.0091, -0.0760,  0.0004, -0.0812,  0.0902,\n",
      "        -0.0741,  0.0695, -0.0525, -0.0741,  0.0278, -0.0640, -0.0199, -0.0633,\n",
      "         0.0149, -0.0275, -0.0856, -0.0580, -0.0747, -0.0139,  0.0040,  0.0315,\n",
      "        -0.0552, -0.0549,  0.0007, -0.0453, -0.0781,  0.0112,  0.0050,  0.0232,\n",
      "        -0.0420,  0.0694,  0.0666,  0.0664,  0.0244, -0.0461, -0.0278, -0.0601,\n",
      "         0.0799, -0.0605, -0.0106, -0.0346,  0.0085,  0.0739, -0.0433, -0.0053,\n",
      "         0.0755, -0.0756, -0.0710, -0.0266,  0.0126, -0.0906,  0.0843, -0.0450,\n",
      "        -0.0306,  0.0114, -0.0750,  0.0695,  0.0847,  0.0204,  0.0869,  0.0717,\n",
      "         0.0892,  0.0096, -0.0551, -0.0669, -0.0853, -0.0864,  0.1047, -0.0818,\n",
      "        -0.0770,  0.0931,  0.0221,  0.0545, -0.0748,  0.0771,  0.0588, -0.0495,\n",
      "         0.0075, -0.0071, -0.0681,  0.0002,  0.0290, -0.0568, -0.0345,  0.0315,\n",
      "         0.0363, -0.0928,  0.0599, -0.0570,  0.0604,  0.0524,  0.0424, -0.1010,\n",
      "        -0.1053, -0.0505, -0.0577,  0.0719,  0.0369,  0.0338,  0.0068,  0.0026,\n",
      "         0.0439,  0.0258, -0.0427,  0.0594, -0.0648, -0.0282, -0.0707, -0.0582,\n",
      "        -0.0210, -0.0880,  0.0366, -0.0133, -0.0476,  0.0635, -0.0333,  0.0534,\n",
      "        -0.0450,  0.0781, -0.0265, -0.0237,  0.0189, -0.0033, -0.0879,  0.0066,\n",
      "        -0.0582,  0.0313, -0.0012, -0.0256,  0.0776, -0.0801,  0.0883, -0.0772,\n",
      "        -0.0547,  0.0284, -0.0085, -0.0172, -0.0248, -0.0611, -0.0257, -0.0427,\n",
      "        -0.0368,  0.0097, -0.0731,  0.0816, -0.0421, -0.0192, -0.0546,  0.0163,\n",
      "         0.0369,  0.0193, -0.0264, -0.0645, -0.0581, -0.0677, -0.0154,  0.0552,\n",
      "        -0.0798,  0.0711,  0.0431,  0.0272, -0.0204,  0.0371, -0.0032,  0.0675,\n",
      "        -0.0399, -0.0378, -0.0247,  0.0556, -0.0469, -0.0313,  0.0346, -0.0774,\n",
      "         0.0135, -0.0863, -0.0374, -0.0790,  0.0758, -0.0534, -0.0496, -0.0032,\n",
      "         0.0652, -0.0750, -0.0940, -0.0387, -0.0594, -0.0751,  0.0502,  0.0511,\n",
      "        -0.0417,  0.0018, -0.0762, -0.0004,  0.0037,  0.0627,  0.0120,  0.0338,\n",
      "        -0.0688,  0.0400,  0.0855,  0.0265,  0.0423, -0.0375,  0.0245,  0.0013,\n",
      "         0.0121, -0.0373, -0.0252,  0.0247,  0.0048,  0.0476,  0.0585, -0.0490,\n",
      "         0.0448, -0.0205, -0.0537, -0.0524,  0.0103,  0.0989, -0.0534,  0.0832,\n",
      "         0.0281,  0.0697, -0.0782,  0.0404, -0.0589,  0.0134, -0.0148, -0.0104,\n",
      "         0.0143, -0.0749, -0.0312,  0.0053, -0.0827, -0.0643, -0.0590,  0.0067],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    count=count+1\n",
    "    if(count==2):\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 tensor([[0.1725, 0.7784, 0.7692, 0.3667]])\n",
      "param Parameter containing:\n",
      "tensor([[ 0.0794, -0.2791,  0.0171, -0.2814],\n",
      "        [-0.0677, -0.3197, -0.2683, -0.3466]], requires_grad=True)\n",
      "param Parameter containing:\n",
      "tensor([ 0.0877, -0.3602], requires_grad=True)\n",
      "tensor([[-0.2058, -0.9542]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a=nn.Linear(4,2)\n",
    "input1=torch.rand((1,4))\n",
    "print(\"input1\",input1)\n",
    "for param in a.parameters():\n",
    "    print(\"param\",param)\n",
    "print(a(input1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m        ageBias \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(ageBias),\u001b[39mlen\u001b[39;49m(ageBias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"modelUsing0.pt\")\n",
    "model.to(device)\n",
    "count=0\n",
    "ageBias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==7):\n",
    "       ageBias = param.tolist()\n",
    "    count=count+1\n",
    "print(len(ageBias),len(ageBias[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09601110219955444]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007277209311723709,\n",
       " -0.0321158841252327,\n",
       " -0.031418390572071075,\n",
       " -0.006457424722611904,\n",
       " 0.0034283681306988,\n",
       " 0.018647771328687668,\n",
       " 0.010360945016145706,\n",
       " -0.046598006039857864,\n",
       " -0.05573476478457451,\n",
       " 0.01843833737075329,\n",
       " 0.0027071069926023483,\n",
       " 0.03294723108410835,\n",
       " 0.02504689060151577,\n",
       " -0.03142755106091499,\n",
       " -0.022691987454891205,\n",
       " 0.03483140096068382,\n",
       " -0.05341877415776253,\n",
       " 0.04222894087433815,\n",
       " -0.01728733628988266,\n",
       " -0.04929398000240326,\n",
       " 0.00046024261973798275,\n",
       " -0.044817082583904266,\n",
       " 0.0034655649214982986,\n",
       " -0.03304927796125412,\n",
       " -0.0016231774352490902,\n",
       " -0.04087826982140541,\n",
       " 0.01253503654152155,\n",
       " -0.030864598229527473,\n",
       " -0.013328468427062035,\n",
       " 0.012476014904677868,\n",
       " -0.037187058478593826,\n",
       " 0.006219789385795593,\n",
       " -0.013966446742415428,\n",
       " 0.01565675437450409,\n",
       " 0.0035794111900031567,\n",
       " -0.005585063714534044,\n",
       " 0.006055895704776049,\n",
       " 0.00048314392915926874,\n",
       " -0.010381164960563183,\n",
       " -0.018931696191430092,\n",
       " 0.012918422929942608,\n",
       " 0.014919551089406013,\n",
       " -0.015488061122596264,\n",
       " -0.01959354802966118,\n",
       " 0.038306545466184616,\n",
       " -0.05790992081165314,\n",
       " -0.017201725393533707,\n",
       " -0.03371630981564522,\n",
       " -0.024791700765490532,\n",
       " -0.031961359083652496,\n",
       " -0.030725467950105667,\n",
       " -0.045284777879714966,\n",
       " -0.012051970697939396,\n",
       " 0.01729130558669567,\n",
       " -0.058299340307712555,\n",
       " -0.008241587318480015,\n",
       " 0.008392270654439926,\n",
       " 0.012528457678854465,\n",
       " -0.02050808258354664,\n",
       " 0.018400557339191437,\n",
       " -0.05368071794509888,\n",
       " -0.04868054389953613,\n",
       " -0.011333262547850609,\n",
       " 0.036896102130413055,\n",
       " -0.029022417962551117,\n",
       " 0.023950502276420593,\n",
       " 0.019032996147871017,\n",
       " 0.0386575311422348,\n",
       " 0.04340917244553566,\n",
       " -0.05563858523964882,\n",
       " -0.02269531600177288,\n",
       " -0.008079467341303825,\n",
       " 0.027136100456118584,\n",
       " 0.024767564609646797,\n",
       " 0.0464879646897316,\n",
       " -0.034298501908779144,\n",
       " -0.05876478925347328,\n",
       " 0.019566943868994713,\n",
       " -0.00596601003780961,\n",
       " 0.012794088572263718,\n",
       " 0.028237752616405487,\n",
       " 0.0027152879629284143,\n",
       " -0.018138255923986435,\n",
       " 0.024093421176075935,\n",
       " 0.014445447362959385,\n",
       " -0.029630817472934723,\n",
       " -0.009077931754291058,\n",
       " 0.04275999963283539,\n",
       " 0.019907813519239426,\n",
       " 0.03173178434371948,\n",
       " -0.010339722968637943,\n",
       " 0.021917376667261124,\n",
       " 0.00547691760584712,\n",
       " 0.04024359956383705,\n",
       " 0.00037949683610349894,\n",
       " -0.043355707079172134,\n",
       " -0.029875755310058594,\n",
       " 0.012577931396663189,\n",
       " -0.01590362749993801,\n",
       " -0.02837674878537655,\n",
       " -0.0026315744034945965,\n",
       " 0.029960552230477333,\n",
       " 0.048201654106378555,\n",
       " 0.05135548114776611,\n",
       " -0.059926338493824005,\n",
       " -0.022241834551095963,\n",
       " -0.047569092363119125,\n",
       " 0.007798505946993828,\n",
       " 0.024846207350492477,\n",
       " -0.06639613211154938,\n",
       " -0.0007212079362943769,\n",
       " -0.022007303312420845,\n",
       " 0.0007844719802960753,\n",
       " -0.03660847619175911,\n",
       " 0.010727467015385628,\n",
       " -0.024773655459284782,\n",
       " 0.015029202215373516,\n",
       " 0.009059355594217777,\n",
       " 0.02116716280579567,\n",
       " 0.04279369115829468,\n",
       " -0.07188471406698227,\n",
       " -0.002769036218523979,\n",
       " 0.03128764033317566,\n",
       " 0.018925964832305908,\n",
       " -0.01784098893404007,\n",
       " 0.029889674857258797,\n",
       " 0.0049612135626375675,\n",
       " -0.006710418500006199]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with shape (512, 128)\n",
    "\n",
    "\n",
    "# Define the directory where you want to save the text files\n",
    "output_directory = \"ageWeights\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Write each list to a separate text file\n",
    "\n",
    "\n",
    "# Write each list to a separate text file\n",
    "for i, sublist in enumerate(ageWeights):\n",
    "    # Define the file name with leading zeros\n",
    "    file_name = f\"{i:03d}.txt\"\n",
    "\n",
    "    # Write each value in the sublist on a new line\n",
    "    with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in sublist:\n",
    "            file.write(f\"{value}\\n\")\n",
    "\n",
    "print(\"Files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 39\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m        \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(layer1Bias),\u001b[39mlen\u001b[39;49m(layer1Bias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "layer1Bias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==2):\n",
    "       layer1Bias = param.tolist()\n",
    "       break\n",
    "    count=count+1\n",
    "print(len(layer1Bias),len(layer1Bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"ageBias.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in ageBias:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
