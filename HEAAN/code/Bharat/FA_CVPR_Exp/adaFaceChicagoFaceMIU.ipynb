{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csgrad/byalavar/miniconda3/envs/train/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import os\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# from tensorflow.keras.models import Model\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.gender_mapping = {'M': 0, 'F': 1}\n",
    "        self.ethnicity_mapping = {'A': 0, 'B': 1, 'L': 2, 'W': 3}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "        \n",
    "    def getAgeLabel(self,value1):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        if(class_ranges[0][0]<=value1 and value1<class_ranges[0][1]):\n",
    "            return 0\n",
    "        elif(class_ranges[1][0]<=value1 and value1<class_ranges[1][1]):\n",
    "            return 1\n",
    "        elif(class_ranges[2][0]<=value1 and value1<class_ranges[2][1]):\n",
    "            return 2\n",
    "        elif(class_ranges[3][0]<=value1 and value1<class_ranges[3][1]):\n",
    "            return 3\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        folder_path  = '/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/Images/CFD/'+row['Model'] # Assuming images are in a folder named 'images'\n",
    "        image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.gif', '.bmp'))]\n",
    "        image_file_path = os.path.join(folder_path, image_files[0])\n",
    "    \n",
    "\n",
    "        image = Image.open(image_file_path)\n",
    "        age = row['AgeRated']\n",
    "        \n",
    "        if(row['AgeRated']<=0):\n",
    "            age=35\n",
    "        label = {\n",
    "            'age': self.getAgeLabel(age),\n",
    "            'gender': self.gender_mapping.get(row['GenderSelf'], 0),  # -1 for unknown\n",
    "            'ethnicity': self.ethnicity_mapping.get(row['EthnicitySelf'], 0)\n",
    "        \n",
    "        }\n",
    "        #print(row['name'])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_file = '/home/csgrad/byalavar/FHE/celebSet/celebSET_final_v1.csv'  # Replace with the actual path to your CSV file\n",
    "# df = pd.read_csv(csv_file)\n",
    "\n",
    "# # Create a list to store the indices of rows with missing files\n",
    "# rows_to_remove = []\n",
    "# count=0\n",
    "# # Iterate through the DataFrame and check if the files exist\n",
    "# for index, row in df.iterrows():\n",
    "#     image_path = '/home/csgrad/byalavar/FHE/celebSet/CELEBTEST/CELEBTEST/'+row['name']+'/' + row['filename'] \n",
    "#     if not os.path.exists(image_path):\n",
    "#         rows_to_remove.append(index)\n",
    "#         count=count+1\n",
    "# df = df.drop(rows_to_remove)\n",
    "# df.to_csv(csv_file, index=False)\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),  # Resize the image to the desired size\n",
    "    transforms.ToTensor(),          # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "])\n",
    "\n",
    "transformAugment = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n",
    "\n",
    "transformAugment2 = transforms.Compose([\n",
    "    transforms.RandomPerspective(),\n",
    "    transforms.RandomAffine([-45,45]),\n",
    "    transforms.ElasticTransform(),\n",
    "    transforms.GaussianBlur([3,3]),\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "# trainloader = DataLoader(trainSet, batch_size=128, shuffle=False)\n",
    "\n",
    "dataSet = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#datasetAugment = CustomDataset('/home/csgrad/byalavar/chicagoFace/CFD Version 3.0/cfdLabels.csv', transform=transformAugment)\n",
    "\n",
    "\n",
    "#dataSet = torch.utils.data.ConcatDataset([dataSet])\n",
    "\n",
    "\n",
    "\n",
    "# Specify the sizes of the training and validation sets\n",
    "train_size = int(0.8 * len(dataSet))\n",
    "testSize = len(dataSet) - train_size\n",
    "\n",
    "# Use random_split to create training and validation datasets\n",
    "train_dataset, test_dataset = random_split(dataSet, [train_size, testSize])\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True,num_workers=2)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "        img = img / 2 + 0.5     # unnormalize\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(1) tensor(3)\n"
     ]
    }
   ],
   "source": [
    "tempIter = iter(testloader)\n",
    "images,labels = next(tempIter)\n",
    "imshow(images[0])\n",
    "print(labels['age'][0],labels['gender'][0],labels['ethnicity'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import Conv2d, Linear\n",
    "from torch.nn import BatchNorm1d, BatchNorm2d\n",
    "from torch.nn import ReLU, Sigmoid\n",
    "from torch.nn import Module\n",
    "from torch.nn import PReLU\n",
    "import os\n",
    "\n",
    "def build_model(model_name='ir_50'):\n",
    "    if model_name == 'ir_101':\n",
    "        return IR_101(input_size=(112,112))\n",
    "    elif model_name == 'ir_50':\n",
    "        return IR_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_se_50':\n",
    "        return IR_SE_50(input_size=(112,112))\n",
    "    elif model_name == 'ir_34':\n",
    "        return IR_34(input_size=(112,112))\n",
    "    elif model_name == 'ir_18':\n",
    "        return IR_18(input_size=(112,112))\n",
    "    else:\n",
    "        raise ValueError('not a correct model name', model_name)\n",
    "\n",
    "def initialize_weights(modules):\n",
    "    \"\"\" Weight initilize, conv2d and linear is initialized with kaiming_normal\n",
    "    \"\"\"\n",
    "    for m in modules:\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight,\n",
    "                                    mode='fan_out',\n",
    "                                    nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class Flatten(Module):\n",
    "    \"\"\" Flat tensor\n",
    "    \"\"\"\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "\n",
    "class LinearBlock(Module):\n",
    "    \"\"\" Convolution block without no-linear activation layer\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(LinearBlock, self).__init__()\n",
    "        self.conv = Conv2d(in_c, out_c, kernel, stride, padding, groups=groups, bias=False)\n",
    "        self.bn = BatchNorm2d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class GNAP(Module):\n",
    "    \"\"\" Global Norm-Aware Pooling block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c):\n",
    "        super(GNAP, self).__init__()\n",
    "        self.bn1 = BatchNorm2d(in_c, affine=False)\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.bn2 = BatchNorm1d(in_c, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(x)\n",
    "        x_norm = torch.norm(x, 2, 1, True)\n",
    "        x_norm_mean = torch.mean(x_norm)\n",
    "        weight = x_norm_mean / x_norm\n",
    "        x = x * weight\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        feature = self.bn2(x)\n",
    "        return feature\n",
    "\n",
    "\n",
    "class GDC(Module):\n",
    "    \"\"\" Global Depthwise Convolution block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_c, embedding_size):\n",
    "        super(GDC, self).__init__()\n",
    "        self.conv_6_dw = LinearBlock(in_c, in_c,\n",
    "                                     groups=in_c,\n",
    "                                     kernel=(7, 7),\n",
    "                                     stride=(1, 1),\n",
    "                                     padding=(0, 0))\n",
    "        self.conv_6_flatten = Flatten()\n",
    "        self.linear = Linear(in_c, embedding_size, bias=False)\n",
    "        self.bn = BatchNorm1d(embedding_size, affine=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_6_dw(x)\n",
    "        x = self.conv_6_flatten(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SEModule(Module):\n",
    "    \"\"\" SE block\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction):\n",
    "        super(SEModule, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = Conv2d(channels, channels // reduction,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.fc1.weight.data)\n",
    "\n",
    "        self.relu = ReLU(inplace=True)\n",
    "        self.fc2 = Conv2d(channels // reduction, channels,\n",
    "                          kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.sigmoid = Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        module_input = x\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return module_input * x\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlockIR(Module):\n",
    "    \"\"\" BasicBlock for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIR, self).__init__()\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, depth, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(depth),\n",
    "            PReLU(depth),\n",
    "            Conv2d(depth, depth, (3, 3), stride, 1, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BottleneckIR(Module):\n",
    "    \"\"\" BasicBlock with bottleneck for IRNet\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIR, self).__init__()\n",
    "        reduction_channel = depth // 4\n",
    "        if in_channel == depth:\n",
    "            self.shortcut_layer = MaxPool2d(1, stride)\n",
    "        else:\n",
    "            self.shortcut_layer = Sequential(\n",
    "                Conv2d(in_channel, depth, (1, 1), stride, bias=False),\n",
    "                BatchNorm2d(depth))\n",
    "        self.res_layer = Sequential(\n",
    "            BatchNorm2d(in_channel),\n",
    "            Conv2d(in_channel, reduction_channel, (1, 1), (1, 1), 0, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, reduction_channel, (3, 3), (1, 1), 1, bias=False),\n",
    "            BatchNorm2d(reduction_channel),\n",
    "            PReLU(reduction_channel),\n",
    "            Conv2d(reduction_channel, depth, (1, 1), stride, 0, bias=False),\n",
    "            BatchNorm2d(depth))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut_layer(x)\n",
    "        res = self.res_layer(x)\n",
    "\n",
    "        return res + shortcut\n",
    "\n",
    "\n",
    "class BasicBlockIRSE(BasicBlockIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BasicBlockIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class BottleneckIRSE(BottleneckIR):\n",
    "    def __init__(self, in_channel, depth, stride):\n",
    "        super(BottleneckIRSE, self).__init__(in_channel, depth, stride)\n",
    "        self.res_layer.add_module(\"se_block\", SEModule(depth, 16))\n",
    "\n",
    "\n",
    "class Bottleneck(namedtuple('Block', ['in_channel', 'depth', 'stride'])):\n",
    "    '''A named tuple describing a ResNet block.'''\n",
    "\n",
    "\n",
    "def get_block(in_channel, depth, num_units, stride=2):\n",
    "\n",
    "    return [Bottleneck(in_channel, depth, stride)] +\\\n",
    "           [Bottleneck(depth, depth, 1) for i in range(num_units - 1)]\n",
    "\n",
    "\n",
    "def get_blocks(num_layers):\n",
    "    if num_layers == 18:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=2),\n",
    "            get_block(in_channel=64, depth=128, num_units=2),\n",
    "            get_block(in_channel=128, depth=256, num_units=2),\n",
    "            get_block(in_channel=256, depth=512, num_units=2)\n",
    "        ]\n",
    "    elif num_layers == 34:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=6),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 50:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=4),\n",
    "            get_block(in_channel=128, depth=256, num_units=14),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 100:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=64, num_units=3),\n",
    "            get_block(in_channel=64, depth=128, num_units=13),\n",
    "            get_block(in_channel=128, depth=256, num_units=30),\n",
    "            get_block(in_channel=256, depth=512, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 152:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=8),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "    elif num_layers == 200:\n",
    "        blocks = [\n",
    "            get_block(in_channel=64, depth=256, num_units=3),\n",
    "            get_block(in_channel=256, depth=512, num_units=24),\n",
    "            get_block(in_channel=512, depth=1024, num_units=36),\n",
    "            get_block(in_channel=1024, depth=2048, num_units=3)\n",
    "        ]\n",
    "\n",
    "    return blocks\n",
    "\n",
    "\n",
    "class Backbone(Module):\n",
    "    def __init__(self, input_size, num_layers, mode='ir'):\n",
    "        \"\"\" Args:\n",
    "            input_size: input_size of backbone\n",
    "            num_layers: num_layers of backbone\n",
    "            mode: support ir or irse\n",
    "        \"\"\"\n",
    "        super(Backbone, self).__init__()\n",
    "        assert input_size[0] in [112, 224], \\\n",
    "            \"input_size should be [112, 112] or [224, 224]\"\n",
    "        assert num_layers in [18, 34, 50, 100, 152, 200], \\\n",
    "            \"num_layers should be 18, 34, 50, 100 or 152\"\n",
    "        assert mode in ['ir', 'ir_se'], \\\n",
    "            \"mode should be ir or ir_se\"\n",
    "        self.input_layer = Sequential(Conv2d(3, 64, (3, 3), 1, 1, bias=False),\n",
    "                                      BatchNorm2d(64), PReLU(64))\n",
    "        blocks = get_blocks(num_layers)\n",
    "        if num_layers <= 100:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BasicBlockIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BasicBlockIRSE\n",
    "            output_channel = 512\n",
    "        else:\n",
    "            if mode == 'ir':\n",
    "                unit_module = BottleneckIR\n",
    "            elif mode == 'ir_se':\n",
    "                unit_module = BottleneckIRSE\n",
    "            output_channel = 2048\n",
    "\n",
    "        if input_size[0] == 112:\n",
    "            self.output_layer = Sequential(BatchNorm2d(output_channel),\n",
    "                                        Dropout(0.4), Flatten(),\n",
    "                                        Linear(output_channel * 7 * 7, 512),\n",
    "                                        BatchNorm1d(512, affine=False))\n",
    "        else:\n",
    "            self.output_layer = Sequential(\n",
    "                BatchNorm2d(output_channel), Dropout(0.4), Flatten(),\n",
    "                Linear(output_channel * 14 * 14, 512),\n",
    "                BatchNorm1d(512, affine=False))\n",
    "\n",
    "        modules = []\n",
    "        for block in blocks:\n",
    "            for bottleneck in block:\n",
    "                modules.append(\n",
    "                    unit_module(bottleneck.in_channel, bottleneck.depth,\n",
    "                                bottleneck.stride))\n",
    "        self.body = Sequential(*modules)\n",
    "\n",
    "        initialize_weights(self.modules())\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # current code only supports one extra image\n",
    "        # it comes with a extra dimension for number of extra image. We will just squeeze it out for now\n",
    "        x = self.input_layer(x)\n",
    "\n",
    "        for idx, module in enumerate(self.body):\n",
    "            x = module(x)\n",
    "\n",
    "        x = self.output_layer(x)\n",
    "        norm = torch.norm(x, 2, 1, True)\n",
    "        output = torch.div(x, norm)\n",
    "\n",
    "        return output, norm\n",
    "\n",
    "\n",
    "\n",
    "def IR_18(input_size):\n",
    "    \"\"\" Constructs a ir-18 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 18, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_34(input_size):\n",
    "    \"\"\" Constructs a ir-34 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 34, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_50(input_size):\n",
    "    \"\"\" Constructs a ir-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_101(input_size):\n",
    "    \"\"\" Constructs a ir-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_152(input_size):\n",
    "    \"\"\" Constructs a ir-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_200(input_size):\n",
    "    \"\"\" Constructs a ir-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_50(input_size):\n",
    "    \"\"\" Constructs a ir_se-50 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 50, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_101(input_size):\n",
    "    \"\"\" Constructs a ir_se-101 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 100, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_152(input_size):\n",
    "    \"\"\" Constructs a ir_se-152 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 152, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def IR_SE_200(input_size):\n",
    "    \"\"\" Constructs a ir_se-200 model.\n",
    "    \"\"\"\n",
    "    model = Backbone(input_size, 200, 'ir_se')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "adaface_models = {\n",
    "    'ir_18':\"/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/adaface_ir18_webface4m.ckpt\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_pretrained_model(architecture='ir_18'):\n",
    "    # load model and pretrained statedict\n",
    "    assert architecture in adaface_models.keys()\n",
    "    model = build_model(architecture)\n",
    "    statedict = torch.load(adaface_models[architecture])['state_dict']\n",
    "    model_statedict = {key[6:]:val for key, val in statedict.items() if key.startswith('model.')}\n",
    "    model.load_state_dict(model_statedict)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def to_input(pil_rgb_image):\n",
    "    np_img = np.array(pil_rgb_image)\n",
    "    brg_img = ((np_img[:,:,::-1] / 255.) - 0.5) / 0.5\n",
    "    tensor = torch.tensor([brg_img.transpose(2,0,1)]).float()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 112, 112])\n",
      "torch.Size([64, 3, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "adaFaceModel = load_pretrained_model('ir_18')\n",
    "\n",
    "print(images.shape)\n",
    "bgr_image = images[:, [2, 1, 0], :, :]\n",
    "print(bgr_image.shape)\n",
    "\n",
    "\n",
    "#feature, _ = adaFaceModel(bgr_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:3\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)  # Ignore DeprecationWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "class PrivacyEnhancingMIU:\n",
    "    def __init__(self, block_size):\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def __get_block(self, feature, index):\n",
    "        startIndex = self.block_size * index\n",
    "        endIndex = startIndex + self.block_size\n",
    "        return feature[startIndex:endIndex]\n",
    "\n",
    "    def shuffle(self, features):\n",
    "        X_alt = features.clone()\n",
    "        for x in range(0, len(X_alt)):\n",
    "            X_alt[x] = self.__shuffle_feature(X_alt[x])\n",
    "        return X_alt\n",
    "\n",
    "    def __shuffle_feature(self, vec):\n",
    "        vec_alt = vec.clone()\n",
    "        num_blocks = vec.size(0) // self.block_size\n",
    "        blocks = [vec_alt[i:i + self.block_size] for i in range(0, len(vec_alt), self.block_size)]\n",
    "        torch.manual_seed(0)  # Ensure consistent shuffling\n",
    "        random_indices = list(range(len(blocks)))\n",
    "        random.shuffle(random_indices)\n",
    "        vec_alt = torch.cat([blocks[i] for i in random_indices], dim=0)\n",
    "        return vec_alt\n",
    "\n",
    "    def __create_cost_matrix(self, vec_1, vec_2, num_blocks):\n",
    "        C = torch.zeros(num_blocks, num_blocks, device=vec_1.device)\n",
    "        for x in range(0, num_blocks):\n",
    "            for y in range(0, num_blocks):\n",
    "                C[x][y] = self.__l2dist(self.__get_block(vec_1, x), self.__get_block(vec_2, y))\n",
    "        return C\n",
    "\n",
    "    def __sort(self, feature, num_blocks, assignment):\n",
    "        vec = feature.clone()\n",
    "        for x in range(0, num_blocks):\n",
    "            part = self.__get_block(feature, assignment[x])\n",
    "            vec[x * self.block_size: (x + 1) * self.block_size] = part\n",
    "        return vec\n",
    "\n",
    "    def reconstruct(self, ref_vec, probe_vec):\n",
    "        dim = ref_vec.size(0)\n",
    "        num_blocks = (dim + self.block_size - 1) // self.block_size\n",
    "        cost_matrix = self.__create_cost_matrix(ref_vec, probe_vec, num_blocks)\n",
    "\n",
    "        row_ind, assignment = linear_sum_assignment(cost_matrix.cpu().numpy())\n",
    "        assignment = torch.tensor(assignment, device=ref_vec.device)\n",
    "        adj_vec = self.__sort(probe_vec, num_blocks, assignment)\n",
    "        return adj_vec\n",
    "\n",
    "    def cos_sim(self, a, b):\n",
    "        a = a.view(-1)\n",
    "        b = b.view(-1)\n",
    "        return torch.dot(a, b) / (a.norm() * b.norm())\n",
    "\n",
    "    def __l2dist(self, a, b):\n",
    "        return torch.norm(a - b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class faceAnalytics(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=nn.Sequential(nn.Linear(512,512),nn.Dropout(0.5),nn.Linear(512,256))\n",
    "        \n",
    "        self.dropout1=nn.Dropout(0.5)\n",
    "        self.layer2=nn.Linear(256,128)\n",
    "        #self.layer3=nn.Linear(1024,512)\n",
    "        self.layer4=nn.Linear(128,64)\n",
    "        self.dropout2=nn.Dropout(0.5)\n",
    "        self.genderOut=nn.Sequential(nn.Linear(64,32),nn.Linear(32,2))\n",
    "        self.ageOut=nn.Linear(64,4)\n",
    "        self.ethnicityOut = nn.Linear(64,4)\n",
    "\n",
    "        # self.maxVal = 0\n",
    "        # self.min=0\n",
    "        \n",
    "    \n",
    "    def writeResult(self,result):\n",
    "       output_directory=\"\"\n",
    "       file_name = \"resultAge.txt\"\n",
    "\n",
    "       with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in result:\n",
    "            file.write(f\"{value}\\n\")\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        #print(\"Input\",x[0])\n",
    "        x=self.layer1(x)\n",
    "        #x=nn.functional.tanh(x)\n",
    "        #print(x[0])\n",
    "        #x=nn.functional.relu(x)\n",
    "        #x=self.dropout1(x)\n",
    "        #x=nn.functional.relu(x)\n",
    "        x=self.layer2(x)\n",
    "        x=nn.functional.relu(x)\n",
    "        #self.writeResult(x[0])\n",
    "       # x=self.layer3(x)\n",
    "        x=self.layer4(x)\n",
    "        #print(torch.max(torch.abs(x)))\n",
    "        #x=nn.functional.relu(x)\n",
    "        \n",
    "        x=self.dropout2(x)\n",
    "        gender=self.genderOut(x)\n",
    "        #gender = nn.functional.relu(gender)\n",
    "        age=self.ageOut(x)\n",
    "\n",
    "        ethn = self.ethnicityOut(x)\n",
    "        #self.writeResult(age[0])\n",
    "        #print(gender)\n",
    "        return gender,age,ethn\n",
    "    \n",
    "    \n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False    \n",
    "    \n",
    "\n",
    "    def trainModel(self,trainloader,testloader,adaFace,device,episodes):\n",
    "        self.train()\n",
    "        #maxVal = 0\n",
    "        learningRate=0.005\n",
    "        gender_loss = nn.CrossEntropyLoss() \n",
    "        age_loss = nn.CrossEntropyLoss() \n",
    "        ethn_loss = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=learningRate,weight_decay=8e-4)\n",
    "        # optimizer = torch.optim.SGD(self.parameters(), lr=learningRate,\n",
    "        # momentum=0.9, weight_decay=5e-3)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=episodes)\n",
    "        trainingAcc = []\n",
    "        pemiu = PrivacyEnhancingMIU(block_size=32)\n",
    "        for e in range(0,episodes):\n",
    "         total_training_loss =0\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         ageAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "    \n",
    "         batchSize = 256\n",
    "         \n",
    "        #  ageLabelTensor = ageLabelTensor.type(torch.LongTensor)\n",
    "        #  genderLabelTensor = genderLabelTensor.type(torch.LongTensor)\n",
    "        #  ethnLabelTensor = ethnLabelTensor.type(torch.LongTensor)\n",
    "\n",
    "        #  while(count<tempPT.shape[0]):\n",
    "        #     if(count+batchSize<=tempPT.shape[0]):\n",
    "        #      inputs = tempPT[count:count+batchSize].to(device=device)\n",
    "        #      age_label = ageLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      gender_label = genderLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #      ethn_label = ethnLabelTensor[count:count+batchSize].to(device=device)\n",
    "        #     else:\n",
    "        #        inputs = tempPT[count:].to(device=device)\n",
    "        #        age_label = ageLabelTensor[count:].to(device=device)\n",
    "        #        gender_label = genderLabelTensor[count:].to(device=device)\n",
    "        #        ethn_label = ethnLabelTensor[count:].to(device=device)\n",
    "           \n",
    "        #     gender,age,ethn = self(inputs)\n",
    "            # age=torch.squeeze(age)\n",
    "            # age=age.type(torch.float32)\n",
    "            #print(age.shape,age_label.shape)\n",
    "            #print(gender.shape,gender_label.shape)\n",
    "            # predictedGender = torch.argmax(gender,dim=1)\n",
    "            # predictedGender = predictedGender.type(torch.float32)\n",
    "            #print(gender)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "         for i,data in enumerate(trainloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            embeddings = pemiu.shuffle(embeddings)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "\n",
    "            ageLoss = age_loss(age,age_label)\n",
    "           \n",
    "            loss = 3*gender_loss(gender,gender_label) + ageLoss + 2*ethn_loss(ethn,ethn_label) \n",
    "            #print(gender)\n",
    "            #print(gender_label)\n",
    "            #totalGenderLoss = totalGenderLoss + loss.item()\n",
    "            loss.backward()\n",
    "            #print(\"Loss:\",loss)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            #total_training_loss = total_training_loss+loss.item()*512\n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #print(predictedGender)\n",
    "            #print(gender_label)\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j].item()):\n",
    "                    genderAcc=genderAcc+1\n",
    "            \n",
    "                if(predictedEthn[j].item()==ethn_label[j].item()):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "  \n",
    "                if(predictedAge[j].item()==age_label[j].item()):\n",
    "                    ageAcc=ageAcc+1\n",
    "  \n",
    "         genderAccuracy =  genderAcc/count\n",
    "         trainingAcc.append(genderAccuracy)\n",
    "         print(\"Episode\", e,\"Gender Accuracy:\", genderAccuracy,\"Age Acc:\", ageAcc/count, \" ethnAcc:\", ethnAcc/count)\n",
    "         #print(\"total training loss:\",total_training_loss/16595,\"\\n\")\n",
    "         #print(\"\\n\")\n",
    "         #scheduler.step()\n",
    "         #print(\"max observed value: \", maxVal)\n",
    "         if(e%2==0):\n",
    "          self.test(testloader,adaFace,device)\n",
    "             \n",
    "        return trainingAcc\n",
    "\n",
    "    def are_values_in_same_class(self,value1, value2):\n",
    "\n",
    "    # Define class ranges\n",
    "        class_ranges = [(15, 22),(22,40),(40,60),(60,80)]\n",
    "    \n",
    "    # Check if both values fall into the same class range\n",
    "        for class_range in class_ranges:\n",
    "            if class_range[0] <= value1 < class_range[1] and class_range[0] <= value2 < class_range[1]:\n",
    "                return True\n",
    "    \n",
    "        return False\n",
    "\n",
    "    def test(self,testloader,adaFace,device):\n",
    "\n",
    "         self.eval()\n",
    "         age_loss = nn.L1Loss()\n",
    "\n",
    "         totalAgeError = 0\n",
    "         genderAccuracy = 0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "         maxAge = 0\n",
    "         minAge = 0\n",
    "         ageAccuracy = 0\n",
    "         total_training_loss =0\n",
    "         tempAcc=0\n",
    "         count=0\n",
    "         totalGenderLoss=0\n",
    "\n",
    "         genderAcc=0\n",
    "         ethnAcc = 0\n",
    "         pemiu = PrivacyEnhancingMIU(block_size=32)\n",
    "         batchSize = 128\n",
    "\n",
    "         for i,data in enumerate(testloader):\n",
    "    \n",
    "            inputs = data[0].to(device=device)\n",
    "            #inputs = inputs.type(torch.double)\n",
    "            age_label = data[1]['age'].to(device=device)\n",
    "            gender_label = data[1]['gender'].to(device=device)\n",
    "            ethn_label = data[1]['ethnicity'].to(device=device)\n",
    "\n",
    "            embeddings,_ = adaFace(inputs)\n",
    "            embeddings = pemiu.shuffle(embeddings)\n",
    "            gender,age,ethn = self(embeddings)\n",
    "         \n",
    "\n",
    "            predictedGender = torch.argmax(gender,dim=1)\n",
    "            predictedEthn = torch.argmax(ethn,dim=1)\n",
    "            predictedAge = torch.argmax(age,dim=1)\n",
    "            #age = get_original_age_value(age)\n",
    "\n",
    "            for j in range(0,predictedGender.shape[0]):\n",
    "                count=count+1\n",
    "                #print(predictedGender[j].item(),gender_label[j])\n",
    "                if(predictedGender[j].item()==gender_label[j]):\n",
    "                    genderAcc=genderAcc+1\n",
    "                if(predictedEthn[j].item()==ethn_label[j]):\n",
    "                    ethnAcc=ethnAcc+1\n",
    "                if(predictedAge[j].item()==age_label[j]):\n",
    "                   ageAccuracy = ageAccuracy +1\n",
    "\n",
    "         genderAccuracy =  genderAcc/count\n",
    "         \n",
    "         print(\"Test Gender Accuracy:\", genderAccuracy,\"Test Age Accuracy:\", ageAccuracy/count, \" Test Ethnicity Acc:\", ethnAcc/count)\n",
    "\n",
    "         return genderAccuracy,totalAgeError\n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender Accuracy: 0.49266247379454925 Age Acc: 0.7337526205450734  ethnAcc: 0.27044025157232704\n",
      "Gender Accuracy: 0.525 Age Accuracy: 0.8666666666666667  ethnAcc: 0.3\n",
      "Gender Accuracy: 0.5031446540880503 Age Acc: 0.8427672955974843  ethnAcc: 0.31027253668763105\n",
      "Gender Accuracy: 0.5094339622641509 Age Acc: 0.8427672955974843  ethnAcc: 0.3312368972746331\n",
      "Gender Accuracy: 0.475 Age Accuracy: 0.8666666666666667  ethnAcc: 0.3416666666666667\n",
      "Gender Accuracy: 0.5366876310272537 Age Acc: 0.8427672955974843  ethnAcc: 0.3270440251572327\n",
      "Gender Accuracy: 0.5429769392033543 Age Acc: 0.8427672955974843  ethnAcc: 0.3417190775681342\n",
      "Gender Accuracy: 0.5416666666666666 Age Accuracy: 0.8666666666666667  ethnAcc: 0.31666666666666665\n",
      "Gender Accuracy: 0.589098532494759 Age Acc: 0.8427672955974843  ethnAcc: 0.36268343815513626\n",
      "Gender Accuracy: 0.6058700209643606 Age Acc: 0.8427672955974843  ethnAcc: 0.33752620545073375\n",
      "Gender Accuracy: 0.5166666666666667 Age Accuracy: 0.8666666666666667  ethnAcc: 0.35833333333333334\n",
      "Gender Accuracy: 0.5513626834381551 Age Acc: 0.8427672955974843  ethnAcc: 0.34591194968553457\n",
      "Gender Accuracy: 0.6519916142557652 Age Acc: 0.8427672955974843  ethnAcc: 0.3522012578616352\n",
      "Gender Accuracy: 0.7083333333333334 Age Accuracy: 0.8666666666666667  ethnAcc: 0.375\n",
      "Gender Accuracy: 0.6645702306079665 Age Acc: 0.8427672955974843  ethnAcc: 0.3920335429769392\n",
      "Gender Accuracy: 0.6624737945492662 Age Acc: 0.8427672955974843  ethnAcc: 0.36268343815513626\n",
      "Gender Accuracy: 0.7 Age Accuracy: 0.8666666666666667  ethnAcc: 0.35833333333333334\n",
      "Gender Accuracy: 0.6876310272536688 Age Acc: 0.8427672955974843  ethnAcc: 0.3941299790356394\n",
      "Gender Accuracy: 0.6582809224318659 Age Acc: 0.8427672955974843  ethnAcc: 0.39832285115303984\n",
      "Gender Accuracy: 0.7083333333333334 Age Accuracy: 0.8666666666666667  ethnAcc: 0.2833333333333333\n",
      "Gender Accuracy: 0.6855345911949685 Age Acc: 0.8427672955974843  ethnAcc: 0.38155136268343814\n",
      "Gender Accuracy: 0.689727463312369 Age Acc: 0.8427672955974843  ethnAcc: 0.3920335429769392\n",
      "Gender Accuracy: 0.7083333333333334 Age Accuracy: 0.8666666666666667  ethnAcc: 0.375\n"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model.to(device)\n",
    "adaFaceModel.to(device)\n",
    "adaFaceModel.eval()\n",
    "trainingAcc = model.trainModel(trainloader,testloader,adaFaceModel,device,100)\n",
    "#torch.save(model,\"bestFaceAn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35.3753],\n",
      "        [34.8900],\n",
      "        [35.9449],\n",
      "        [35.1217],\n",
      "        [35.7582],\n",
      "        [35.6678],\n",
      "        [35.2125],\n",
      "        [36.1453],\n",
      "        [35.4029],\n",
      "        [35.2653],\n",
      "        [35.0805],\n",
      "        [35.3967],\n",
      "        [35.5769],\n",
      "        [35.7067],\n",
      "        [35.9907],\n",
      "        [35.8430],\n",
      "        [35.9960],\n",
      "        [35.7801],\n",
      "        [36.0240],\n",
      "        [35.3092],\n",
      "        [34.7713],\n",
      "        [35.2087],\n",
      "        [35.2737],\n",
      "        [34.7884],\n",
      "        [34.8579],\n",
      "        [35.5894],\n",
      "        [35.0393],\n",
      "        [35.1824],\n",
      "        [35.2798],\n",
      "        [35.3226],\n",
      "        [34.7159],\n",
      "        [34.9689],\n",
      "        [34.7194],\n",
      "        [34.5731],\n",
      "        [35.1871],\n",
      "        [34.6003],\n",
      "        [35.5002],\n",
      "        [35.1668],\n",
      "        [35.6073],\n",
      "        [35.7567],\n",
      "        [35.5327],\n",
      "        [35.1987],\n",
      "        [35.2451],\n",
      "        [34.9374],\n",
      "        [35.2929],\n",
      "        [34.3929],\n",
      "        [34.5153],\n",
      "        [35.3669],\n",
      "        [34.5637],\n",
      "        [35.0643],\n",
      "        [34.7852],\n",
      "        [34.8137],\n",
      "        [35.1823],\n",
      "        [34.5501],\n",
      "        [34.4022],\n",
      "        [34.5978],\n",
      "        [34.9801],\n",
      "        [35.3785],\n",
      "        [35.3309],\n",
      "        [35.3094],\n",
      "        [34.4434],\n",
      "        [34.4440],\n",
      "        [34.7743],\n",
      "        [34.8726],\n",
      "        [34.4675],\n",
      "        [34.9710],\n",
      "        [34.8205],\n",
      "        [34.9515],\n",
      "        [34.4587],\n",
      "        [34.8638],\n",
      "        [34.6174],\n",
      "        [34.3467],\n",
      "        [35.1777],\n",
      "        [34.3238],\n",
      "        [34.5169],\n",
      "        [34.4216],\n",
      "        [35.1418],\n",
      "        [35.1291],\n",
      "        [35.2088],\n",
      "        [34.7792],\n",
      "        [35.4482],\n",
      "        [34.2262],\n",
      "        [34.2712],\n",
      "        [35.4014],\n",
      "        [34.4724],\n",
      "        [34.9141],\n",
      "        [34.9530],\n",
      "        [34.7307],\n",
      "        [34.6980],\n",
      "        [34.5458],\n",
      "        [34.8650],\n",
      "        [34.6202],\n",
      "        [34.5739],\n",
      "        [34.4134],\n",
      "        [34.8370],\n",
      "        [34.4672],\n",
      "        [34.4837],\n",
      "        [34.5230],\n",
      "        [34.4193],\n",
      "        [34.5315],\n",
      "        [34.7996],\n",
      "        [34.8419],\n",
      "        [34.9814],\n",
      "        [35.0938],\n",
      "        [35.5417],\n",
      "        [34.5715],\n",
      "        [35.0048],\n",
      "        [35.0402],\n",
      "        [34.8746],\n",
      "        [35.1177],\n",
      "        [35.2236],\n",
      "        [34.6062],\n",
      "        [35.1779],\n",
      "        [34.6547],\n",
      "        [35.3587],\n",
      "        [35.1580],\n",
      "        [34.9708],\n",
      "        [34.8810],\n",
      "        [34.9202],\n",
      "        [35.4713],\n",
      "        [36.2521],\n",
      "        [36.0412],\n",
      "        [35.8995],\n",
      "        [35.5841],\n",
      "        [35.5625],\n",
      "        [35.4475],\n",
      "        [35.7295],\n",
      "        [35.6512]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([36, 38, 33, 37, 43, 42, 37, 39, 40, 38, 38, 38, 36, 45, 34, 38, 45, 38,\n",
      "        41, 42, 41, 44, 44, 45, 46, 43, 49, 49, 40, 40, 46, 41, 48, 43, 44, 46,\n",
      "        44, 44, 49, 49, 36, 36, 36, 36, 36, 33, 27, 35, 32, 35, 31, 35, 36, 35,\n",
      "        35, 35, 33, 36, 32, 32, 28, 31, 28, 28, 28, 28, 28, 28, 31, 31, 26, 28,\n",
      "        29, 29, 28, 28, 28, 28, 28, 28, 44, 49, 44, 44, 41, 43, 45, 38, 44, 43,\n",
      "        30, 49, 49, 30, 37, 47, 41, 37, 35, 35, 47, 47, 42, 47, 42, 40, 40, 43,\n",
      "        42, 49, 47, 38, 45, 42, 44, 50, 40, 40, 40, 45, 34, 34, 34, 34, 30, 34,\n",
      "        41, 40], device='cuda:0')\n",
      "tensor([[35.5908],\n",
      "        [35.1970],\n",
      "        [35.3564],\n",
      "        [35.2313],\n",
      "        [35.9744],\n",
      "        [35.7748],\n",
      "        [35.1981],\n",
      "        [36.1145],\n",
      "        [36.2820],\n",
      "        [35.7477],\n",
      "        [35.3510],\n",
      "        [35.3646],\n",
      "        [35.6046],\n",
      "        [35.6847],\n",
      "        [35.8232],\n",
      "        [35.5912],\n",
      "        [34.7685],\n",
      "        [34.8064],\n",
      "        [35.9165],\n",
      "        [34.2044],\n",
      "        [35.8144],\n",
      "        [36.8804],\n",
      "        [36.2190],\n",
      "        [35.2708],\n",
      "        [35.4765],\n",
      "        [35.6900],\n",
      "        [35.3513],\n",
      "        [35.9896],\n",
      "        [35.9006],\n",
      "        [35.7300],\n",
      "        [35.5070],\n",
      "        [36.1814],\n",
      "        [34.5486],\n",
      "        [35.1370],\n",
      "        [34.6699],\n",
      "        [35.2049],\n",
      "        [34.6361],\n",
      "        [35.0357],\n",
      "        [35.3003],\n",
      "        [35.4785],\n",
      "        [35.2726],\n",
      "        [34.9821],\n",
      "        [35.6880],\n",
      "        [34.8993],\n",
      "        [35.1290],\n",
      "        [34.5569],\n",
      "        [34.6750],\n",
      "        [34.7631],\n",
      "        [34.8707],\n",
      "        [34.7044],\n",
      "        [34.7422],\n",
      "        [35.1428],\n",
      "        [33.8254],\n",
      "        [34.4819],\n",
      "        [34.1235],\n",
      "        [33.9784],\n",
      "        [33.8354],\n",
      "        [34.3219],\n",
      "        [34.0219],\n",
      "        [34.4072],\n",
      "        [34.0714],\n",
      "        [34.3921],\n",
      "        [33.9476],\n",
      "        [34.0390],\n",
      "        [34.0656],\n",
      "        [34.0163],\n",
      "        [34.3066],\n",
      "        [33.9083],\n",
      "        [34.2981],\n",
      "        [34.1271],\n",
      "        [34.1253],\n",
      "        [34.0908],\n",
      "        [35.3379],\n",
      "        [35.1753],\n",
      "        [35.6381],\n",
      "        [35.9315],\n",
      "        [35.7863],\n",
      "        [36.3072],\n",
      "        [35.1858],\n",
      "        [35.4719],\n",
      "        [35.2710],\n",
      "        [35.6580],\n",
      "        [35.3458],\n",
      "        [35.7561],\n",
      "        [35.7932],\n",
      "        [35.7866],\n",
      "        [35.7116],\n",
      "        [35.8126],\n",
      "        [35.0542],\n",
      "        [36.1936],\n",
      "        [36.0494],\n",
      "        [36.0367],\n",
      "        [34.2524],\n",
      "        [35.1225],\n",
      "        [34.8039],\n",
      "        [35.1657],\n",
      "        [34.8633],\n",
      "        [35.0094],\n",
      "        [35.0707],\n",
      "        [34.8928],\n",
      "        [34.5676],\n",
      "        [34.5746],\n",
      "        [34.8142],\n",
      "        [34.5922],\n",
      "        [34.8044],\n",
      "        [34.2854],\n",
      "        [35.7924],\n",
      "        [35.4193],\n",
      "        [35.4458],\n",
      "        [34.9607],\n",
      "        [35.2986],\n",
      "        [35.0042],\n",
      "        [35.7203],\n",
      "        [35.4764],\n",
      "        [35.4616],\n",
      "        [35.6453],\n",
      "        [35.5811],\n",
      "        [35.0138],\n",
      "        [35.1917],\n",
      "        [35.2128],\n",
      "        [35.4942],\n",
      "        [35.0316],\n",
      "        [35.3369],\n",
      "        [34.7188],\n",
      "        [35.2221],\n",
      "        [35.2316],\n",
      "        [35.3422],\n",
      "        [35.4883]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 31, 32, 31, 34, 34, 34, 34, 36, 40, 35, 38, 54, 45, 42, 52, 36, 39,\n",
      "        52, 46, 49, 49, 54, 52, 54, 56, 42, 47, 38, 50, 36, 52, 35, 44, 44, 37,\n",
      "        35, 39, 35, 42, 40, 43, 43, 44, 45, 38, 38, 44, 37, 44, 35, 40, 22, 20,\n",
      "        20, 14, 22, 24, 22, 20, 19, 24, 19, 21, 21, 18, 18, 18, 19, 19, 19, 20,\n",
      "        41, 41, 36, 38, 41, 41, 41, 41, 41, 31, 41, 44, 41, 41, 44, 44, 41, 45,\n",
      "        41, 42, 39, 44, 35, 51, 51, 35, 51, 47, 51, 45, 42, 42, 46, 46, 39, 39,\n",
      "        39, 39, 28, 46, 60, 57, 58, 57, 53, 61, 56, 53, 59, 44, 59, 61, 52, 62,\n",
      "        59, 52], device='cuda:0')\n",
      "tensor([[35.6716],\n",
      "        [35.1297],\n",
      "        [35.2232],\n",
      "        [35.1773],\n",
      "        [35.1076],\n",
      "        [35.1033],\n",
      "        [35.6510],\n",
      "        [35.0427],\n",
      "        [34.9387],\n",
      "        [35.1592],\n",
      "        [35.3419],\n",
      "        [34.7959],\n",
      "        [35.3542],\n",
      "        [34.9941],\n",
      "        [35.3323],\n",
      "        [35.0026],\n",
      "        [34.7597],\n",
      "        [35.2275],\n",
      "        [35.2417],\n",
      "        [35.3213],\n",
      "        [34.7919],\n",
      "        [35.3347],\n",
      "        [35.7698],\n",
      "        [34.9955],\n",
      "        [35.7109],\n",
      "        [36.2404],\n",
      "        [35.3818],\n",
      "        [35.6378],\n",
      "        [36.6203],\n",
      "        [35.9013],\n",
      "        [35.7063],\n",
      "        [35.7928],\n",
      "        [36.1944],\n",
      "        [35.6834],\n",
      "        [35.9556],\n",
      "        [35.6982],\n",
      "        [35.9141],\n",
      "        [36.0318],\n",
      "        [35.7683],\n",
      "        [35.9707],\n",
      "        [36.1653],\n",
      "        [36.0832],\n",
      "        [35.9055],\n",
      "        [35.8411],\n",
      "        [35.1547],\n",
      "        [34.9846],\n",
      "        [35.2182],\n",
      "        [35.1227],\n",
      "        [34.6151],\n",
      "        [34.9115],\n",
      "        [35.2904],\n",
      "        [35.2560],\n",
      "        [35.1627],\n",
      "        [34.8735],\n",
      "        [34.8523],\n",
      "        [35.1542],\n",
      "        [34.9391],\n",
      "        [35.1873],\n",
      "        [34.8206],\n",
      "        [35.0930],\n",
      "        [35.1345],\n",
      "        [35.3721],\n",
      "        [35.0396],\n",
      "        [35.3457],\n",
      "        [34.7716],\n",
      "        [35.7270],\n",
      "        [35.2169],\n",
      "        [35.9665],\n",
      "        [36.0495],\n",
      "        [34.8878],\n",
      "        [35.5672],\n",
      "        [36.0367],\n",
      "        [35.5373],\n",
      "        [35.8219],\n",
      "        [35.0303],\n",
      "        [35.9436],\n",
      "        [35.4115],\n",
      "        [36.1393],\n",
      "        [35.8877],\n",
      "        [36.1495],\n",
      "        [35.6376],\n",
      "        [35.1883],\n",
      "        [34.7152],\n",
      "        [35.1076],\n",
      "        [35.1417],\n",
      "        [34.4864],\n",
      "        [34.5122],\n",
      "        [34.9478],\n",
      "        [34.3896],\n",
      "        [34.9186],\n",
      "        [34.4826],\n",
      "        [34.9237],\n",
      "        [34.8632],\n",
      "        [34.8885],\n",
      "        [34.6944],\n",
      "        [34.5077],\n",
      "        [34.9331],\n",
      "        [34.4756],\n",
      "        [34.7049],\n",
      "        [34.6700],\n",
      "        [34.1618],\n",
      "        [34.8048],\n",
      "        [34.9063],\n",
      "        [34.8158],\n",
      "        [36.1041],\n",
      "        [35.1679],\n",
      "        [35.6690],\n",
      "        [35.5321],\n",
      "        [34.9810],\n",
      "        [35.6375],\n",
      "        [34.8390],\n",
      "        [35.8340],\n",
      "        [34.5673],\n",
      "        [35.5223],\n",
      "        [35.6042],\n",
      "        [35.3888],\n",
      "        [35.3246],\n",
      "        [35.2683],\n",
      "        [34.5957],\n",
      "        [34.9024],\n",
      "        [35.5123],\n",
      "        [34.8012],\n",
      "        [35.4647],\n",
      "        [35.6990],\n",
      "        [35.3785],\n",
      "        [34.9155],\n",
      "        [35.1936],\n",
      "        [35.6639]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([57, 57, 44, 63, 27, 35, 37, 32, 36, 32, 33, 32, 36, 29, 29, 31, 31, 29,\n",
      "        35, 33, 31, 32, 32, 38, 37, 37, 37, 37, 37, 43, 37, 37, 37, 43, 37, 37,\n",
      "        37, 37, 37, 38, 37, 37, 37, 37, 37, 38, 42, 41, 38, 42, 31, 41, 41, 31,\n",
      "        31, 38, 31, 38, 38, 38, 36, 38, 38, 38, 51, 35, 38, 46, 46, 38, 46, 38,\n",
      "        51, 44, 38, 35, 51, 37, 44, 37, 38, 38, 51, 38, 31, 27, 31, 31, 22, 27,\n",
      "        31, 27, 31, 31, 31, 31, 24, 27, 27, 31, 31, 28, 31, 31, 41, 41, 41, 41,\n",
      "        47, 39, 41, 45, 41, 46, 42, 42, 42, 38, 42, 36, 36, 38, 41, 45, 52, 45,\n",
      "        35, 43], device='cuda:0')\n",
      "tensor([[35.4795],\n",
      "        [35.6666],\n",
      "        [35.8893],\n",
      "        [35.2787],\n",
      "        [34.9508],\n",
      "        [35.3670],\n",
      "        [35.3751],\n",
      "        [35.6291],\n",
      "        [35.4762],\n",
      "        [35.4837],\n",
      "        [35.5142],\n",
      "        [35.0019],\n",
      "        [35.2089],\n",
      "        [35.2128],\n",
      "        [35.4845],\n",
      "        [35.2642],\n",
      "        [35.1375],\n",
      "        [34.4778],\n",
      "        [35.0244],\n",
      "        [34.9095],\n",
      "        [35.0418],\n",
      "        [34.5147],\n",
      "        [34.7461],\n",
      "        [35.0369],\n",
      "        [35.2373],\n",
      "        [34.9923],\n",
      "        [35.0513],\n",
      "        [34.9557],\n",
      "        [35.0776],\n",
      "        [34.6016],\n",
      "        [35.1065],\n",
      "        [34.4345],\n",
      "        [35.0290],\n",
      "        [35.2665],\n",
      "        [34.9426],\n",
      "        [35.1003],\n",
      "        [35.6985],\n",
      "        [36.5956],\n",
      "        [35.7663],\n",
      "        [35.1041],\n",
      "        [36.1409],\n",
      "        [36.7595],\n",
      "        [36.1990],\n",
      "        [35.7948],\n",
      "        [36.0171],\n",
      "        [35.8555],\n",
      "        [36.3284],\n",
      "        [36.0309],\n",
      "        [34.9465],\n",
      "        [35.8947],\n",
      "        [36.5779],\n",
      "        [35.6974],\n",
      "        [36.4422],\n",
      "        [36.1278],\n",
      "        [36.1386],\n",
      "        [36.3792],\n",
      "        [35.3477],\n",
      "        [35.1244],\n",
      "        [35.1181],\n",
      "        [34.7718],\n",
      "        [34.9308],\n",
      "        [35.5438],\n",
      "        [35.1727],\n",
      "        [35.4193],\n",
      "        [34.7622],\n",
      "        [35.1816],\n",
      "        [35.2385],\n",
      "        [35.5055],\n",
      "        [35.1696],\n",
      "        [35.1384],\n",
      "        [35.3725],\n",
      "        [35.9272],\n",
      "        [35.8556],\n",
      "        [35.0302],\n",
      "        [35.1732],\n",
      "        [35.1763],\n",
      "        [35.1862],\n",
      "        [34.4615],\n",
      "        [34.9141],\n",
      "        [34.7764],\n",
      "        [34.9442],\n",
      "        [35.0660],\n",
      "        [34.9732],\n",
      "        [35.4361],\n",
      "        [34.6876],\n",
      "        [35.0154],\n",
      "        [34.7629],\n",
      "        [34.8500],\n",
      "        [35.0277],\n",
      "        [34.9580],\n",
      "        [34.8705],\n",
      "        [34.8615],\n",
      "        [34.8021],\n",
      "        [35.4124],\n",
      "        [34.7570],\n",
      "        [34.8142],\n",
      "        [35.4418],\n",
      "        [35.7955],\n",
      "        [35.1213],\n",
      "        [35.4149],\n",
      "        [35.1159],\n",
      "        [35.6329],\n",
      "        [35.2507],\n",
      "        [34.4524],\n",
      "        [35.2479],\n",
      "        [35.4540],\n",
      "        [35.8907],\n",
      "        [34.9457],\n",
      "        [35.1632],\n",
      "        [35.8660],\n",
      "        [36.0482],\n",
      "        [34.5688],\n",
      "        [35.3720],\n",
      "        [35.1416],\n",
      "        [35.3966],\n",
      "        [35.2632],\n",
      "        [35.6064],\n",
      "        [35.2045],\n",
      "        [35.2445],\n",
      "        [36.0054],\n",
      "        [35.7060],\n",
      "        [35.4776],\n",
      "        [35.4532],\n",
      "        [35.9189],\n",
      "        [35.4298],\n",
      "        [36.0614],\n",
      "        [36.2864],\n",
      "        [35.8412]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([48, 49, 22, 48, 47, 35, 51, 49, 40, 48, 48, 23, 39, 48, 39, 52, 64, 64,\n",
      "        64, 69, 38, 65, 66, 69, 71, 69, 69, 62, 64, 66, 61, 67, 40, 58, 56, 63,\n",
      "        33, 42, 42, 38, 38, 38, 36, 42, 42, 38, 41, 42, 32, 35, 36, 21, 29, 21,\n",
      "        36, 37, 22, 25, 25, 15, 25, 25, 31, 31, 27, 27, 31, 18, 24, 25, 29, 25,\n",
      "        25, 25, 22, 22, 54, 48, 54, 48, 45, 54, 50, 40, 49, 51, 54, 42, 54, 52,\n",
      "        54, 45, 45, 45, 43, 45, 40, 31, 39, 53, 58, 31, 40, 40, 40, 42, 39, 57,\n",
      "        52, 40, 40, 36, 50, 58, 39, 52, 23, 24, 23, 23, 23, 23, 19, 23, 23, 23,\n",
      "        23, 23], device='cuda:0')\n",
      "tensor([[35.6144],\n",
      "        [35.2893],\n",
      "        [35.6544],\n",
      "        [35.3373],\n",
      "        [34.5653],\n",
      "        [35.4691],\n",
      "        [35.2060],\n",
      "        [35.3587],\n",
      "        [34.9862],\n",
      "        [34.8001],\n",
      "        [34.8143],\n",
      "        [35.3639],\n",
      "        [34.8885],\n",
      "        [35.0373],\n",
      "        [34.9672],\n",
      "        [34.4939],\n",
      "        [35.2780],\n",
      "        [35.0649],\n",
      "        [34.7581],\n",
      "        [34.7647],\n",
      "        [35.2495],\n",
      "        [35.1054],\n",
      "        [34.7663],\n",
      "        [34.7225],\n",
      "        [35.5914],\n",
      "        [34.9022],\n",
      "        [34.6351],\n",
      "        [35.1620],\n",
      "        [35.1612],\n",
      "        [35.0974],\n",
      "        [35.1613],\n",
      "        [35.2439],\n",
      "        [35.1459],\n",
      "        [35.8126],\n",
      "        [35.4711],\n",
      "        [35.1724],\n",
      "        [35.1280],\n",
      "        [35.2822],\n",
      "        [35.5129],\n",
      "        [35.3774],\n",
      "        [35.6354],\n",
      "        [35.0499],\n",
      "        [35.1217],\n",
      "        [34.7722],\n",
      "        [34.9898],\n",
      "        [35.3910],\n",
      "        [35.1966],\n",
      "        [35.5621],\n",
      "        [35.0921],\n",
      "        [34.7162],\n",
      "        [35.5062],\n",
      "        [35.4526],\n",
      "        [35.3123],\n",
      "        [35.0316],\n",
      "        [34.5430],\n",
      "        [35.0080],\n",
      "        [35.7929],\n",
      "        [35.3753],\n",
      "        [35.0895],\n",
      "        [35.4575],\n",
      "        [35.1117],\n",
      "        [35.0628],\n",
      "        [35.0176],\n",
      "        [35.1503],\n",
      "        [34.6163],\n",
      "        [35.5882],\n",
      "        [35.2155],\n",
      "        [35.4436],\n",
      "        [34.4796],\n",
      "        [35.0091],\n",
      "        [34.6105],\n",
      "        [34.4541],\n",
      "        [34.5933],\n",
      "        [35.1123],\n",
      "        [34.8238],\n",
      "        [34.6670],\n",
      "        [34.5692],\n",
      "        [35.5169],\n",
      "        [35.4058],\n",
      "        [34.8378],\n",
      "        [34.2255],\n",
      "        [34.2950],\n",
      "        [34.9130],\n",
      "        [34.5225],\n",
      "        [34.3320],\n",
      "        [35.0717],\n",
      "        [34.6032],\n",
      "        [34.8387],\n",
      "        [35.3734],\n",
      "        [35.7447],\n",
      "        [35.2935],\n",
      "        [35.3257],\n",
      "        [35.5311],\n",
      "        [35.6017],\n",
      "        [35.9415],\n",
      "        [35.4047],\n",
      "        [35.2737],\n",
      "        [35.6353],\n",
      "        [35.8708],\n",
      "        [35.2433],\n",
      "        [35.6270],\n",
      "        [35.3618],\n",
      "        [36.2034],\n",
      "        [35.0211],\n",
      "        [35.1217],\n",
      "        [35.4628],\n",
      "        [35.2553],\n",
      "        [36.0134],\n",
      "        [34.5506],\n",
      "        [34.5815],\n",
      "        [34.7117],\n",
      "        [34.2520],\n",
      "        [34.3769],\n",
      "        [34.5910],\n",
      "        [34.5354],\n",
      "        [34.6707],\n",
      "        [34.2979],\n",
      "        [34.4241],\n",
      "        [34.6106],\n",
      "        [34.4812],\n",
      "        [35.0758],\n",
      "        [34.7206],\n",
      "        [34.7231],\n",
      "        [34.4175],\n",
      "        [34.4378],\n",
      "        [34.5189],\n",
      "        [34.3755],\n",
      "        [34.4504]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([25, 23, 23, 23, 23, 23, 23, 24, 35, 39, 37, 37, 35, 35, 35, 40, 35, 35,\n",
      "        35, 40, 35, 35, 35, 35, 39, 35, 35, 44, 46, 46, 41, 46, 45, 47, 41, 41,\n",
      "        45, 48, 25, 51, 45, 46, 25, 41, 47, 42, 46, 43, 51, 51, 51, 42, 51, 44,\n",
      "        51, 40, 49, 47, 46, 49, 44, 44, 45, 47, 40, 40, 46, 46, 36, 28, 36, 35,\n",
      "        33, 30, 39, 32, 39, 32, 29, 30, 35, 35, 35, 35, 29, 39, 36, 36, 41, 41,\n",
      "        35, 35, 30, 33, 33, 37, 37, 31, 39, 34, 31, 40, 43, 32, 32, 43, 40, 43,\n",
      "        31, 36, 28, 28, 28, 26, 26, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "        28, 28], device='cuda:0')\n",
      "tensor([[34.9354],\n",
      "        [35.5847],\n",
      "        [35.0843],\n",
      "        [34.5578],\n",
      "        [35.3019],\n",
      "        [34.8993],\n",
      "        [34.9238],\n",
      "        [34.8123],\n",
      "        [34.5559],\n",
      "        [34.9041],\n",
      "        [34.7236],\n",
      "        [35.2706],\n",
      "        [34.7996],\n",
      "        [35.0668],\n",
      "        [35.5628],\n",
      "        [35.0146],\n",
      "        [34.9071],\n",
      "        [34.8801],\n",
      "        [34.8271],\n",
      "        [35.1872],\n",
      "        [34.5878],\n",
      "        [34.5235],\n",
      "        [34.2992],\n",
      "        [34.6512],\n",
      "        [34.6249],\n",
      "        [34.5212],\n",
      "        [34.1500],\n",
      "        [34.7980],\n",
      "        [34.6923],\n",
      "        [34.3243],\n",
      "        [34.2346],\n",
      "        [34.2828],\n",
      "        [34.2228],\n",
      "        [34.3608],\n",
      "        [34.6858],\n",
      "        [34.3873],\n",
      "        [34.5244],\n",
      "        [34.4514],\n",
      "        [34.3453],\n",
      "        [34.7674],\n",
      "        [35.8849],\n",
      "        [36.0618],\n",
      "        [35.7256],\n",
      "        [35.5733],\n",
      "        [34.8199],\n",
      "        [35.4566],\n",
      "        [35.6569],\n",
      "        [35.0206],\n",
      "        [35.8021],\n",
      "        [34.9743],\n",
      "        [35.2409],\n",
      "        [35.9429],\n",
      "        [35.8933],\n",
      "        [36.0441],\n",
      "        [36.1695],\n",
      "        [35.5283],\n",
      "        [35.4363],\n",
      "        [35.6680],\n",
      "        [35.5766],\n",
      "        [34.8636],\n",
      "        [35.9381],\n",
      "        [35.0391],\n",
      "        [35.8069],\n",
      "        [35.3174],\n",
      "        [34.8805],\n",
      "        [34.3396],\n",
      "        [35.9616],\n",
      "        [35.0980],\n",
      "        [35.0979],\n",
      "        [34.9715],\n",
      "        [34.7473],\n",
      "        [35.1693],\n",
      "        [35.4876],\n",
      "        [35.0187],\n",
      "        [35.3090],\n",
      "        [35.4881],\n",
      "        [35.2279],\n",
      "        [35.0522],\n",
      "        [34.6560],\n",
      "        [35.0230],\n",
      "        [34.8411],\n",
      "        [35.5551],\n",
      "        [35.2293],\n",
      "        [35.2838],\n",
      "        [35.3332],\n",
      "        [34.4285],\n",
      "        [34.9231],\n",
      "        [34.8155],\n",
      "        [34.7130],\n",
      "        [35.2222],\n",
      "        [34.9147],\n",
      "        [34.6843],\n",
      "        [34.9610],\n",
      "        [34.2048],\n",
      "        [35.3861],\n",
      "        [34.9440],\n",
      "        [35.3340],\n",
      "        [34.9076],\n",
      "        [35.4352],\n",
      "        [34.6392],\n",
      "        [35.1992],\n",
      "        [35.5547],\n",
      "        [35.4188],\n",
      "        [35.5040],\n",
      "        [35.2623],\n",
      "        [35.2231],\n",
      "        [35.3551],\n",
      "        [34.2089],\n",
      "        [36.1320],\n",
      "        [35.1604],\n",
      "        [35.0429],\n",
      "        [35.4114],\n",
      "        [35.7380],\n",
      "        [35.4845],\n",
      "        [34.9338],\n",
      "        [34.5837],\n",
      "        [35.4295],\n",
      "        [36.0695],\n",
      "        [34.4804],\n",
      "        [36.1543],\n",
      "        [35.3321],\n",
      "        [35.1507],\n",
      "        [35.1774],\n",
      "        [34.8528],\n",
      "        [35.0173],\n",
      "        [35.2683],\n",
      "        [34.9862],\n",
      "        [35.0621]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([34, 26, 31, 34, 26, 25, 33, 33, 33, 25, 33, 27, 35, 31, 26, 30, 23, 34,\n",
      "        35, 31, 28, 21, 24, 21, 21, 21, 24, 24, 26, 21, 21, 21, 21, 21, 26, 21,\n",
      "        21, 21, 21, 24, 30, 30, 30, 30, 30, 31, 30, 33, 27, 28, 28, 34, 30, 30,\n",
      "        30, 28, 33, 27, 33, 38, 47, 47, 47, 36, 36, 41, 47, 46, 47, 48, 41, 47,\n",
      "        52, 31, 38, 46, 48, 38, 27, 46, 46, 49, 45, 41, 43, 43, 43, 43, 43, 41,\n",
      "        43, 41, 43, 40, 37, 43, 51, 43, 49, 49, 30, 30, 30, 30, 30, 30, 30, 24,\n",
      "        17, 30, 30, 30, 30, 28, 24, 32, 27, 32, 24, 27, 57, 52, 52, 59, 49, 46,\n",
      "        46, 55], device='cuda:0')\n",
      "tensor([[35.5787],\n",
      "        [35.3184],\n",
      "        [34.7838],\n",
      "        [35.3138],\n",
      "        [36.2333],\n",
      "        [35.3760],\n",
      "        [34.7017],\n",
      "        [34.7551],\n",
      "        [35.1854],\n",
      "        [35.1167],\n",
      "        [34.8667],\n",
      "        [35.5446],\n",
      "        [35.0842],\n",
      "        [35.0810],\n",
      "        [34.9591],\n",
      "        [34.9136],\n",
      "        [35.4882],\n",
      "        [34.9892],\n",
      "        [35.3778],\n",
      "        [35.0248],\n",
      "        [34.9740],\n",
      "        [35.5236],\n",
      "        [35.3771],\n",
      "        [35.2655],\n",
      "        [34.8318],\n",
      "        [35.1147],\n",
      "        [35.0397],\n",
      "        [35.2705],\n",
      "        [35.2720],\n",
      "        [35.3148],\n",
      "        [34.9709],\n",
      "        [34.7626],\n",
      "        [35.1236],\n",
      "        [35.9690],\n",
      "        [35.8185],\n",
      "        [35.1855],\n",
      "        [36.0162],\n",
      "        [36.3036],\n",
      "        [35.4538],\n",
      "        [35.8881],\n",
      "        [36.2321],\n",
      "        [35.7489],\n",
      "        [35.6275],\n",
      "        [35.9719],\n",
      "        [35.5694],\n",
      "        [35.5413],\n",
      "        [35.3599],\n",
      "        [35.3126],\n",
      "        [35.7186],\n",
      "        [35.4608],\n",
      "        [35.7050],\n",
      "        [35.6522],\n",
      "        [34.6701],\n",
      "        [34.5933],\n",
      "        [34.9761],\n",
      "        [34.5039],\n",
      "        [35.2864],\n",
      "        [34.8144],\n",
      "        [34.5630],\n",
      "        [34.6471],\n",
      "        [34.5796],\n",
      "        [34.2417],\n",
      "        [34.8353],\n",
      "        [34.8033],\n",
      "        [34.2711],\n",
      "        [34.9276],\n",
      "        [34.9628],\n",
      "        [34.3316],\n",
      "        [35.5308],\n",
      "        [34.3840],\n",
      "        [34.8614],\n",
      "        [34.6373],\n",
      "        [36.0299],\n",
      "        [35.9143],\n",
      "        [36.2348],\n",
      "        [35.9186],\n",
      "        [35.7079],\n",
      "        [36.2644],\n",
      "        [35.8824],\n",
      "        [35.8047],\n",
      "        [36.1476],\n",
      "        [35.8653],\n",
      "        [36.0065],\n",
      "        [36.1544],\n",
      "        [36.3721],\n",
      "        [35.6363],\n",
      "        [35.2340],\n",
      "        [36.0789],\n",
      "        [36.0321],\n",
      "        [35.6410],\n",
      "        [35.7115],\n",
      "        [35.1184],\n",
      "        [35.3790],\n",
      "        [35.2813],\n",
      "        [35.4760],\n",
      "        [34.9338],\n",
      "        [34.6445],\n",
      "        [34.7922],\n",
      "        [34.9295],\n",
      "        [35.0089],\n",
      "        [34.8993],\n",
      "        [35.1170],\n",
      "        [34.7012],\n",
      "        [34.6902],\n",
      "        [35.1757],\n",
      "        [34.9937],\n",
      "        [34.9860],\n",
      "        [34.8467],\n",
      "        [35.3488],\n",
      "        [35.0205],\n",
      "        [34.9816],\n",
      "        [34.7718],\n",
      "        [35.5287],\n",
      "        [35.3159],\n",
      "        [34.8780],\n",
      "        [35.1130],\n",
      "        [35.2618],\n",
      "        [35.2182],\n",
      "        [35.4153],\n",
      "        [35.5620],\n",
      "        [35.5765],\n",
      "        [34.6176],\n",
      "        [35.1192],\n",
      "        [35.1904],\n",
      "        [35.6753],\n",
      "        [34.8183],\n",
      "        [34.5606],\n",
      "        [35.4210]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "tensor([47, 45, 52, 59, 48, 55, 55, 59, 59, 51, 51, 45, 40, 32, 29, 41, 41, 36,\n",
      "        36,  3, 32, 42, 32, 40, 39, 32, 16, 40, 40, 40, 16, 38, 55, 52, 66, 52,\n",
      "        76, 67, 70, 68, 65, 60, 60, 70, 70, 70, 68, 77, 68, 68, 68, 66, 29, 29,\n",
      "        36, 29, 35, 29, 24, 35, 29, 29, 27, 32, 29, 32, 28, 33, 32, 29, 36, 39,\n",
      "        34, 34, 36, 36, 36, 36, 42, 36, 36, 36, 36, 36, 38, 36, 31, 36, 29, 29,\n",
      "        36, 29, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 40, 36, 36,\n",
      "        36, 36, 33, 35, 20, 20, 21, 24, 19, 19, 19, 21, 24, 24, 19, 19, 19, 20,\n",
      "        24, 19], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mtest(testloader,arcFaceModel,device)\n",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=191'>192</a>\u001b[0m predictedEthn \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(ethn,dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=193'>194</a>\u001b[0m age \u001b[39m=\u001b[39m get_original_age_value(age)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=194'>195</a>\u001b[0m \u001b[39mprint\u001b[39;49m(age)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=195'>196</a>\u001b[0m \u001b[39mprint\u001b[39m(age_label)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/FA_CVPR_Exp/arcFaceCelebSetBase.ipynb#X50sdnNjb2RlLXJlbW90ZQ%3D%3D?line=196'>197</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,predictedGender\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[1;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/miniconda3/envs/train/lib/python3.9/site-packages/torch/_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[1;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[1;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    117\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[1;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.test(testloader,arcFaceModel,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"arcFaceCelebSetBase.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"negGenderBaseWiki.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5ccd692eb0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainingAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"model92.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "input1=[]\n",
    "for i,data in enumerate(val_dataloader):\n",
    "    \n",
    "    if(count==0):\n",
    "     inputs=resnet(data[\"image\"].to(device))\n",
    "\n",
    " \n",
    "     input1 = polyprotect(0,inputs[0])\n",
    "\n",
    "     break\n",
    "    count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0', grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "tensor([-0.0765, -0.1069, -0.0411,  0.0238,  0.0118,  0.0784, -0.0193, -0.0194,\n",
      "        -0.0132,  0.0487,  0.0409, -0.0441, -0.1003,  0.0050,  0.0179,  0.0378,\n",
      "        -0.0322,  0.0842, -0.0395, -0.0201,  0.0457, -0.0654, -0.0586,  0.0188,\n",
      "        -0.0772,  0.0069,  0.0861, -0.0244,  0.0486, -0.0309, -0.0071,  0.0655,\n",
      "        -0.1047,  0.0400,  0.0215, -0.0451,  0.0729, -0.0582, -0.0285,  0.0711,\n",
      "        -0.0588, -0.0468, -0.0742, -0.0929,  0.0281,  0.0036, -0.0665, -0.0713,\n",
      "        -0.0775,  0.0966,  0.0213,  0.0536, -0.0497, -0.0261,  0.0736, -0.0707,\n",
      "        -0.0635,  0.0039,  0.0356,  0.0208, -0.0432,  0.0132,  0.0090, -0.0508,\n",
      "         0.0649, -0.0474,  0.0852,  0.0400,  0.0783,  0.0792, -0.0682, -0.0400,\n",
      "         0.0074, -0.0067,  0.0327,  0.0179, -0.0077, -0.0110,  0.0008,  0.0626,\n",
      "         0.0268, -0.0395, -0.0766,  0.0686, -0.0601,  0.0466,  0.0655,  0.0477,\n",
      "        -0.0761,  0.0306,  0.0702, -0.0810,  0.0598,  0.0180, -0.0715, -0.0503,\n",
      "        -0.0228, -0.0253,  0.0304, -0.0354, -0.0314, -0.0703, -0.0203,  0.0615,\n",
      "         0.0830,  0.0707,  0.0716, -0.0595, -0.0409, -0.0479, -0.0437,  0.0757,\n",
      "        -0.0215, -0.0659,  0.0782, -0.0438,  0.0741, -0.1035, -0.0170,  0.0418,\n",
      "         0.0713, -0.0575,  0.0096, -0.0349, -0.0885,  0.0735,  0.0153, -0.0870],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(-0.2496, device='cuda:0', grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    print(param[0])\n",
    "    print(torch.dot(input1,param[1]))\n",
    "    break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4430, -1.9958, -0.6684,  1.0280, -1.1776,  0.5820,  1.1919, -1.2120,\n",
       "         0.5127, -0.1822,  0.6574, -1.9295,  1.2562, -1.0405, -1.5425, -2.9240,\n",
       "         0.8135,  1.8771,  0.7530, -0.4737,  2.3692, -1.3006, -1.7764, -1.7158,\n",
       "        -1.2634,  0.7241,  1.4031, -2.1193,  0.3556,  0.8521, -2.6465, -1.6996,\n",
       "        -0.3830,  0.5889, -1.5234,  0.5707, -0.4224, -1.3535, -1.2482, -2.5428,\n",
       "        -0.5712, -0.3220,  0.3134,  1.0675, -2.0277, -0.0984,  0.9127, -0.8203,\n",
       "         0.5162,  0.8371,  0.2184,  1.7868,  0.1441,  2.2517,  0.9456,  0.2534,\n",
       "        -2.4333, -1.6649,  0.5323, -0.8450,  0.6767, -1.2998,  0.1268, -1.4707,\n",
       "        -1.2234, -3.1957, -0.3958,  2.0446, -1.4466,  1.2428, -0.1448,  1.3427,\n",
       "        -0.7067, -1.0655, -1.0468, -4.1246,  1.0056, -1.1438, -0.4887,  1.7819,\n",
       "        -0.3919, -1.5383,  3.3167,  0.0240, -0.7870, -2.7450, -2.3516, -0.2413,\n",
       "        -1.3294, -2.1587, -1.5163,  1.6668, -0.6842, -1.0367, -1.9168,  0.2893,\n",
       "        -1.6461, -0.0207, -0.1686,  1.3771,  2.9180,  1.0974, -1.5445, -1.6418,\n",
       "        -0.9539, -0.2443, -1.6943,  1.4373,  2.0447, -0.0315,  1.7296, -0.5938,\n",
       "        -0.6551,  0.2148,  0.5714,  2.0054, -1.2415,  2.9698,  0.6808,  0.2798,\n",
       "         0.3181,  0.2219,  0.2307,  0.2685,  0.3365,  0.8023, -2.3881,  1.5875],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"input1.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in input1:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ageAccuracy:  0.638671875\n",
      "ageAccuracy:  0.62109375\n",
      "ageAccuracy:  0.6087239583333334\n",
      "ageAccuracy:  0.6162109375\n",
      "ageAccuracy:  0.626953125\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.62890625\n",
      "ageAccuracy:  0.628662109375\n",
      "ageAccuracy:  0.6271701388888888\n",
      "ageAccuracy:  0.6259765625\n",
      "ageAccuracy:  0.6296164772727273\n",
      "ageAccuracy:  0.6300455729166666\n",
      "ageAccuracy:  0.6275540865384616\n",
      "ageAccuracy:  0.6256975446428571\n",
      "ageAccuracy:  0.62578125\n",
      "ageAccuracy:  0.627197265625\n",
      "ageAccuracy:  0.6246553308823529\n",
      "ageAccuracy:  0.6252170138888888\n",
      "ageAccuracy:  0.6258223684210527\n",
      "ageAccuracy:  0.62392578125\n",
      "ageAccuracy:  0.6255580357142857\n",
      "ageAccuracy:  0.6242009943181818\n",
      "ageAccuracy:  0.6240658967391305\n",
      "ageAccuracy:  0.624267578125\n",
      "ageAccuracy:  0.6246875\n",
      "ageAccuracy:  0.6246995192307693\n",
      "ageAccuracy:  0.6237702546296297\n",
      "ageAccuracy:  0.6241629464285714\n",
      "ageAccuracy:  0.6245285560344828\n",
      "ageAccuracy:  0.6251953125\n",
      "ageAccuracy:  0.6246219758064516\n",
      "ageAccuracy:  0.62457275390625\n",
      "ageAccuracy:  0.6244081439393939\n",
      "ageAccuracy:  0.6249425551470589\n",
      "ageAccuracy:  0.6246651785714286\n",
      "ageAccuracy:  0.6248372395833334\n",
      "ageAccuracy:  0.6230996621621622\n",
      "ageAccuracy:  0.6235608552631579\n",
      "ageAccuracy:  0.6234475160256411\n",
      "ageAccuracy:  0.62275390625\n",
      "ageAccuracy:  0.6228563262195121\n",
      "ageAccuracy:  0.6216982886904762\n",
      "ageAccuracy:  0.6209574854651163\n",
      "ageAccuracy:  0.6209161931818182\n",
      "ageAccuracy:  0.6213541666666667\n",
      "ageAccuracy:  0.621475883152174\n",
      "ageAccuracy:  0.6214261968085106\n",
      "ageAccuracy:  0.62158203125\n",
      "ageAccuracy:  0.6218510841836735\n",
      "ageAccuracy:  0.6220703125\n",
      "ageAccuracy:  0.6222043504901961\n",
      "ageAccuracy:  0.6222581129807693\n",
      "ageAccuracy:  0.6218676297169812\n",
      "ageAccuracy:  0.6221426504629629\n",
      "ageAccuracy:  0.6223011363636364\n",
      "ageAccuracy:  0.6221400669642857\n",
      "ageAccuracy:  0.621813322368421\n",
      "ageAccuracy:  0.6223060344827587\n",
      "ageAccuracy:  0.6223847987288136\n",
      "ageAccuracy:  0.6228515625\n",
      "ageAccuracy:  0.6227587090163934\n",
      "ageAccuracy:  0.6231098790322581\n",
      "ageAccuracy:  0.6231398809523809\n",
      "ageAccuracy:  0.623321533203125\n",
      "ageAccuracy:  0.6232572115384616\n",
      "ageAccuracy:  0.6234907670454546\n",
      "ageAccuracy:  0.6238922574626866\n",
      "ageAccuracy:  0.6239372702205882\n",
      "ageAccuracy:  0.6240942028985508\n",
      "ageAccuracy:  0.6241908482142857\n",
      "ageAccuracy:  0.6242572623239436\n",
      "ageAccuracy:  0.6239691840277778\n",
      "ageAccuracy:  0.6239030393835616\n",
      "ageAccuracy:  0.6237595016891891\n",
      "ageAccuracy:  0.62421875\n",
      "ageAccuracy:  0.624254728618421\n",
      "ageAccuracy:  0.624416599025974\n",
      "ageAccuracy:  0.624198717948718\n",
      "ageAccuracy:  0.6240302367217028\n",
      "Test Gender Accuracy: 0.9118510045752934 \n",
      "\n",
      "Test Age Accuracy: 0.6240302367217028 \n",
      "\n",
      "Test Age Loss: 0.313527571161588 \n",
      "\n",
      "\n",
      "\n",
      "Max 0\n",
      "Min 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9118510045752934, 4815.783493041992)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"/home/csgrad/byalavar/FHE/HEAAN/modelUsing0.pt\")\n",
    "model.to(device)\n",
    "model.test(dataloader,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"modelUsing0.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "Parameter containing:\n",
      "tensor([-0.0608, -0.0217,  0.0529, -0.0089,  0.0091,  0.0046, -0.0850,  0.0737,\n",
      "         0.0143,  0.0217, -0.0977,  0.0810, -0.0564,  0.0011,  0.0722, -0.0247,\n",
      "         0.0400, -0.0504, -0.0266,  0.0041,  0.0306, -0.0060, -0.0088, -0.0187,\n",
      "         0.0724, -0.0828, -0.0848, -0.0345, -0.0290,  0.0105,  0.0145, -0.0039,\n",
      "        -0.0052, -0.0191,  0.0698, -0.0620, -0.0487, -0.1063,  0.0467, -0.0002,\n",
      "         0.0537,  0.0358, -0.0329,  0.0654, -0.0006, -0.1011, -0.0192, -0.0640,\n",
      "        -0.0694,  0.0320, -0.1085,  0.0418, -0.0238, -0.0615, -0.0560,  0.0657,\n",
      "        -0.0512,  0.0451, -0.0391,  0.0244, -0.0777, -0.0340,  0.0475,  0.0886,\n",
      "         0.0003, -0.0109, -0.0577, -0.0619, -0.0323, -0.0008, -0.0176,  0.0066,\n",
      "         0.0504,  0.0278, -0.0135,  0.0303,  0.0313, -0.0311,  0.0308, -0.0487,\n",
      "         0.0603, -0.0842,  0.0063, -0.0263,  0.0686,  0.0789,  0.0931,  0.0091,\n",
      "        -0.0183, -0.0787,  0.0457,  0.0954,  0.0281, -0.0374,  0.0159, -0.0512,\n",
      "        -0.0433, -0.0511, -0.0834,  0.0953, -0.1000,  0.0523, -0.0116,  0.0425,\n",
      "        -0.0527, -0.0206, -0.0190, -0.0797,  0.0660, -0.0485, -0.0466,  0.0153,\n",
      "        -0.0169,  0.0452, -0.0746, -0.0683,  0.0565,  0.0540, -0.0384,  0.0310,\n",
      "         0.0139,  0.0437, -0.0087, -0.0292,  0.0351, -0.0614, -0.0722,  0.0297,\n",
      "         0.1136,  0.0672, -0.0866,  0.1015, -0.0465,  0.0330,  0.0159, -0.0102,\n",
      "         0.0414,  0.0236,  0.0637,  0.0466,  0.0528, -0.0651, -0.0702, -0.0829,\n",
      "        -0.0911,  0.0808, -0.0970,  0.0308,  0.1084,  0.0431,  0.0110,  0.0354,\n",
      "        -0.0004,  0.0313, -0.0509,  0.0891, -0.0619, -0.0549,  0.0235, -0.0453,\n",
      "         0.0305,  0.0650,  0.0026,  0.0656,  0.0059,  0.0531, -0.0560,  0.0448,\n",
      "         0.0648, -0.0330, -0.0089, -0.1149,  0.0918, -0.0469,  0.0221, -0.0289,\n",
      "         0.0285,  0.1076, -0.0770, -0.0513,  0.0834,  0.0107, -0.0912, -0.0662,\n",
      "        -0.0766,  0.0287,  0.0123, -0.0207, -0.0837, -0.0780,  0.0546,  0.0836,\n",
      "        -0.0027,  0.1223, -0.0599, -0.0164,  0.0038,  0.0645,  0.0602, -0.0260,\n",
      "        -0.1117, -0.0681, -0.0433,  0.0739,  0.0762,  0.0478,  0.0897, -0.0819,\n",
      "         0.0830, -0.0597,  0.0852,  0.0506,  0.0303,  0.0344, -0.0822, -0.0732,\n",
      "        -0.0964,  0.0137, -0.0595, -0.0760,  0.0394,  0.0083, -0.0690,  0.0529,\n",
      "         0.0407, -0.0937,  0.0200,  0.0386,  0.0058,  0.0301, -0.0113,  0.0929,\n",
      "         0.0309, -0.0483, -0.0190, -0.0249,  0.0614, -0.0806,  0.0442,  0.0468,\n",
      "         0.0455,  0.0116, -0.0451, -0.0917,  0.0322, -0.0705,  0.0507, -0.0204,\n",
      "         0.0007, -0.0027,  0.0428,  0.0796, -0.0316,  0.0552, -0.0604,  0.0575,\n",
      "         0.0360,  0.0643,  0.0433, -0.0074,  0.0539, -0.0003,  0.0321,  0.0552,\n",
      "         0.0537, -0.0608, -0.0301,  0.0042,  0.0934,  0.0286, -0.1056, -0.0474,\n",
      "        -0.0313, -0.0984,  0.0300,  0.0091, -0.0760,  0.0004, -0.0812,  0.0902,\n",
      "        -0.0741,  0.0695, -0.0525, -0.0741,  0.0278, -0.0640, -0.0199, -0.0633,\n",
      "         0.0149, -0.0275, -0.0856, -0.0580, -0.0747, -0.0139,  0.0040,  0.0315,\n",
      "        -0.0552, -0.0549,  0.0007, -0.0453, -0.0781,  0.0112,  0.0050,  0.0232,\n",
      "        -0.0420,  0.0694,  0.0666,  0.0664,  0.0244, -0.0461, -0.0278, -0.0601,\n",
      "         0.0799, -0.0605, -0.0106, -0.0346,  0.0085,  0.0739, -0.0433, -0.0053,\n",
      "         0.0755, -0.0756, -0.0710, -0.0266,  0.0126, -0.0906,  0.0843, -0.0450,\n",
      "        -0.0306,  0.0114, -0.0750,  0.0695,  0.0847,  0.0204,  0.0869,  0.0717,\n",
      "         0.0892,  0.0096, -0.0551, -0.0669, -0.0853, -0.0864,  0.1047, -0.0818,\n",
      "        -0.0770,  0.0931,  0.0221,  0.0545, -0.0748,  0.0771,  0.0588, -0.0495,\n",
      "         0.0075, -0.0071, -0.0681,  0.0002,  0.0290, -0.0568, -0.0345,  0.0315,\n",
      "         0.0363, -0.0928,  0.0599, -0.0570,  0.0604,  0.0524,  0.0424, -0.1010,\n",
      "        -0.1053, -0.0505, -0.0577,  0.0719,  0.0369,  0.0338,  0.0068,  0.0026,\n",
      "         0.0439,  0.0258, -0.0427,  0.0594, -0.0648, -0.0282, -0.0707, -0.0582,\n",
      "        -0.0210, -0.0880,  0.0366, -0.0133, -0.0476,  0.0635, -0.0333,  0.0534,\n",
      "        -0.0450,  0.0781, -0.0265, -0.0237,  0.0189, -0.0033, -0.0879,  0.0066,\n",
      "        -0.0582,  0.0313, -0.0012, -0.0256,  0.0776, -0.0801,  0.0883, -0.0772,\n",
      "        -0.0547,  0.0284, -0.0085, -0.0172, -0.0248, -0.0611, -0.0257, -0.0427,\n",
      "        -0.0368,  0.0097, -0.0731,  0.0816, -0.0421, -0.0192, -0.0546,  0.0163,\n",
      "         0.0369,  0.0193, -0.0264, -0.0645, -0.0581, -0.0677, -0.0154,  0.0552,\n",
      "        -0.0798,  0.0711,  0.0431,  0.0272, -0.0204,  0.0371, -0.0032,  0.0675,\n",
      "        -0.0399, -0.0378, -0.0247,  0.0556, -0.0469, -0.0313,  0.0346, -0.0774,\n",
      "         0.0135, -0.0863, -0.0374, -0.0790,  0.0758, -0.0534, -0.0496, -0.0032,\n",
      "         0.0652, -0.0750, -0.0940, -0.0387, -0.0594, -0.0751,  0.0502,  0.0511,\n",
      "        -0.0417,  0.0018, -0.0762, -0.0004,  0.0037,  0.0627,  0.0120,  0.0338,\n",
      "        -0.0688,  0.0400,  0.0855,  0.0265,  0.0423, -0.0375,  0.0245,  0.0013,\n",
      "         0.0121, -0.0373, -0.0252,  0.0247,  0.0048,  0.0476,  0.0585, -0.0490,\n",
      "         0.0448, -0.0205, -0.0537, -0.0524,  0.0103,  0.0989, -0.0534,  0.0832,\n",
      "         0.0281,  0.0697, -0.0782,  0.0404, -0.0589,  0.0134, -0.0148, -0.0104,\n",
      "         0.0143, -0.0749, -0.0312,  0.0053, -0.0827, -0.0643, -0.0590,  0.0067],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for param in model.parameters():\n",
    "    print(param.shape)\n",
    "    count=count+1\n",
    "    if(count==2):\n",
    "        print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input1 tensor([[0.1725, 0.7784, 0.7692, 0.3667]])\n",
      "param Parameter containing:\n",
      "tensor([[ 0.0794, -0.2791,  0.0171, -0.2814],\n",
      "        [-0.0677, -0.3197, -0.2683, -0.3466]], requires_grad=True)\n",
      "param Parameter containing:\n",
      "tensor([ 0.0877, -0.3602], requires_grad=True)\n",
      "tensor([[-0.2058, -0.9542]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a=nn.Linear(4,2)\n",
    "input1=torch.rand((1,4))\n",
    "print(\"input1\",input1)\n",
    "for param in a.parameters():\n",
    "    print(\"param\",param)\n",
    "print(a(input1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n",
      "torch.Size([128, 512])\n",
      "torch.Size([128])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m        ageBias \u001b[39m=\u001b[39m param\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Btrail-01.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(ageBias),\u001b[39mlen\u001b[39;49m(ageBias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "model=faceAnalytics()\n",
    "model=torch.load(\"modelUsing0.pt\")\n",
    "model.to(device)\n",
    "count=0\n",
    "ageBias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==7):\n",
    "       ageBias = param.tolist()\n",
    "    count=count+1\n",
    "print(len(ageBias),len(ageBias[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09601110219955444]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007277209311723709,\n",
       " -0.0321158841252327,\n",
       " -0.031418390572071075,\n",
       " -0.006457424722611904,\n",
       " 0.0034283681306988,\n",
       " 0.018647771328687668,\n",
       " 0.010360945016145706,\n",
       " -0.046598006039857864,\n",
       " -0.05573476478457451,\n",
       " 0.01843833737075329,\n",
       " 0.0027071069926023483,\n",
       " 0.03294723108410835,\n",
       " 0.02504689060151577,\n",
       " -0.03142755106091499,\n",
       " -0.022691987454891205,\n",
       " 0.03483140096068382,\n",
       " -0.05341877415776253,\n",
       " 0.04222894087433815,\n",
       " -0.01728733628988266,\n",
       " -0.04929398000240326,\n",
       " 0.00046024261973798275,\n",
       " -0.044817082583904266,\n",
       " 0.0034655649214982986,\n",
       " -0.03304927796125412,\n",
       " -0.0016231774352490902,\n",
       " -0.04087826982140541,\n",
       " 0.01253503654152155,\n",
       " -0.030864598229527473,\n",
       " -0.013328468427062035,\n",
       " 0.012476014904677868,\n",
       " -0.037187058478593826,\n",
       " 0.006219789385795593,\n",
       " -0.013966446742415428,\n",
       " 0.01565675437450409,\n",
       " 0.0035794111900031567,\n",
       " -0.005585063714534044,\n",
       " 0.006055895704776049,\n",
       " 0.00048314392915926874,\n",
       " -0.010381164960563183,\n",
       " -0.018931696191430092,\n",
       " 0.012918422929942608,\n",
       " 0.014919551089406013,\n",
       " -0.015488061122596264,\n",
       " -0.01959354802966118,\n",
       " 0.038306545466184616,\n",
       " -0.05790992081165314,\n",
       " -0.017201725393533707,\n",
       " -0.03371630981564522,\n",
       " -0.024791700765490532,\n",
       " -0.031961359083652496,\n",
       " -0.030725467950105667,\n",
       " -0.045284777879714966,\n",
       " -0.012051970697939396,\n",
       " 0.01729130558669567,\n",
       " -0.058299340307712555,\n",
       " -0.008241587318480015,\n",
       " 0.008392270654439926,\n",
       " 0.012528457678854465,\n",
       " -0.02050808258354664,\n",
       " 0.018400557339191437,\n",
       " -0.05368071794509888,\n",
       " -0.04868054389953613,\n",
       " -0.011333262547850609,\n",
       " 0.036896102130413055,\n",
       " -0.029022417962551117,\n",
       " 0.023950502276420593,\n",
       " 0.019032996147871017,\n",
       " 0.0386575311422348,\n",
       " 0.04340917244553566,\n",
       " -0.05563858523964882,\n",
       " -0.02269531600177288,\n",
       " -0.008079467341303825,\n",
       " 0.027136100456118584,\n",
       " 0.024767564609646797,\n",
       " 0.0464879646897316,\n",
       " -0.034298501908779144,\n",
       " -0.05876478925347328,\n",
       " 0.019566943868994713,\n",
       " -0.00596601003780961,\n",
       " 0.012794088572263718,\n",
       " 0.028237752616405487,\n",
       " 0.0027152879629284143,\n",
       " -0.018138255923986435,\n",
       " 0.024093421176075935,\n",
       " 0.014445447362959385,\n",
       " -0.029630817472934723,\n",
       " -0.009077931754291058,\n",
       " 0.04275999963283539,\n",
       " 0.019907813519239426,\n",
       " 0.03173178434371948,\n",
       " -0.010339722968637943,\n",
       " 0.021917376667261124,\n",
       " 0.00547691760584712,\n",
       " 0.04024359956383705,\n",
       " 0.00037949683610349894,\n",
       " -0.043355707079172134,\n",
       " -0.029875755310058594,\n",
       " 0.012577931396663189,\n",
       " -0.01590362749993801,\n",
       " -0.02837674878537655,\n",
       " -0.0026315744034945965,\n",
       " 0.029960552230477333,\n",
       " 0.048201654106378555,\n",
       " 0.05135548114776611,\n",
       " -0.059926338493824005,\n",
       " -0.022241834551095963,\n",
       " -0.047569092363119125,\n",
       " 0.007798505946993828,\n",
       " 0.024846207350492477,\n",
       " -0.06639613211154938,\n",
       " -0.0007212079362943769,\n",
       " -0.022007303312420845,\n",
       " 0.0007844719802960753,\n",
       " -0.03660847619175911,\n",
       " 0.010727467015385628,\n",
       " -0.024773655459284782,\n",
       " 0.015029202215373516,\n",
       " 0.009059355594217777,\n",
       " 0.02116716280579567,\n",
       " 0.04279369115829468,\n",
       " -0.07188471406698227,\n",
       " -0.002769036218523979,\n",
       " 0.03128764033317566,\n",
       " 0.018925964832305908,\n",
       " -0.01784098893404007,\n",
       " 0.029889674857258797,\n",
       " 0.0049612135626375675,\n",
       " -0.006710418500006199]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with shape (512, 128)\n",
    "\n",
    "\n",
    "# Define the directory where you want to save the text files\n",
    "output_directory = \"ageWeights\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Write each list to a separate text file\n",
    "\n",
    "\n",
    "# Write each list to a separate text file\n",
    "for i, sublist in enumerate(ageWeights):\n",
    "    # Define the file name with leading zeros\n",
    "    file_name = f\"{i:03d}.txt\"\n",
    "\n",
    "    # Write each value in the sublist on a new line\n",
    "    with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in sublist:\n",
    "            file.write(f\"{value}\\n\")\n",
    "\n",
    "print(\"Files saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 128])\n",
      "torch.Size([512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'float' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb Cell 39\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m        \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     count\u001b[39m=\u001b[39mcount\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Btrail-02.cse.buffalo.edu/home/csgrad/byalavar/FHE/HEAAN/faceAnlaytics.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(layer1Bias),\u001b[39mlen\u001b[39;49m(layer1Bias[\u001b[39m0\u001b[39;49m]))\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
     ]
    }
   ],
   "source": [
    "count=1\n",
    "layer1Bias=[]\n",
    "for param in model.parameters(): \n",
    "    print(param.shape)\n",
    "    if(count==2):\n",
    "       layer1Bias = param.tolist()\n",
    "       break\n",
    "    count=count+1\n",
    "print(len(layer1Bias),len(layer1Bias[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory=\"\"\n",
    "file_name = \"ageBias.txt\"\n",
    "\n",
    "with open(os.path.join(output_directory, file_name), \"w\") as file:\n",
    "        for value in ageBias:\n",
    "            file.write(f\"{value}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
